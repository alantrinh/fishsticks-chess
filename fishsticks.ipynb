{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 20000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalise_scores(scores):\n",
    "    \"\"\"normalise scores between 0 and 1\"\"\"\n",
    "    return np.asarray(scores / abs(scores).max() / 2 + 0.5)\n",
    "\n",
    "def load_dataset(batches, stockfish_depth):\n",
    "    file_counter = 1\n",
    "    path=f'data/batches/depth/{stockfish_depth:02d}'\n",
    "    data = np.load(f'{path}/batch_{file_counter:02d}.npz')\n",
    "    x_train, y_train = data['bitboards'], data['scores']\n",
    "    while file_counter < batches:\n",
    "        file_counter += 1\n",
    "        new_data = np.load(f'{path}/batch_{file_counter:02d}.npz')\n",
    "        x_train = np.append(x_train, new_data['bitboards'], axis=0)\n",
    "        y_train = np.append(y_train, new_data['scores'])\n",
    "    y_train = normalise_scores(y_train)\n",
    "    return x_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras.models as models\n",
    "import tensorflow.keras.layers as layers\n",
    "import tensorflow.keras.optimizers as optimizers\n",
    "import tensorflow.keras.callbacks as callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(conv_size, conv_depth, dense_units):\n",
    "    inputs = layers.Input(shape=(12, 8, 8))\n",
    "\n",
    "    # adding the convolutional layers\n",
    "    x = inputs\n",
    "    for _ in range(conv_depth):\n",
    "        x = layers.Conv2D(\n",
    "            filters=conv_size,\n",
    "            kernel_size=(3, 3),\n",
    "            padding='same',\n",
    "            activation='relu',\n",
    "            data_format='channels_first'\n",
    "        )(x)\n",
    "\n",
    "    x = layers.Flatten()(x)\n",
    "    x = layers.Dense(dense_units, activation='relu')(x)\n",
    "    x = layers.Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "    return models.Model(inputs=inputs, outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_filters = 32\n",
    "number_conv_layers = 4\n",
    "dense_layer_units = 64\n",
    "model = build_model(number_filters, number_conv_layers, dense_layer_units) # initial 32, 4, 64 (64, 1, 64)\n",
    "x_train, y_train = load_dataset(BATCHES)\n",
    "\n",
    "model.compile(optimizer=optimizers.Adam(5e-4), loss='mean_squared_error')\n",
    "model.summary()\n",
    "history = model.fit(x_train, y_train,\n",
    "          batch_size=2048,\n",
    "          epochs=100,\n",
    "          verbose=1,\n",
    "          validation_split=0.2,\n",
    "          callbacks=[callbacks.ReduceLROnPlateau(monitor='loss', patience=10),\n",
    "                     callbacks.EarlyStopping(monitor='loss', patience=15, min_delta=1e-4)])\n",
    "\n",
    "model.save(f'models/model_{number_filters}_filters_{number_conv_layers}_conv_layers_{dense_layer_units}_dense_units.h5')\n",
    "print('New model saved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_14\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_23 (InputLayer)       [(None, 12, 8, 8)]        0         \n",
      "                                                                 \n",
      " conv2d_38 (Conv2D)          (None, 64, 8, 8)          6976      \n",
      "                                                                 \n",
      " flatten_14 (Flatten)        (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_27 (Dense)            (None, 64)                262208    \n",
      "                                                                 \n",
      " dense_28 (Dense)            (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 269,249\n",
      "Trainable params: 269,249\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "  1/391 [..............................] - ETA: 1:43 - loss: 9.8863e-04"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-18 19:29:45.196230: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - ETA: 0s - loss: 3.0491e-04"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-18 19:29:54.907314: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 11s 27ms/step - loss: 3.0491e-04 - val_loss: 2.9769e-04 - lr: 5.0000e-04\n",
      "Epoch 2/100\n",
      "391/391 [==============================] - 10s 26ms/step - loss: 2.6335e-04 - val_loss: 2.9273e-04 - lr: 5.0000e-04\n",
      "Epoch 3/100\n",
      "391/391 [==============================] - 10s 26ms/step - loss: 2.3819e-04 - val_loss: 2.8879e-04 - lr: 5.0000e-04\n",
      "Epoch 4/100\n",
      "391/391 [==============================] - 10s 26ms/step - loss: 2.1208e-04 - val_loss: 2.9514e-04 - lr: 5.0000e-04\n",
      "Epoch 5/100\n",
      "391/391 [==============================] - 10s 26ms/step - loss: 1.9009e-04 - val_loss: 2.8928e-04 - lr: 5.0000e-04\n",
      "Epoch 6/100\n",
      "391/391 [==============================] - 10s 26ms/step - loss: 1.6926e-04 - val_loss: 2.8599e-04 - lr: 5.0000e-04\n",
      "Epoch 7/100\n",
      "391/391 [==============================] - 10s 26ms/step - loss: 1.5116e-04 - val_loss: 2.8673e-04 - lr: 5.0000e-04\n",
      "Epoch 8/100\n",
      "391/391 [==============================] - 10s 26ms/step - loss: 1.3498e-04 - val_loss: 2.9089e-04 - lr: 5.0000e-04\n",
      "Epoch 9/100\n",
      "391/391 [==============================] - 10s 26ms/step - loss: 1.2194e-04 - val_loss: 2.9455e-04 - lr: 5.0000e-04\n",
      "Epoch 10/100\n",
      "391/391 [==============================] - 10s 26ms/step - loss: 1.1066e-04 - val_loss: 2.9238e-04 - lr: 5.0000e-04\n",
      "Epoch 11/100\n",
      "391/391 [==============================] - 10s 26ms/step - loss: 1.0133e-04 - val_loss: 2.9278e-04 - lr: 5.0000e-04\n",
      "Epoch 12/100\n",
      "391/391 [==============================] - 10s 26ms/step - loss: 9.3713e-05 - val_loss: 2.9386e-04 - lr: 5.0000e-04\n",
      "Epoch 13/100\n",
      "391/391 [==============================] - 10s 26ms/step - loss: 8.6632e-05 - val_loss: 2.9825e-04 - lr: 5.0000e-04\n",
      "Epoch 14/100\n",
      "391/391 [==============================] - 10s 26ms/step - loss: 8.1252e-05 - val_loss: 3.0013e-04 - lr: 5.0000e-04\n",
      "Epoch 15/100\n",
      "391/391 [==============================] - 10s 26ms/step - loss: 7.5939e-05 - val_loss: 2.9820e-04 - lr: 5.0000e-04\n",
      "Epoch 16/100\n",
      "391/391 [==============================] - 10s 26ms/step - loss: 7.1315e-05 - val_loss: 3.0072e-04 - lr: 5.0000e-04\n",
      "Epoch 17/100\n",
      "391/391 [==============================] - 10s 26ms/step - loss: 6.7528e-05 - val_loss: 3.0347e-04 - lr: 5.0000e-04\n",
      "Epoch 18/100\n",
      "391/391 [==============================] - 10s 26ms/step - loss: 6.4119e-05 - val_loss: 3.0371e-04 - lr: 5.0000e-04\n",
      "Epoch 19/100\n",
      "391/391 [==============================] - 10s 26ms/step - loss: 6.0927e-05 - val_loss: 3.0003e-04 - lr: 5.0000e-04\n",
      "Epoch 20/100\n",
      "391/391 [==============================] - 10s 26ms/step - loss: 5.8008e-05 - val_loss: 3.0298e-04 - lr: 5.0000e-04\n",
      "Epoch 21/100\n",
      "391/391 [==============================] - 10s 26ms/step - loss: 5.5741e-05 - val_loss: 3.0409e-04 - lr: 5.0000e-04\n",
      "Epoch 22/100\n",
      "391/391 [==============================] - 10s 26ms/step - loss: 5.3529e-05 - val_loss: 3.0904e-04 - lr: 5.0000e-04\n",
      "Epoch 23/100\n",
      "391/391 [==============================] - 10s 26ms/step - loss: 5.1723e-05 - val_loss: 3.0243e-04 - lr: 5.0000e-04\n",
      "Epoch 24/100\n",
      "391/391 [==============================] - 10s 26ms/step - loss: 4.4992e-05 - val_loss: 3.0430e-04 - lr: 5.0000e-05\n",
      "Epoch 25/100\n",
      "391/391 [==============================] - 10s 26ms/step - loss: 4.3565e-05 - val_loss: 3.0528e-04 - lr: 5.0000e-05\n",
      "Epoch 26/100\n",
      "391/391 [==============================] - 10s 26ms/step - loss: 4.2936e-05 - val_loss: 3.0646e-04 - lr: 5.0000e-05\n",
      "Epoch 27/100\n",
      "391/391 [==============================] - 10s 26ms/step - loss: 4.2542e-05 - val_loss: 3.0694e-04 - lr: 5.0000e-05\n",
      "Epoch 28/100\n",
      "391/391 [==============================] - 10s 26ms/step - loss: 4.2196e-05 - val_loss: 3.0732e-04 - lr: 5.0000e-05\n",
      "Epoch 29/100\n",
      "391/391 [==============================] - 10s 26ms/step - loss: 4.1866e-05 - val_loss: 3.0829e-04 - lr: 5.0000e-05\n",
      "Epoch 30/100\n",
      "391/391 [==============================] - 10s 26ms/step - loss: 4.1593e-05 - val_loss: 3.0860e-04 - lr: 5.0000e-05\n",
      "Epoch 31/100\n",
      "391/391 [==============================] - 10s 26ms/step - loss: 4.1320e-05 - val_loss: 3.0959e-04 - lr: 5.0000e-05\n",
      "Epoch 32/100\n",
      "391/391 [==============================] - 10s 26ms/step - loss: 4.1043e-05 - val_loss: 3.0803e-04 - lr: 5.0000e-05\n",
      "Epoch 33/100\n",
      "391/391 [==============================] - 10s 26ms/step - loss: 4.0778e-05 - val_loss: 3.0993e-04 - lr: 5.0000e-05\n",
      "Epoch 34/100\n",
      "391/391 [==============================] - 10s 26ms/step - loss: 3.9904e-05 - val_loss: 3.0964e-04 - lr: 5.0000e-06\n",
      "Epoch 35/100\n",
      "391/391 [==============================] - 10s 26ms/step - loss: 3.9827e-05 - val_loss: 3.0933e-04 - lr: 5.0000e-06\n",
      "Epoch 36/100\n",
      "391/391 [==============================] - 10s 26ms/step - loss: 3.9783e-05 - val_loss: 3.0943e-04 - lr: 5.0000e-06\n",
      "Epoch 37/100\n",
      "391/391 [==============================] - 10s 26ms/step - loss: 3.9747e-05 - val_loss: 3.0959e-04 - lr: 5.0000e-06\n",
      "Epoch 38/100\n",
      "391/391 [==============================] - 10s 26ms/step - loss: 3.9718e-05 - val_loss: 3.0972e-04 - lr: 5.0000e-06\n",
      "Epoch 39/100\n",
      "391/391 [==============================] - 10s 26ms/step - loss: 3.9688e-05 - val_loss: 3.0986e-04 - lr: 5.0000e-06\n",
      "New model saved\n"
     ]
    }
   ],
   "source": [
    "number_filters = 64\n",
    "number_conv_layers = 1\n",
    "dense_layer_units = 64\n",
    "model = build_model(number_filters, number_conv_layers, dense_layer_units) # initial 32, 4, 64 (64, 1, 64)\n",
    "x_train, y_train = load_dataset(BATCHES)\n",
    "\n",
    "model.compile(optimizer=optimizers.Adam(5e-4), loss='mean_squared_error')\n",
    "model.summary()\n",
    "history = model.fit(x_train, y_train,\n",
    "          batch_size=2048,\n",
    "          epochs=100,\n",
    "          verbose=1,\n",
    "          validation_split=0.2,\n",
    "          callbacks=[callbacks.ReduceLROnPlateau(monitor='loss', patience=10),\n",
    "                     callbacks.EarlyStopping(monitor='loss', patience=15, min_delta=1e-5)])\n",
    "\n",
    "model.save(f'models/model_{number_filters}_filters_{number_conv_layers}_conv_layers_{dense_layer_units}_dense_units.h5')\n",
    "print('New model saved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_17\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_26 (InputLayer)       [(None, 12, 8, 8)]        0         \n",
      "                                                                 \n",
      " conv2d_41 (Conv2D)          (None, 64, 8, 8)          6976      \n",
      "                                                                 \n",
      " flatten_17 (Flatten)        (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_33 (Dense)            (None, 64)                262208    \n",
      "                                                                 \n",
      " dense_34 (Dense)            (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 269,249\n",
      "Trainable params: 269,249\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "  1/196 [..............................] - ETA: 55s - loss: 4.9938e-04"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-18 23:05:56.081927: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "196/196 [==============================] - ETA: 0s - loss: 3.2976e-04"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-18 23:06:03.922275: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "196/196 [==============================] - 8s 42ms/step - loss: 3.2976e-04 - val_loss: 3.0373e-04 - lr: 5.0000e-04\n",
      "Epoch 2/100\n",
      "196/196 [==============================] - 8s 41ms/step - loss: 2.7724e-04 - val_loss: 2.9761e-04 - lr: 5.0000e-04\n",
      "Epoch 3/100\n",
      "196/196 [==============================] - 8s 41ms/step - loss: 2.6493e-04 - val_loss: 2.9315e-04 - lr: 5.0000e-04\n",
      "Epoch 4/100\n",
      "196/196 [==============================] - 8s 42ms/step - loss: 2.5259e-04 - val_loss: 2.8871e-04 - lr: 5.0000e-04\n",
      "Epoch 5/100\n",
      "196/196 [==============================] - 8s 42ms/step - loss: 2.3846e-04 - val_loss: 2.8348e-04 - lr: 5.0000e-04\n",
      "Epoch 6/100\n",
      "196/196 [==============================] - 8s 41ms/step - loss: 2.2587e-04 - val_loss: 2.7820e-04 - lr: 5.0000e-04\n",
      "Epoch 7/100\n",
      "196/196 [==============================] - 8s 41ms/step - loss: 2.1565e-04 - val_loss: 2.8167e-04 - lr: 5.0000e-04\n",
      "Epoch 8/100\n",
      "196/196 [==============================] - 8s 41ms/step - loss: 2.0732e-04 - val_loss: 2.8531e-04 - lr: 5.0000e-04\n",
      "Epoch 9/100\n",
      "196/196 [==============================] - 8s 41ms/step - loss: 1.9865e-04 - val_loss: 2.8300e-04 - lr: 5.0000e-04\n",
      "Epoch 10/100\n",
      "196/196 [==============================] - 8s 41ms/step - loss: 1.9016e-04 - val_loss: 2.8531e-04 - lr: 5.0000e-04\n",
      "Epoch 11/100\n",
      "196/196 [==============================] - 8s 42ms/step - loss: 1.8245e-04 - val_loss: 2.8351e-04 - lr: 5.0000e-04\n",
      "Epoch 12/100\n",
      "196/196 [==============================] - 8s 41ms/step - loss: 1.7466e-04 - val_loss: 2.8793e-04 - lr: 5.0000e-04\n",
      "Epoch 13/100\n",
      "196/196 [==============================] - 8s 41ms/step - loss: 1.6532e-04 - val_loss: 2.9397e-04 - lr: 5.0000e-04\n",
      "Epoch 14/100\n",
      "196/196 [==============================] - 8s 42ms/step - loss: 1.5714e-04 - val_loss: 2.9485e-04 - lr: 5.0000e-04\n",
      "Epoch 15/100\n",
      "196/196 [==============================] - 8s 41ms/step - loss: 1.4939e-04 - val_loss: 2.9923e-04 - lr: 5.0000e-04\n",
      "Epoch 16/100\n",
      "196/196 [==============================] - 8s 41ms/step - loss: 1.4069e-04 - val_loss: 2.9962e-04 - lr: 5.0000e-04\n",
      "Epoch 17/100\n",
      "196/196 [==============================] - 8s 41ms/step - loss: 1.3013e-04 - val_loss: 3.0005e-04 - lr: 5.0000e-05\n",
      "Epoch 18/100\n",
      "196/196 [==============================] - 8s 41ms/step - loss: 1.2865e-04 - val_loss: 3.0036e-04 - lr: 5.0000e-05\n",
      "Epoch 19/100\n",
      "196/196 [==============================] - 8s 42ms/step - loss: 1.2759e-04 - val_loss: 3.0168e-04 - lr: 5.0000e-05\n",
      "Epoch 20/100\n",
      "196/196 [==============================] - 8s 42ms/step - loss: 1.2654e-04 - val_loss: 3.0155e-04 - lr: 5.0000e-05\n",
      "Epoch 21/100\n",
      "196/196 [==============================] - 8s 42ms/step - loss: 1.2559e-04 - val_loss: 3.0076e-04 - lr: 5.0000e-05\n",
      "Epoch 22/100\n",
      "196/196 [==============================] - 8s 41ms/step - loss: 1.2463e-04 - val_loss: 3.0385e-04 - lr: 5.0000e-05\n",
      "Epoch 23/100\n",
      "196/196 [==============================] - 8s 41ms/step - loss: 1.2367e-04 - val_loss: 3.0370e-04 - lr: 5.0000e-05\n",
      "Epoch 24/100\n",
      "196/196 [==============================] - 8s 42ms/step - loss: 1.2269e-04 - val_loss: 3.0232e-04 - lr: 5.0000e-05\n",
      "Epoch 25/100\n",
      "196/196 [==============================] - 8s 41ms/step - loss: 1.2176e-04 - val_loss: 3.0398e-04 - lr: 5.0000e-05\n",
      "Epoch 26/100\n",
      "196/196 [==============================] - 8s 41ms/step - loss: 1.2081e-04 - val_loss: 3.0321e-04 - lr: 5.0000e-05\n",
      "Epoch 27/100\n",
      "196/196 [==============================] - 8s 41ms/step - loss: 1.1983e-04 - val_loss: 3.0489e-04 - lr: 5.0000e-05\n",
      "Epoch 28/100\n",
      "196/196 [==============================] - 8s 41ms/step - loss: 1.1883e-04 - val_loss: 3.0518e-04 - lr: 5.0000e-05\n",
      "Epoch 29/100\n",
      "196/196 [==============================] - 8s 41ms/step - loss: 1.1785e-04 - val_loss: 3.0444e-04 - lr: 5.0000e-05\n",
      "Epoch 30/100\n",
      "196/196 [==============================] - 8s 42ms/step - loss: 1.1687e-04 - val_loss: 3.0351e-04 - lr: 5.0000e-05\n",
      "Epoch 31/100\n",
      "196/196 [==============================] - 8s 42ms/step - loss: 1.1595e-04 - val_loss: 3.0486e-04 - lr: 5.0000e-05\n",
      "Epoch 32/100\n",
      "196/196 [==============================] - 8s 42ms/step - loss: 1.1446e-04 - val_loss: 3.0536e-04 - lr: 5.0000e-06\n",
      "Epoch 33/100\n",
      "196/196 [==============================] - 8s 42ms/step - loss: 1.1427e-04 - val_loss: 3.0615e-04 - lr: 5.0000e-06\n",
      "Epoch 34/100\n",
      "196/196 [==============================] - 8s 41ms/step - loss: 1.1416e-04 - val_loss: 3.0588e-04 - lr: 5.0000e-06\n",
      "Epoch 35/100\n",
      "196/196 [==============================] - 8s 41ms/step - loss: 1.1405e-04 - val_loss: 3.0602e-04 - lr: 5.0000e-06\n",
      "Epoch 36/100\n",
      "196/196 [==============================] - 8s 41ms/step - loss: 1.1394e-04 - val_loss: 3.0584e-04 - lr: 5.0000e-06\n",
      "Epoch 37/100\n",
      "196/196 [==============================] - 8s 42ms/step - loss: 1.1384e-04 - val_loss: 3.0595e-04 - lr: 5.0000e-06\n",
      "Epoch 38/100\n",
      "196/196 [==============================] - 8s 41ms/step - loss: 1.1372e-04 - val_loss: 3.0632e-04 - lr: 5.0000e-06\n",
      "Epoch 39/100\n",
      "196/196 [==============================] - 8s 41ms/step - loss: 1.1362e-04 - val_loss: 3.0628e-04 - lr: 5.0000e-06\n",
      "Epoch 40/100\n",
      "196/196 [==============================] - 8s 42ms/step - loss: 1.1351e-04 - val_loss: 3.0612e-04 - lr: 5.0000e-06\n",
      "Epoch 41/100\n",
      "196/196 [==============================] - 8s 42ms/step - loss: 1.1342e-04 - val_loss: 3.0626e-04 - lr: 5.0000e-06\n",
      "Epoch 42/100\n",
      "196/196 [==============================] - 8s 41ms/step - loss: 1.1322e-04 - val_loss: 3.0626e-04 - lr: 5.0000e-07\n",
      "New model saved\n"
     ]
    }
   ],
   "source": [
    "number_filters = 64\n",
    "number_conv_layers = 1\n",
    "dense_layer_units = 64\n",
    "batch_size = 4096\n",
    "model = build_model(number_filters, number_conv_layers, dense_layer_units) # initial 32, 4, 64 (64, 1, 64)\n",
    "x_train, y_train = load_dataset(BATCHES)\n",
    "\n",
    "model.compile(optimizer=optimizers.Adam(5e-4), loss='mean_squared_error')\n",
    "model.summary()\n",
    "history = model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=100,\n",
    "          verbose=1,\n",
    "          validation_split=0.2,\n",
    "          callbacks=[callbacks.ReduceLROnPlateau(monitor='loss', patience=10),\n",
    "                     callbacks.EarlyStopping(monitor='loss', patience=15, min_delta=1e-5)])\n",
    "\n",
    "model.save(f'models/model_{number_filters}_filters_{number_conv_layers}_conv_layers_{dense_layer_units}_dense_units_{batch_size}_batch_size.h5')\n",
    "print('New model saved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_23\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_32 (InputLayer)       [(None, 12, 8, 8)]        0         \n",
      "                                                                 \n",
      " conv2d_52 (Conv2D)          (None, 64, 8, 8)          6976      \n",
      "                                                                 \n",
      " conv2d_53 (Conv2D)          (None, 64, 8, 8)          36928     \n",
      "                                                                 \n",
      " flatten_23 (Flatten)        (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_45 (Dense)            (None, 64)                262208    \n",
      "                                                                 \n",
      " dense_46 (Dense)            (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 306,177\n",
      "Trainable params: 306,177\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-18 23:32:30.758419: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "196/196 [==============================] - ETA: 0s - loss: 3.0238e-04"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-18 23:32:45.720126: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "196/196 [==============================] - 16s 79ms/step - loss: 3.0238e-04 - val_loss: 3.0278e-04 - lr: 5.0000e-04\n",
      "Epoch 2/100\n",
      "196/196 [==============================] - 15s 79ms/step - loss: 2.7657e-04 - val_loss: 2.9275e-04 - lr: 5.0000e-04\n",
      "Epoch 3/100\n",
      "196/196 [==============================] - 15s 78ms/step - loss: 2.5640e-04 - val_loss: 2.8343e-04 - lr: 5.0000e-04\n",
      "Epoch 4/100\n",
      "196/196 [==============================] - 15s 78ms/step - loss: 2.3769e-04 - val_loss: 2.7760e-04 - lr: 5.0000e-04\n",
      "Epoch 5/100\n",
      "196/196 [==============================] - 15s 79ms/step - loss: 2.1891e-04 - val_loss: 2.7477e-04 - lr: 5.0000e-04\n",
      "Epoch 6/100\n",
      "196/196 [==============================] - 15s 79ms/step - loss: 2.0587e-04 - val_loss: 2.7566e-04 - lr: 5.0000e-04\n",
      "Epoch 7/100\n",
      "196/196 [==============================] - 16s 79ms/step - loss: 1.8788e-04 - val_loss: 2.8213e-04 - lr: 5.0000e-04\n",
      "Epoch 8/100\n",
      "196/196 [==============================] - 15s 78ms/step - loss: 1.7263e-04 - val_loss: 2.7966e-04 - lr: 5.0000e-04\n",
      "Epoch 9/100\n",
      "196/196 [==============================] - 15s 78ms/step - loss: 1.5679e-04 - val_loss: 2.9860e-04 - lr: 5.0000e-04\n",
      "Epoch 10/100\n",
      "196/196 [==============================] - 15s 79ms/step - loss: 1.4013e-04 - val_loss: 2.8482e-04 - lr: 5.0000e-04\n",
      "Epoch 11/100\n",
      "196/196 [==============================] - 16s 80ms/step - loss: 1.2659e-04 - val_loss: 2.8621e-04 - lr: 5.0000e-04\n",
      "Epoch 12/100\n",
      "196/196 [==============================] - 15s 79ms/step - loss: 1.1551e-04 - val_loss: 2.9582e-04 - lr: 5.0000e-04\n",
      "Epoch 13/100\n",
      "196/196 [==============================] - 15s 79ms/step - loss: 1.0538e-04 - val_loss: 2.9260e-04 - lr: 5.0000e-04\n",
      "Epoch 14/100\n",
      "196/196 [==============================] - 16s 81ms/step - loss: 9.6619e-05 - val_loss: 2.8719e-04 - lr: 5.0000e-04\n",
      "Epoch 15/100\n",
      "196/196 [==============================] - 15s 79ms/step - loss: 8.8677e-05 - val_loss: 2.9107e-04 - lr: 5.0000e-04\n",
      "Epoch 16/100\n",
      "196/196 [==============================] - 15s 79ms/step - loss: 8.2909e-05 - val_loss: 2.9358e-04 - lr: 5.0000e-04\n",
      "Epoch 17/100\n",
      "196/196 [==============================] - 15s 78ms/step - loss: 7.7465e-05 - val_loss: 2.8887e-04 - lr: 5.0000e-04\n",
      "Epoch 18/100\n",
      "196/196 [==============================] - 15s 79ms/step - loss: 7.2046e-05 - val_loss: 2.8892e-04 - lr: 5.0000e-04\n",
      "Epoch 19/100\n",
      "196/196 [==============================] - 15s 79ms/step - loss: 6.7686e-05 - val_loss: 2.9082e-04 - lr: 5.0000e-04\n",
      "Epoch 20/100\n",
      "196/196 [==============================] - 15s 78ms/step - loss: 6.4479e-05 - val_loss: 3.0336e-04 - lr: 5.0000e-04\n",
      "Epoch 21/100\n",
      "196/196 [==============================] - 15s 79ms/step - loss: 6.0916e-05 - val_loss: 2.9613e-04 - lr: 5.0000e-04\n",
      "Epoch 22/100\n",
      "196/196 [==============================] - 15s 79ms/step - loss: 5.8506e-05 - val_loss: 3.0337e-04 - lr: 5.0000e-04\n",
      "Epoch 23/100\n",
      "196/196 [==============================] - 15s 78ms/step - loss: 5.5263e-05 - val_loss: 2.9926e-04 - lr: 5.0000e-04\n",
      "Epoch 24/100\n",
      "196/196 [==============================] - 15s 79ms/step - loss: 5.3135e-05 - val_loss: 2.9732e-04 - lr: 5.0000e-04\n",
      "Epoch 25/100\n",
      "196/196 [==============================] - 16s 80ms/step - loss: 4.9761e-05 - val_loss: 2.9602e-04 - lr: 5.0000e-04\n",
      "Epoch 26/100\n",
      "196/196 [==============================] - 15s 79ms/step - loss: 4.8903e-05 - val_loss: 2.9661e-04 - lr: 5.0000e-04\n",
      "Epoch 27/100\n",
      "196/196 [==============================] - 15s 78ms/step - loss: 4.2943e-05 - val_loss: 2.9720e-04 - lr: 5.0000e-05\n",
      "Epoch 28/100\n",
      "196/196 [==============================] - 15s 78ms/step - loss: 4.1710e-05 - val_loss: 2.9795e-04 - lr: 5.0000e-05\n",
      "Epoch 29/100\n",
      "196/196 [==============================] - 15s 79ms/step - loss: 4.1232e-05 - val_loss: 2.9759e-04 - lr: 5.0000e-05\n",
      "Epoch 30/100\n",
      "196/196 [==============================] - 16s 80ms/step - loss: 4.0864e-05 - val_loss: 2.9704e-04 - lr: 5.0000e-05\n",
      "Epoch 31/100\n",
      "196/196 [==============================] - 16s 80ms/step - loss: 4.0585e-05 - val_loss: 2.9759e-04 - lr: 5.0000e-05\n",
      "Epoch 32/100\n",
      "196/196 [==============================] - 15s 79ms/step - loss: 4.0284e-05 - val_loss: 2.9759e-04 - lr: 5.0000e-05\n",
      "Epoch 33/100\n",
      "196/196 [==============================] - 16s 80ms/step - loss: 4.0052e-05 - val_loss: 2.9797e-04 - lr: 5.0000e-05\n",
      "Epoch 34/100\n",
      "196/196 [==============================] - 15s 79ms/step - loss: 3.9780e-05 - val_loss: 2.9808e-04 - lr: 5.0000e-05\n",
      "Epoch 35/100\n",
      "196/196 [==============================] - 16s 80ms/step - loss: 3.9531e-05 - val_loss: 2.9917e-04 - lr: 5.0000e-05\n",
      "Epoch 36/100\n",
      "196/196 [==============================] - 16s 80ms/step - loss: 3.9275e-05 - val_loss: 2.9947e-04 - lr: 5.0000e-05\n",
      "Epoch 37/100\n",
      "196/196 [==============================] - 16s 80ms/step - loss: 3.8536e-05 - val_loss: 2.9919e-04 - lr: 5.0000e-06\n",
      "Epoch 38/100\n",
      "196/196 [==============================] - 16s 79ms/step - loss: 3.8477e-05 - val_loss: 2.9911e-04 - lr: 5.0000e-06\n",
      "Epoch 39/100\n",
      "196/196 [==============================] - 15s 79ms/step - loss: 3.8440e-05 - val_loss: 2.9898e-04 - lr: 5.0000e-06\n",
      "Epoch 40/100\n",
      "196/196 [==============================] - 15s 79ms/step - loss: 3.8409e-05 - val_loss: 2.9915e-04 - lr: 5.0000e-06\n",
      "Epoch 41/100\n",
      "196/196 [==============================] - 15s 79ms/step - loss: 3.8384e-05 - val_loss: 2.9922e-04 - lr: 5.0000e-06\n",
      "Epoch 42/100\n",
      "196/196 [==============================] - 16s 79ms/step - loss: 3.8350e-05 - val_loss: 2.9896e-04 - lr: 5.0000e-06\n",
      "New model saved\n"
     ]
    }
   ],
   "source": [
    "number_filters = 64\n",
    "number_conv_layers = 2\n",
    "dense_layer_units = 64\n",
    "batch_size = 4096\n",
    "model = build_model(number_filters, number_conv_layers, dense_layer_units) # initial 32, 4, 64 (64, 1, 64)\n",
    "x_train, y_train = load_dataset(BATCHES)\n",
    "\n",
    "model.compile(optimizer=optimizers.Adam(5e-4), loss='mean_squared_error')\n",
    "model.summary()\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=100,\n",
    "          verbose=1,\n",
    "          validation_split=0.2,\n",
    "          callbacks=[callbacks.ReduceLROnPlateau(monitor='loss', patience=10),\n",
    "                     callbacks.EarlyStopping(monitor='loss', patience=15, min_delta=1e-5)])\n",
    "\n",
    "model.save(f'models/model_{number_filters}_filters_{number_conv_layers}_conv_layers_{dense_layer_units}_dense_units_{batch_size}_batch_size.h5')\n",
    "print('New model saved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_26\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_35 (InputLayer)       [(None, 12, 8, 8)]        0         \n",
      "                                                                 \n",
      " conv2d_60 (Conv2D)          (None, 128, 8, 8)         13952     \n",
      "                                                                 \n",
      " conv2d_61 (Conv2D)          (None, 128, 8, 8)         147584    \n",
      "                                                                 \n",
      " flatten_26 (Flatten)        (None, 8192)              0         \n",
      "                                                                 \n",
      " dense_51 (Dense)            (None, 64)                524352    \n",
      "                                                                 \n",
      " dense_52 (Dense)            (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 685,953\n",
      "Trainable params: 685,953\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-19 00:10:35.160746: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "196/196 [==============================] - ETA: 0s - loss: 3.0984e-04"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-19 00:10:57.123462: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "196/196 [==============================] - 23s 116ms/step - loss: 3.0984e-04 - val_loss: 3.0120e-04 - lr: 5.0000e-04\n",
      "Epoch 2/100\n",
      "196/196 [==============================] - 23s 115ms/step - loss: 2.7206e-04 - val_loss: 2.8964e-04 - lr: 5.0000e-04\n",
      "Epoch 3/100\n",
      "196/196 [==============================] - 23s 115ms/step - loss: 2.5262e-04 - val_loss: 2.7955e-04 - lr: 5.0000e-04\n",
      "Epoch 4/100\n",
      "196/196 [==============================] - 23s 115ms/step - loss: 2.3364e-04 - val_loss: 2.7370e-04 - lr: 5.0000e-04\n",
      "Epoch 5/100\n",
      "196/196 [==============================] - 23s 115ms/step - loss: 2.1871e-04 - val_loss: 2.7515e-04 - lr: 5.0000e-04\n",
      "Epoch 6/100\n",
      "196/196 [==============================] - 23s 115ms/step - loss: 2.0383e-04 - val_loss: 2.7223e-04 - lr: 5.0000e-04\n",
      "Epoch 7/100\n",
      "196/196 [==============================] - 23s 115ms/step - loss: 1.9004e-04 - val_loss: 2.8095e-04 - lr: 5.0000e-04\n",
      "Epoch 8/100\n",
      "196/196 [==============================] - 22s 115ms/step - loss: 1.7551e-04 - val_loss: 2.8701e-04 - lr: 5.0000e-04\n",
      "Epoch 9/100\n",
      "196/196 [==============================] - 23s 115ms/step - loss: 1.5882e-04 - val_loss: 2.8706e-04 - lr: 5.0000e-04\n",
      "Epoch 10/100\n",
      "196/196 [==============================] - 23s 115ms/step - loss: 1.4275e-04 - val_loss: 2.8877e-04 - lr: 5.0000e-04\n",
      "Epoch 11/100\n",
      "196/196 [==============================] - 23s 115ms/step - loss: 1.2584e-04 - val_loss: 2.9216e-04 - lr: 5.0000e-04\n",
      "Epoch 12/100\n",
      "196/196 [==============================] - 23s 115ms/step - loss: 1.0870e-04 - val_loss: 2.9027e-04 - lr: 5.0000e-05\n",
      "Epoch 13/100\n",
      "196/196 [==============================] - 23s 115ms/step - loss: 1.0615e-04 - val_loss: 2.9089e-04 - lr: 5.0000e-05\n",
      "Epoch 14/100\n",
      "196/196 [==============================] - 23s 115ms/step - loss: 1.0450e-04 - val_loss: 2.9143e-04 - lr: 5.0000e-05\n",
      "Epoch 15/100\n",
      "196/196 [==============================] - 23s 115ms/step - loss: 1.0288e-04 - val_loss: 2.9135e-04 - lr: 5.0000e-05\n",
      "Epoch 16/100\n",
      "196/196 [==============================] - 23s 116ms/step - loss: 1.0149e-04 - val_loss: 2.9129e-04 - lr: 5.0000e-05\n",
      "Epoch 17/100\n",
      "196/196 [==============================] - 23s 115ms/step - loss: 1.0002e-04 - val_loss: 2.9228e-04 - lr: 5.0000e-05\n",
      "Epoch 18/100\n",
      "196/196 [==============================] - 23s 116ms/step - loss: 9.8633e-05 - val_loss: 2.9100e-04 - lr: 5.0000e-05\n",
      "New model saved\n"
     ]
    }
   ],
   "source": [
    "number_filters = 128\n",
    "number_conv_layers = 2\n",
    "dense_layer_units = 64\n",
    "batch_size = 4096\n",
    "model = build_model(number_filters, number_conv_layers, dense_layer_units) # initial 32, 4, 64 (64, 1, 64)\n",
    "x_train, y_train = load_dataset(BATCHES)\n",
    "\n",
    "model.compile(optimizer=optimizers.Adam(5e-4), loss='mean_squared_error')\n",
    "model.summary()\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=100,\n",
    "          verbose=1,\n",
    "          validation_split=0.2,\n",
    "          callbacks=[callbacks.ReduceLROnPlateau(monitor='val_loss', patience=10),\n",
    "                     callbacks.EarlyStopping(monitor='val_loss', patience=15, min_delta=1e-5)])\n",
    "\n",
    "model.save(f'models/model_{number_filters}_filters_{number_conv_layers}_conv_layers_{dense_layer_units}_dense_units_{batch_size}_batch_size.h5')\n",
    "print('New model saved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_28\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_37 (InputLayer)       [(None, 12, 8, 8)]        0         \n",
      "                                                                 \n",
      " conv2d_64 (Conv2D)          (None, 128, 8, 8)         13952     \n",
      "                                                                 \n",
      " flatten_28 (Flatten)        (None, 8192)              0         \n",
      "                                                                 \n",
      " dense_55 (Dense)            (None, 64)                524352    \n",
      "                                                                 \n",
      " dense_56 (Dense)            (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 538,369\n",
      "Trainable params: 538,369\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "  1/196 [..............................] - ETA: 57s - loss: 6.5805e-04"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-19 00:28:47.454892: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "196/196 [==============================] - ETA: 0s - loss: 3.2757e-04"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-19 00:28:56.442378: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "196/196 [==============================] - 10s 48ms/step - loss: 3.2757e-04 - val_loss: 3.0963e-04 - lr: 5.0000e-04\n",
      "Epoch 2/100\n",
      "196/196 [==============================] - 9s 47ms/step - loss: 2.8210e-04 - val_loss: 2.9858e-04 - lr: 5.0000e-04\n",
      "Epoch 3/100\n",
      "196/196 [==============================] - 9s 46ms/step - loss: 2.6692e-04 - val_loss: 2.9123e-04 - lr: 5.0000e-04\n",
      "Epoch 4/100\n",
      "196/196 [==============================] - 9s 46ms/step - loss: 2.5121e-04 - val_loss: 2.8231e-04 - lr: 5.0000e-04\n",
      "Epoch 5/100\n",
      "196/196 [==============================] - 9s 46ms/step - loss: 2.3650e-04 - val_loss: 2.7505e-04 - lr: 5.0000e-04\n",
      "Epoch 6/100\n",
      "196/196 [==============================] - 9s 46ms/step - loss: 2.2549e-04 - val_loss: 2.7187e-04 - lr: 5.0000e-04\n",
      "Epoch 7/100\n",
      "196/196 [==============================] - 9s 47ms/step - loss: 2.1511e-04 - val_loss: 2.7126e-04 - lr: 5.0000e-04\n",
      "Epoch 8/100\n",
      "196/196 [==============================] - 9s 47ms/step - loss: 2.0671e-04 - val_loss: 2.7098e-04 - lr: 5.0000e-04\n",
      "Epoch 9/100\n",
      "196/196 [==============================] - 9s 46ms/step - loss: 1.9900e-04 - val_loss: 2.7364e-04 - lr: 5.0000e-04\n",
      "Epoch 10/100\n",
      "196/196 [==============================] - 9s 46ms/step - loss: 1.9299e-04 - val_loss: 2.7565e-04 - lr: 5.0000e-04\n",
      "Epoch 11/100\n",
      "196/196 [==============================] - 9s 46ms/step - loss: 1.8657e-04 - val_loss: 2.7955e-04 - lr: 5.0000e-04\n",
      "Epoch 12/100\n",
      "196/196 [==============================] - 9s 46ms/step - loss: 1.8016e-04 - val_loss: 2.7529e-04 - lr: 5.0000e-05\n",
      "Epoch 13/100\n",
      "196/196 [==============================] - 9s 46ms/step - loss: 1.7905e-04 - val_loss: 2.7597e-04 - lr: 5.0000e-05\n",
      "Epoch 14/100\n",
      "196/196 [==============================] - 9s 47ms/step - loss: 1.7834e-04 - val_loss: 2.7619e-04 - lr: 5.0000e-05\n",
      "Epoch 15/100\n",
      "196/196 [==============================] - 9s 47ms/step - loss: 1.7761e-04 - val_loss: 2.7638e-04 - lr: 5.0000e-05\n",
      "Epoch 16/100\n",
      "196/196 [==============================] - 9s 47ms/step - loss: 1.7697e-04 - val_loss: 2.7643e-04 - lr: 5.0000e-05\n",
      "Epoch 17/100\n",
      "196/196 [==============================] - 9s 47ms/step - loss: 1.7632e-04 - val_loss: 2.7659e-04 - lr: 5.0000e-05\n",
      "Epoch 18/100\n",
      "196/196 [==============================] - 9s 47ms/step - loss: 1.7573e-04 - val_loss: 2.7717e-04 - lr: 5.0000e-05\n",
      "Epoch 19/100\n",
      "196/196 [==============================] - 9s 47ms/step - loss: 1.7499e-04 - val_loss: 2.7743e-04 - lr: 5.0000e-05\n",
      "Epoch 20/100\n",
      "196/196 [==============================] - 9s 47ms/step - loss: 1.7438e-04 - val_loss: 2.7769e-04 - lr: 5.0000e-05\n",
      "Epoch 21/100\n",
      "196/196 [==============================] - 9s 47ms/step - loss: 1.7365e-04 - val_loss: 2.7789e-04 - lr: 5.0000e-05\n",
      "New model saved\n"
     ]
    }
   ],
   "source": [
    "number_filters = 128\n",
    "number_conv_layers = 1\n",
    "dense_layer_units = 64\n",
    "batch_size = 4096\n",
    "model = build_model(number_filters, number_conv_layers, dense_layer_units) # initial 32, 4, 64 (64, 1, 64)\n",
    "x_train, y_train = load_dataset(BATCHES)\n",
    "\n",
    "model.compile(optimizer=optimizers.Adam(5e-4), loss='mean_squared_error')\n",
    "model.summary()\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=100,\n",
    "          verbose=1,\n",
    "          validation_split=0.2,\n",
    "          callbacks=[callbacks.ReduceLROnPlateau(monitor='val_loss', patience=10),\n",
    "                     callbacks.EarlyStopping(monitor='val_loss', patience=15, min_delta=1e-5)])\n",
    "\n",
    "model.save(f'models/model_{number_filters}_filters_{number_conv_layers}_conv_layers_{dense_layer_units}_dense_units_{batch_size}_batch_size.h5')\n",
    "print('New model saved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_30\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_39 (InputLayer)       [(None, 12, 8, 8)]        0         \n",
      "                                                                 \n",
      " conv2d_66 (Conv2D)          (None, 128, 8, 8)         13952     \n",
      "                                                                 \n",
      " flatten_30 (Flatten)        (None, 8192)              0         \n",
      "                                                                 \n",
      " dense_59 (Dense)            (None, 128)               1048704   \n",
      "                                                                 \n",
      " dense_60 (Dense)            (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,062,785\n",
      "Trainable params: 1,062,785\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "  1/196 [..............................] - ETA: 56s - loss: 5.6673e-04"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-19 00:41:32.386869: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "196/196 [==============================] - ETA: 0s - loss: 3.4228e-04"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-19 00:41:41.613317: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "196/196 [==============================] - 10s 49ms/step - loss: 3.4228e-04 - val_loss: 3.0822e-04 - lr: 5.0000e-04\n",
      "Epoch 2/100\n",
      "196/196 [==============================] - 10s 49ms/step - loss: 2.8931e-04 - val_loss: 3.0148e-04 - lr: 5.0000e-04\n",
      "Epoch 3/100\n",
      "196/196 [==============================] - 10s 49ms/step - loss: 2.7648e-04 - val_loss: 2.9523e-04 - lr: 5.0000e-04\n",
      "Epoch 4/100\n",
      "196/196 [==============================] - 10s 49ms/step - loss: 2.6052e-04 - val_loss: 2.8992e-04 - lr: 5.0000e-04\n",
      "Epoch 5/100\n",
      "196/196 [==============================] - 10s 49ms/step - loss: 2.4182e-04 - val_loss: 2.7799e-04 - lr: 5.0000e-04\n",
      "Epoch 6/100\n",
      "196/196 [==============================] - 9s 48ms/step - loss: 2.2591e-04 - val_loss: 2.7154e-04 - lr: 5.0000e-04\n",
      "Epoch 7/100\n",
      "196/196 [==============================] - 9s 48ms/step - loss: 2.1579e-04 - val_loss: 2.7035e-04 - lr: 1.0000e-04\n",
      "Epoch 8/100\n",
      "196/196 [==============================] - 10s 49ms/step - loss: 2.1337e-04 - val_loss: 2.7008e-04 - lr: 1.0000e-04\n",
      "Epoch 9/100\n",
      "196/196 [==============================] - 10s 49ms/step - loss: 2.1127e-04 - val_loss: 2.7015e-04 - lr: 1.0000e-04\n",
      "Epoch 10/100\n",
      "196/196 [==============================] - 9s 48ms/step - loss: 2.0909e-04 - val_loss: 2.7003e-04 - lr: 1.0000e-04\n",
      "Epoch 11/100\n",
      "196/196 [==============================] - 9s 48ms/step - loss: 2.0694e-04 - val_loss: 2.6975e-04 - lr: 1.0000e-04\n",
      "Epoch 12/100\n",
      "196/196 [==============================] - 9s 48ms/step - loss: 2.0484e-04 - val_loss: 2.7011e-04 - lr: 2.0000e-05\n",
      "Epoch 13/100\n",
      "196/196 [==============================] - 9s 48ms/step - loss: 2.0438e-04 - val_loss: 2.7014e-04 - lr: 2.0000e-05\n",
      "Epoch 14/100\n",
      "196/196 [==============================] - 9s 48ms/step - loss: 2.0390e-04 - val_loss: 2.7014e-04 - lr: 2.0000e-05\n",
      "Epoch 15/100\n",
      "196/196 [==============================] - 10s 49ms/step - loss: 2.0342e-04 - val_loss: 2.7048e-04 - lr: 2.0000e-05\n",
      "New model saved\n"
     ]
    }
   ],
   "source": [
    "number_filters = 128\n",
    "number_conv_layers = 1\n",
    "dense_layer_units = 128\n",
    "batch_size = 4096\n",
    "model = build_model(number_filters, number_conv_layers, dense_layer_units) # initial 32, 4, 64 (64, 1, 64)\n",
    "x_train, y_train = load_dataset(BATCHES)\n",
    "\n",
    "model.compile(optimizer=optimizers.Adam(5e-4), loss='mean_squared_error')\n",
    "model.summary()\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=100,\n",
    "          verbose=1,\n",
    "          validation_split=0.2,\n",
    "          callbacks=[callbacks.ReduceLROnPlateau(monitor='val_loss', patience=5, factor=0.2),\n",
    "                     callbacks.EarlyStopping(monitor='val_loss', patience=10, min_delta=1e-5)])\n",
    "\n",
    "model.save(f'models/model_{number_filters}_filters_{number_conv_layers}_conv_layers_{dense_layer_units}_dense_units_{batch_size}_batch_size.h5')\n",
    "print('New model saved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_40\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_49 (InputLayer)       [(None, 12, 8, 8)]        0         \n",
      "                                                                 \n",
      " conv2d_76 (Conv2D)          (None, 128, 8, 8)         13952     \n",
      "                                                                 \n",
      " flatten_40 (Flatten)        (None, 8192)              0         \n",
      "                                                                 \n",
      " dense_79 (Dense)            (None, 128)               1048704   \n",
      "                                                                 \n",
      " dense_80 (Dense)            (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,062,785\n",
      "Trainable params: 1,062,785\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-19 01:13:05.435839: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - ETA: 0s - loss: 4.0798e-04"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-19 01:13:13.641227: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 9s 105ms/step - loss: 4.0798e-04 - val_loss: 3.1231e-04 - lr: 5.0000e-04\n",
      "Epoch 2/100\n",
      "80/80 [==============================] - 8s 105ms/step - loss: 2.9668e-04 - val_loss: 3.1038e-04 - lr: 5.0000e-04\n",
      "Epoch 3/100\n",
      "80/80 [==============================] - 8s 104ms/step - loss: 2.9044e-04 - val_loss: 3.0269e-04 - lr: 5.0000e-04\n",
      "Epoch 4/100\n",
      "80/80 [==============================] - 8s 106ms/step - loss: 2.7999e-04 - val_loss: 2.9885e-04 - lr: 5.0000e-04\n",
      "Epoch 5/100\n",
      "80/80 [==============================] - 8s 104ms/step - loss: 2.7176e-04 - val_loss: 2.9596e-04 - lr: 5.0000e-04\n",
      "Epoch 6/100\n",
      "80/80 [==============================] - 8s 104ms/step - loss: 2.6459e-04 - val_loss: 2.9356e-04 - lr: 5.0000e-04\n",
      "Epoch 7/100\n",
      "80/80 [==============================] - 8s 104ms/step - loss: 2.5680e-04 - val_loss: 2.8967e-04 - lr: 5.0000e-04\n",
      "Epoch 8/100\n",
      "80/80 [==============================] - 8s 104ms/step - loss: 2.4793e-04 - val_loss: 2.8538e-04 - lr: 5.0000e-04\n",
      "Epoch 9/100\n",
      "80/80 [==============================] - 8s 104ms/step - loss: 2.3817e-04 - val_loss: 2.8141e-04 - lr: 5.0000e-04\n",
      "Epoch 10/100\n",
      "80/80 [==============================] - 8s 104ms/step - loss: 2.2948e-04 - val_loss: 2.7683e-04 - lr: 5.0000e-04\n",
      "Epoch 11/100\n",
      "80/80 [==============================] - 8s 104ms/step - loss: 2.2106e-04 - val_loss: 2.7306e-04 - lr: 5.0000e-04\n",
      "Epoch 12/100\n",
      "80/80 [==============================] - 8s 104ms/step - loss: 2.1558e-04 - val_loss: 2.7060e-04 - lr: 5.0000e-04\n",
      "Epoch 13/100\n",
      "80/80 [==============================] - 8s 104ms/step - loss: 2.0906e-04 - val_loss: 2.7046e-04 - lr: 5.0000e-04\n",
      "Epoch 14/100\n",
      "80/80 [==============================] - 8s 104ms/step - loss: 2.0403e-04 - val_loss: 2.7006e-04 - lr: 5.0000e-04\n",
      "Epoch 15/100\n",
      "80/80 [==============================] - 8s 104ms/step - loss: 1.9961e-04 - val_loss: 2.7104e-04 - lr: 5.0000e-04\n",
      "Epoch 16/100\n",
      "80/80 [==============================] - 8s 105ms/step - loss: 1.9384e-04 - val_loss: 2.7100e-04 - lr: 5.0000e-04\n",
      "Epoch 17/100\n",
      "80/80 [==============================] - 8s 104ms/step - loss: 1.8893e-04 - val_loss: 2.7075e-04 - lr: 1.0000e-04\n",
      "Epoch 18/100\n",
      "80/80 [==============================] - 8s 105ms/step - loss: 1.8766e-04 - val_loss: 2.7088e-04 - lr: 1.0000e-04\n",
      "Epoch 19/100\n",
      "80/80 [==============================] - 8s 105ms/step - loss: 1.8673e-04 - val_loss: 2.7100e-04 - lr: 1.0000e-04\n",
      "Epoch 20/100\n",
      "80/80 [==============================] - 8s 105ms/step - loss: 1.8575e-04 - val_loss: 2.7145e-04 - lr: 1.0000e-04\n",
      "Epoch 21/100\n",
      "80/80 [==============================] - 8s 105ms/step - loss: 1.8470e-04 - val_loss: 2.7123e-04 - lr: 1.0000e-04\n",
      "New model saved\n"
     ]
    }
   ],
   "source": [
    "tf.keras.utils.set_random_seed(42)\n",
    "\n",
    "number_filters = 128\n",
    "number_conv_layers = 1\n",
    "dense_layer_units = 128\n",
    "batch_size = 10000\n",
    "model = build_model(number_filters, number_conv_layers, dense_layer_units) # initial 32, 4, 64 (64, 1, 64)\n",
    "x_train, y_train = load_dataset(BATCHES)\n",
    "\n",
    "model.compile(optimizer=optimizers.Adam(5e-4), loss='mean_squared_error')\n",
    "model.summary()\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=100,\n",
    "          verbose=1,\n",
    "          validation_split=0.2,\n",
    "          callbacks=[callbacks.ReduceLROnPlateau(monitor='val_loss', patience=5, min_delta=1e-5, factor=0.2),\n",
    "                     callbacks.EarlyStopping(monitor='val_loss', patience=10, min_delta=1e-5)])\n",
    "\n",
    "model.save(f'models/model_{number_filters}_filters_{number_conv_layers}_conv_layers_{dense_layer_units}_dense_units_{batch_size}_batch_size.h5')\n",
    "print('New model saved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_41\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_50 (InputLayer)       [(None, 12, 8, 8)]        0         \n",
      "                                                                 \n",
      " conv2d_77 (Conv2D)          (None, 128, 8, 8)         13952     \n",
      "                                                                 \n",
      " flatten_41 (Flatten)        (None, 8192)              0         \n",
      "                                                                 \n",
      " dense_81 (Dense)            (None, 128)               1048704   \n",
      "                                                                 \n",
      " dense_82 (Dense)            (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,062,785\n",
      "Trainable params: 1,062,785\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-19 01:16:58.541678: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - ETA: 0s - loss: 3.8220e-04"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-19 01:17:06.992032: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 9s 86ms/step - loss: 3.8220e-04 - val_loss: 3.1164e-04 - lr: 5.0000e-04\n",
      "Epoch 2/100\n",
      "100/100 [==============================] - 9s 85ms/step - loss: 2.9480e-04 - val_loss: 3.0598e-04 - lr: 5.0000e-04\n",
      "Epoch 3/100\n",
      "100/100 [==============================] - 8s 85ms/step - loss: 2.8271e-04 - val_loss: 2.9914e-04 - lr: 5.0000e-04\n",
      "Epoch 4/100\n",
      "100/100 [==============================] - 9s 85ms/step - loss: 2.7225e-04 - val_loss: 2.9587e-04 - lr: 5.0000e-04\n",
      "Epoch 5/100\n",
      "100/100 [==============================] - 8s 85ms/step - loss: 2.6318e-04 - val_loss: 2.9257e-04 - lr: 5.0000e-04\n",
      "Epoch 6/100\n",
      "100/100 [==============================] - 9s 85ms/step - loss: 2.5297e-04 - val_loss: 2.8696e-04 - lr: 5.0000e-04\n",
      "Epoch 7/100\n",
      "100/100 [==============================] - 8s 85ms/step - loss: 2.4159e-04 - val_loss: 2.8041e-04 - lr: 5.0000e-04\n",
      "Epoch 8/100\n",
      "100/100 [==============================] - 9s 85ms/step - loss: 2.2994e-04 - val_loss: 2.7657e-04 - lr: 5.0000e-04\n",
      "Epoch 9/100\n",
      "100/100 [==============================] - 9s 85ms/step - loss: 2.2159e-04 - val_loss: 2.7597e-04 - lr: 5.0000e-04\n",
      "Epoch 10/100\n",
      "100/100 [==============================] - 9s 87ms/step - loss: 2.1300e-04 - val_loss: 2.7258e-04 - lr: 5.0000e-04\n",
      "Epoch 11/100\n",
      "100/100 [==============================] - 9s 85ms/step - loss: 2.0675e-04 - val_loss: 2.7036e-04 - lr: 5.0000e-04\n",
      "Epoch 12/100\n",
      "100/100 [==============================] - 9s 85ms/step - loss: 2.0092e-04 - val_loss: 2.6941e-04 - lr: 5.0000e-04\n",
      "Epoch 13/100\n",
      "100/100 [==============================] - 9s 85ms/step - loss: 1.9509e-04 - val_loss: 2.7110e-04 - lr: 5.0000e-04\n",
      "Epoch 14/100\n",
      "100/100 [==============================] - 9s 87ms/step - loss: 1.8906e-04 - val_loss: 2.7049e-04 - lr: 1.0000e-04\n",
      "Epoch 15/100\n",
      "100/100 [==============================] - 9s 86ms/step - loss: 1.8780e-04 - val_loss: 2.7110e-04 - lr: 1.0000e-04\n",
      "Epoch 16/100\n",
      "100/100 [==============================] - 8s 85ms/step - loss: 1.8663e-04 - val_loss: 2.7176e-04 - lr: 1.0000e-04\n",
      "Epoch 17/100\n",
      "100/100 [==============================] - 9s 86ms/step - loss: 1.8556e-04 - val_loss: 2.7104e-04 - lr: 1.0000e-04\n",
      "Epoch 18/100\n",
      "100/100 [==============================] - 9s 85ms/step - loss: 1.8445e-04 - val_loss: 2.7135e-04 - lr: 1.0000e-04\n",
      "New model saved\n"
     ]
    }
   ],
   "source": [
    "tf.keras.utils.set_random_seed(42)\n",
    "\n",
    "number_filters = 128\n",
    "number_conv_layers = 1\n",
    "dense_layer_units = 128\n",
    "batch_size = 8000\n",
    "model = build_model(number_filters, number_conv_layers, dense_layer_units) # initial 32, 4, 64\n",
    "x_train, y_train = load_dataset(BATCHES)\n",
    "\n",
    "model.compile(optimizer=optimizers.Adam(5e-4), loss='mean_squared_error')\n",
    "model.summary()\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=100,\n",
    "          verbose=1,\n",
    "          validation_split=0.2,\n",
    "          callbacks=[callbacks.ReduceLROnPlateau(monitor='val_loss', patience=5, min_delta=1e-5, factor=0.2),\n",
    "                     callbacks.EarlyStopping(monitor='val_loss', patience=10, min_delta=1e-5)])\n",
    "\n",
    "model.save(f'models/model_{number_filters}_filters_{number_conv_layers}_conv_layers_{dense_layer_units}_dense_units_{batch_size}_batch_size.h5')\n",
    "print('New model saved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_49\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_58 (InputLayer)       [(None, 12, 8, 8)]        0         \n",
      "                                                                 \n",
      " conv2d_85 (Conv2D)          (None, 128, 8, 8)         13952     \n",
      "                                                                 \n",
      " flatten_49 (Flatten)        (None, 8192)              0         \n",
      "                                                                 \n",
      " dense_97 (Dense)            (None, 128)               1048704   \n",
      "                                                                 \n",
      " dense_98 (Dense)            (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,062,785\n",
      "Trainable params: 1,062,785\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-19 13:31:54.996950: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - ETA: 0s - loss: 8.0842e-05"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-19 13:32:03.426712: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 9s 87ms/step - loss: 8.0842e-05 - val_loss: 8.1856e-05 - lr: 5.0000e-05\n",
      "Epoch 2/100\n",
      "100/100 [==============================] - 8s 85ms/step - loss: 6.2314e-05 - val_loss: 7.6299e-05 - lr: 5.0000e-05\n",
      "Epoch 3/100\n",
      "100/100 [==============================] - 8s 85ms/step - loss: 5.8504e-05 - val_loss: 7.4135e-05 - lr: 5.0000e-05\n",
      "Epoch 4/100\n",
      "100/100 [==============================] - 9s 85ms/step - loss: 5.6997e-05 - val_loss: 7.3543e-05 - lr: 5.0000e-05\n",
      "Epoch 5/100\n",
      "100/100 [==============================] - 8s 85ms/step - loss: 5.6196e-05 - val_loss: 7.3289e-05 - lr: 5.0000e-05\n",
      "Epoch 6/100\n",
      "100/100 [==============================] - 9s 85ms/step - loss: 5.5534e-05 - val_loss: 7.3159e-05 - lr: 5.0000e-05\n",
      "Epoch 7/100\n",
      "100/100 [==============================] - 9s 85ms/step - loss: 5.4886e-05 - val_loss: 7.3055e-05 - lr: 5.0000e-05\n",
      "Epoch 8/100\n",
      "100/100 [==============================] - 9s 85ms/step - loss: 5.4243e-05 - val_loss: 7.3072e-05 - lr: 5.0000e-05\n",
      "Epoch 9/100\n",
      "100/100 [==============================] - 9s 85ms/step - loss: 5.3592e-05 - val_loss: 7.2943e-05 - lr: 5.0000e-05\n",
      "Epoch 10/100\n",
      "100/100 [==============================] - 9s 85ms/step - loss: 5.2962e-05 - val_loss: 7.2959e-05 - lr: 5.0000e-05\n",
      "Epoch 11/100\n",
      "100/100 [==============================] - 9s 85ms/step - loss: 5.2313e-05 - val_loss: 7.2885e-05 - lr: 5.0000e-05\n",
      "Epoch 12/100\n",
      "100/100 [==============================] - 8s 85ms/step - loss: 5.1652e-05 - val_loss: 7.2963e-05 - lr: 5.0000e-05\n",
      "Epoch 13/100\n",
      "100/100 [==============================] - 8s 85ms/step - loss: 5.0990e-05 - val_loss: 7.2890e-05 - lr: 5.0000e-05\n",
      "Epoch 14/100\n",
      "100/100 [==============================] - 9s 86ms/step - loss: 5.0302e-05 - val_loss: 7.2856e-05 - lr: 5.0000e-05\n",
      "Epoch 15/100\n",
      "100/100 [==============================] - 9s 86ms/step - loss: 4.9614e-05 - val_loss: 7.2924e-05 - lr: 5.0000e-05\n",
      "Epoch 16/100\n",
      "100/100 [==============================] - 9s 86ms/step - loss: 4.8941e-05 - val_loss: 7.2882e-05 - lr: 5.0000e-05\n",
      "Epoch 17/100\n",
      "100/100 [==============================] - 9s 85ms/step - loss: 4.8263e-05 - val_loss: 7.2951e-05 - lr: 5.0000e-05\n",
      "Epoch 18/100\n",
      "100/100 [==============================] - 9s 86ms/step - loss: 4.7706e-05 - val_loss: 7.2886e-05 - lr: 1.0000e-05\n",
      "Epoch 19/100\n",
      "100/100 [==============================] - 9s 85ms/step - loss: 4.7549e-05 - val_loss: 7.2889e-05 - lr: 1.0000e-05\n",
      "Epoch 20/100\n",
      "100/100 [==============================] - 8s 85ms/step - loss: 4.7401e-05 - val_loss: 7.2908e-05 - lr: 1.0000e-05\n",
      "Epoch 21/100\n",
      "100/100 [==============================] - 9s 85ms/step - loss: 4.7253e-05 - val_loss: 7.2932e-05 - lr: 1.0000e-05\n",
      "Epoch 22/100\n",
      "100/100 [==============================] - 9s 85ms/step - loss: 4.7111e-05 - val_loss: 7.2870e-05 - lr: 1.0000e-05\n",
      "Epoch 23/100\n",
      "100/100 [==============================] - 9s 85ms/step - loss: 4.6962e-05 - val_loss: 7.2923e-05 - lr: 1.0000e-05\n",
      "Epoch 24/100\n",
      "100/100 [==============================] - 9s 85ms/step - loss: 4.6815e-05 - val_loss: 7.2926e-05 - lr: 1.0000e-05\n",
      "Epoch 25/100\n",
      "100/100 [==============================] - 9s 85ms/step - loss: 4.6660e-05 - val_loss: 7.2914e-05 - lr: 1.0000e-05\n",
      "Epoch 26/100\n",
      "100/100 [==============================] - 8s 85ms/step - loss: 4.6509e-05 - val_loss: 7.2939e-05 - lr: 1.0000e-05\n",
      "Epoch 27/100\n",
      "100/100 [==============================] - 8s 85ms/step - loss: 4.6358e-05 - val_loss: 7.2938e-05 - lr: 1.0000e-05\n",
      "New model saved\n"
     ]
    }
   ],
   "source": [
    "tf.keras.utils.set_random_seed(42)\n",
    "\n",
    "number_filters = 128\n",
    "number_conv_layers = 1\n",
    "dense_layer_units = 128\n",
    "batch_size = 8000\n",
    "stockfish_depth = 5\n",
    "model = build_model(number_filters, number_conv_layers, dense_layer_units) # initial 32, 4, 64\n",
    "x_train, y_train = load_dataset(batches=BATCHES, stockfish_depth=stockfish_depth)\n",
    "\n",
    "model.compile(optimizer=optimizers.Adam(5e-5), loss='mean_squared_error')\n",
    "model.summary()\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=100,\n",
    "          verbose=1,\n",
    "          validation_split=0.2,\n",
    "          callbacks=[callbacks.ReduceLROnPlateau(monitor='val_loss', patience=10, min_delta=1e-6, factor=0.2),\n",
    "                     callbacks.EarlyStopping(monitor='val_loss', patience=20, min_delta=1e-6)])\n",
    "\n",
    "model.save(f'models/model_{number_filters}_filters_{number_conv_layers}_conv_layers_{dense_layer_units}_dense_units_{batch_size}_batch_size_{stockfish_depth}_depth.h5')\n",
    "print('New model saved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_48\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_57 (InputLayer)       [(None, 12, 8, 8)]        0         \n",
      "                                                                 \n",
      " conv2d_84 (Conv2D)          (None, 128, 8, 8)         13952     \n",
      "                                                                 \n",
      " flatten_48 (Flatten)        (None, 8192)              0         \n",
      "                                                                 \n",
      " dense_95 (Dense)            (None, 128)               1048704   \n",
      "                                                                 \n",
      " dense_96 (Dense)            (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,062,785\n",
      "Trainable params: 1,062,785\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "  1/100 [..............................] - ETA: 28s - loss: 1.4715e-04"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-19 13:24:25.785079: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - ETA: 0s - loss: 5.3652e-05"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-19 13:24:34.220126: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 9s 87ms/step - loss: 5.3652e-05 - val_loss: 4.9656e-05 - lr: 5.0000e-05\n",
      "Epoch 2/100\n",
      "100/100 [==============================] - 9s 86ms/step - loss: 3.4979e-05 - val_loss: 4.3816e-05 - lr: 5.0000e-05\n",
      "Epoch 3/100\n",
      "100/100 [==============================] - 9s 86ms/step - loss: 3.1110e-05 - val_loss: 4.1634e-05 - lr: 5.0000e-05\n",
      "Epoch 4/100\n",
      "100/100 [==============================] - 9s 86ms/step - loss: 2.9828e-05 - val_loss: 4.1011e-05 - lr: 5.0000e-05\n",
      "Epoch 5/100\n",
      "100/100 [==============================] - 9s 87ms/step - loss: 2.9308e-05 - val_loss: 4.0696e-05 - lr: 5.0000e-05\n",
      "Epoch 6/100\n",
      "100/100 [==============================] - 9s 86ms/step - loss: 2.8947e-05 - val_loss: 4.0504e-05 - lr: 5.0000e-05\n",
      "Epoch 7/100\n",
      "100/100 [==============================] - 9s 86ms/step - loss: 2.8644e-05 - val_loss: 4.0350e-05 - lr: 5.0000e-05\n",
      "Epoch 8/100\n",
      "100/100 [==============================] - 9s 86ms/step - loss: 2.8368e-05 - val_loss: 4.0267e-05 - lr: 5.0000e-05\n",
      "Epoch 9/100\n",
      "100/100 [==============================] - 9s 87ms/step - loss: 2.8112e-05 - val_loss: 4.0182e-05 - lr: 5.0000e-05\n",
      "Epoch 10/100\n",
      "100/100 [==============================] - 9s 86ms/step - loss: 2.7870e-05 - val_loss: 4.0121e-05 - lr: 5.0000e-05\n",
      "Epoch 11/100\n",
      "100/100 [==============================] - 9s 87ms/step - loss: 2.7632e-05 - val_loss: 4.0051e-05 - lr: 5.0000e-05\n",
      "Epoch 12/100\n",
      "100/100 [==============================] - 9s 86ms/step - loss: 2.7401e-05 - val_loss: 4.0025e-05 - lr: 5.0000e-05\n",
      "Epoch 13/100\n",
      "100/100 [==============================] - 9s 86ms/step - loss: 2.7169e-05 - val_loss: 3.9988e-05 - lr: 5.0000e-05\n",
      "Epoch 14/100\n",
      "100/100 [==============================] - 9s 87ms/step - loss: 2.6933e-05 - val_loss: 3.9950e-05 - lr: 5.0000e-05\n",
      "Epoch 15/100\n",
      "100/100 [==============================] - 9s 87ms/step - loss: 2.6703e-05 - val_loss: 3.9936e-05 - lr: 5.0000e-05\n",
      "Epoch 16/100\n",
      "100/100 [==============================] - 9s 87ms/step - loss: 2.6476e-05 - val_loss: 3.9905e-05 - lr: 5.0000e-05\n",
      "Epoch 17/100\n",
      "100/100 [==============================] - 9s 87ms/step - loss: 2.6298e-05 - val_loss: 3.9893e-05 - lr: 1.0000e-05\n",
      "Epoch 18/100\n",
      "100/100 [==============================] - 9s 87ms/step - loss: 2.6250e-05 - val_loss: 3.9896e-05 - lr: 1.0000e-05\n",
      "Epoch 19/100\n",
      "100/100 [==============================] - 9s 87ms/step - loss: 2.6202e-05 - val_loss: 3.9896e-05 - lr: 1.0000e-05\n",
      "Epoch 20/100\n",
      "100/100 [==============================] - 9s 90ms/step - loss: 2.6155e-05 - val_loss: 3.9895e-05 - lr: 1.0000e-05\n",
      "Epoch 21/100\n",
      "100/100 [==============================] - 9s 90ms/step - loss: 2.6106e-05 - val_loss: 3.9902e-05 - lr: 1.0000e-05\n",
      "Epoch 22/100\n",
      "100/100 [==============================] - 9s 88ms/step - loss: 2.6058e-05 - val_loss: 3.9877e-05 - lr: 1.0000e-05\n",
      "Epoch 23/100\n",
      "100/100 [==============================] - 9s 87ms/step - loss: 2.6008e-05 - val_loss: 3.9885e-05 - lr: 1.0000e-05\n",
      "Epoch 24/100\n",
      "100/100 [==============================] - 9s 86ms/step - loss: 2.5958e-05 - val_loss: 3.9885e-05 - lr: 1.0000e-05\n",
      "Epoch 25/100\n",
      "100/100 [==============================] - 9s 86ms/step - loss: 2.5910e-05 - val_loss: 3.9875e-05 - lr: 1.0000e-05\n",
      "Epoch 26/100\n",
      "100/100 [==============================] - 9s 86ms/step - loss: 2.5857e-05 - val_loss: 3.9875e-05 - lr: 1.0000e-05\n",
      "New model saved\n"
     ]
    }
   ],
   "source": [
    "tf.keras.utils.set_random_seed(42)\n",
    "\n",
    "number_filters = 128\n",
    "number_conv_layers = 1\n",
    "dense_layer_units = 128\n",
    "batch_size = 8000\n",
    "stockfish_depth = 0\n",
    "model = build_model(number_filters, number_conv_layers, dense_layer_units) # initial 32, 4, 64\n",
    "x_train, y_train = load_dataset(batches=BATCHES, stockfish_depth=stockfish_depth)\n",
    "\n",
    "model.compile(optimizer=optimizers.Adam(5e-5), loss='mean_squared_error')\n",
    "model.summary()\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=100,\n",
    "          verbose=1,\n",
    "          validation_split=0.2,\n",
    "          callbacks=[callbacks.ReduceLROnPlateau(monitor='val_loss', patience=10, min_delta=1e-6, factor=0.2),\n",
    "                     callbacks.EarlyStopping(monitor='val_loss', patience=20, min_delta=1e-6)])\n",
    "\n",
    "model.save(f'models/model_{number_filters}_filters_{number_conv_layers}_conv_layers_{dense_layer_units}_dense_units_{batch_size}_batch_size_{stockfish_depth}_depth.h5')\n",
    "print('New model saved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_50\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_59 (InputLayer)       [(None, 12, 8, 8)]        0         \n",
      "                                                                 \n",
      " conv2d_86 (Conv2D)          (None, 128, 8, 8)         13952     \n",
      "                                                                 \n",
      " flatten_50 (Flatten)        (None, 8192)              0         \n",
      "                                                                 \n",
      " dense_99 (Dense)            (None, 128)               1048704   \n",
      "                                                                 \n",
      " dense_100 (Dense)           (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,062,785\n",
      "Trainable params: 1,062,785\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-19 14:28:30.474263: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - ETA: 0s - loss: 5.3652e-05"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-19 14:28:38.990988: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 9s 86ms/step - loss: 5.3652e-05 - val_loss: 4.9656e-05 - lr: 5.0000e-05\n",
      "Epoch 2/100\n",
      "100/100 [==============================] - 9s 86ms/step - loss: 3.4979e-05 - val_loss: 4.3816e-05 - lr: 5.0000e-05\n",
      "Epoch 3/100\n",
      "100/100 [==============================] - 9s 86ms/step - loss: 3.1110e-05 - val_loss: 4.1634e-05 - lr: 5.0000e-05\n",
      "Epoch 4/100\n",
      "100/100 [==============================] - 9s 85ms/step - loss: 2.9828e-05 - val_loss: 4.1011e-05 - lr: 5.0000e-05\n",
      "Epoch 5/100\n",
      "100/100 [==============================] - 9s 85ms/step - loss: 2.9308e-05 - val_loss: 4.0696e-05 - lr: 5.0000e-05\n",
      "Epoch 6/100\n",
      "100/100 [==============================] - 9s 85ms/step - loss: 2.8947e-05 - val_loss: 4.0504e-05 - lr: 5.0000e-05\n",
      "Epoch 7/100\n",
      "100/100 [==============================] - 9s 86ms/step - loss: 2.8644e-05 - val_loss: 4.0350e-05 - lr: 5.0000e-05\n",
      "Epoch 8/100\n",
      "100/100 [==============================] - 9s 86ms/step - loss: 2.8368e-05 - val_loss: 4.0267e-05 - lr: 5.0000e-05\n",
      "Epoch 9/100\n",
      "100/100 [==============================] - 9s 86ms/step - loss: 2.8112e-05 - val_loss: 4.0182e-05 - lr: 5.0000e-05\n",
      "Epoch 10/100\n",
      "100/100 [==============================] - 9s 86ms/step - loss: 2.7870e-05 - val_loss: 4.0121e-05 - lr: 5.0000e-05\n",
      "Epoch 11/100\n",
      "100/100 [==============================] - 9s 86ms/step - loss: 2.7632e-05 - val_loss: 4.0051e-05 - lr: 5.0000e-05\n",
      "Epoch 12/100\n",
      "100/100 [==============================] - 9s 86ms/step - loss: 2.7401e-05 - val_loss: 4.0025e-05 - lr: 5.0000e-05\n",
      "Epoch 13/100\n",
      "100/100 [==============================] - 9s 86ms/step - loss: 2.7169e-05 - val_loss: 3.9988e-05 - lr: 5.0000e-05\n",
      "Epoch 14/100\n",
      "100/100 [==============================] - 9s 86ms/step - loss: 2.6933e-05 - val_loss: 3.9950e-05 - lr: 5.0000e-05\n",
      "Epoch 15/100\n",
      "100/100 [==============================] - 9s 86ms/step - loss: 2.6703e-05 - val_loss: 3.9936e-05 - lr: 5.0000e-05\n",
      "Epoch 16/100\n",
      "100/100 [==============================] - 9s 86ms/step - loss: 2.6476e-05 - val_loss: 3.9905e-05 - lr: 5.0000e-05\n",
      "Epoch 17/100\n",
      "100/100 [==============================] - 9s 86ms/step - loss: 2.6298e-05 - val_loss: 3.9893e-05 - lr: 1.0000e-05\n",
      "Epoch 18/100\n",
      "100/100 [==============================] - 9s 86ms/step - loss: 2.6250e-05 - val_loss: 3.9896e-05 - lr: 1.0000e-05\n",
      "Epoch 19/100\n",
      "100/100 [==============================] - 9s 86ms/step - loss: 2.6202e-05 - val_loss: 3.9896e-05 - lr: 1.0000e-05\n",
      "Epoch 20/100\n",
      "100/100 [==============================] - 9s 86ms/step - loss: 2.6155e-05 - val_loss: 3.9895e-05 - lr: 1.0000e-05\n",
      "Epoch 21/100\n",
      "100/100 [==============================] - 9s 86ms/step - loss: 2.6106e-05 - val_loss: 3.9902e-05 - lr: 1.0000e-05\n",
      "Epoch 22/100\n",
      "100/100 [==============================] - 9s 86ms/step - loss: 2.6058e-05 - val_loss: 3.9877e-05 - lr: 1.0000e-05\n",
      "Epoch 23/100\n",
      "100/100 [==============================] - 9s 86ms/step - loss: 2.6008e-05 - val_loss: 3.9885e-05 - lr: 1.0000e-05\n",
      "Epoch 24/100\n",
      "100/100 [==============================] - 9s 86ms/step - loss: 2.5958e-05 - val_loss: 3.9885e-05 - lr: 1.0000e-05\n",
      "Epoch 25/100\n",
      "100/100 [==============================] - 9s 86ms/step - loss: 2.5910e-05 - val_loss: 3.9875e-05 - lr: 1.0000e-05\n",
      "Epoch 26/100\n",
      "100/100 [==============================] - 9s 86ms/step - loss: 2.5857e-05 - val_loss: 3.9875e-05 - lr: 1.0000e-05\n",
      "New model saved\n"
     ]
    }
   ],
   "source": [
    "tf.keras.utils.set_random_seed(42)\n",
    "\n",
    "number_filters = 128\n",
    "number_conv_layers = 1\n",
    "dense_layer_units = 128\n",
    "batch_size = 8000\n",
    "stockfish_depth = 1\n",
    "model = build_model(number_filters, number_conv_layers, dense_layer_units) # initial 32, 4, 64\n",
    "x_train, y_train = load_dataset(batches=BATCHES, stockfish_depth=stockfish_depth)\n",
    "\n",
    "model.compile(optimizer=optimizers.Adam(5e-5), loss='mean_squared_error')\n",
    "model.summary()\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=100,\n",
    "          verbose=1,\n",
    "          validation_split=0.2,\n",
    "          callbacks=[callbacks.ReduceLROnPlateau(monitor='val_loss', patience=10, min_delta=1e-6, factor=0.2),\n",
    "                     callbacks.EarlyStopping(monitor='val_loss', patience=20, min_delta=1e-6)])\n",
    "\n",
    "model.save(f'models/model_{number_filters}_filters_{number_conv_layers}_conv_layers_{dense_layer_units}_dense_units_{batch_size}_batch_size_{stockfish_depth}_depth.h5')\n",
    "print('New model saved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_51\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_60 (InputLayer)       [(None, 12, 8, 8)]        0         \n",
      "                                                                 \n",
      " conv2d_87 (Conv2D)          (None, 128, 8, 8)         13952     \n",
      "                                                                 \n",
      " flatten_51 (Flatten)        (None, 8192)              0         \n",
      "                                                                 \n",
      " dense_101 (Dense)           (None, 128)               1048704   \n",
      "                                                                 \n",
      " dense_102 (Dense)           (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,062,785\n",
      "Trainable params: 1,062,785\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-19 14:53:37.241800: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - ETA: 0s - loss: 6.8263e-05"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-19 14:53:45.695607: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 9s 86ms/step - loss: 6.8263e-05 - val_loss: 6.5184e-05 - lr: 5.0000e-05\n",
      "Epoch 2/100\n",
      "100/100 [==============================] - 9s 86ms/step - loss: 4.9553e-05 - val_loss: 5.9452e-05 - lr: 5.0000e-05\n",
      "Epoch 3/100\n",
      "100/100 [==============================] - 8s 85ms/step - loss: 4.5632e-05 - val_loss: 5.7199e-05 - lr: 5.0000e-05\n",
      "Epoch 4/100\n",
      "100/100 [==============================] - 9s 86ms/step - loss: 4.4296e-05 - val_loss: 5.6657e-05 - lr: 5.0000e-05\n",
      "Epoch 5/100\n",
      "100/100 [==============================] - 9s 86ms/step - loss: 4.3746e-05 - val_loss: 5.6382e-05 - lr: 5.0000e-05\n",
      "Epoch 6/100\n",
      "100/100 [==============================] - 9s 86ms/step - loss: 4.3344e-05 - val_loss: 5.6237e-05 - lr: 5.0000e-05\n",
      "Epoch 7/100\n",
      "100/100 [==============================] - 9s 86ms/step - loss: 4.2977e-05 - val_loss: 5.6119e-05 - lr: 5.0000e-05\n",
      "Epoch 8/100\n",
      "100/100 [==============================] - 9s 86ms/step - loss: 4.2638e-05 - val_loss: 5.6071e-05 - lr: 5.0000e-05\n",
      "Epoch 9/100\n",
      "100/100 [==============================] - 9s 86ms/step - loss: 4.2307e-05 - val_loss: 5.5973e-05 - lr: 5.0000e-05\n",
      "Epoch 10/100\n",
      "100/100 [==============================] - 9s 86ms/step - loss: 4.1992e-05 - val_loss: 5.5979e-05 - lr: 5.0000e-05\n",
      "Epoch 11/100\n",
      "100/100 [==============================] - 9s 86ms/step - loss: 4.1675e-05 - val_loss: 5.5911e-05 - lr: 5.0000e-05\n",
      "Epoch 12/100\n",
      "100/100 [==============================] - 9s 86ms/step - loss: 4.1367e-05 - val_loss: 5.5929e-05 - lr: 5.0000e-05\n",
      "Epoch 13/100\n",
      "100/100 [==============================] - 9s 86ms/step - loss: 4.1060e-05 - val_loss: 5.5888e-05 - lr: 5.0000e-05\n",
      "Epoch 14/100\n",
      "100/100 [==============================] - 9s 86ms/step - loss: 4.0739e-05 - val_loss: 5.5885e-05 - lr: 5.0000e-05\n",
      "Epoch 15/100\n",
      "100/100 [==============================] - 9s 86ms/step - loss: 4.0439e-05 - val_loss: 5.5908e-05 - lr: 5.0000e-05\n",
      "Epoch 16/100\n",
      "100/100 [==============================] - 9s 86ms/step - loss: 4.0130e-05 - val_loss: 5.5889e-05 - lr: 5.0000e-05\n",
      "Epoch 17/100\n",
      "100/100 [==============================] - 9s 86ms/step - loss: 3.9838e-05 - val_loss: 5.5891e-05 - lr: 5.0000e-05\n",
      "Epoch 18/100\n",
      "100/100 [==============================] - 9s 86ms/step - loss: 3.9588e-05 - val_loss: 5.5877e-05 - lr: 1.0000e-05\n",
      "Epoch 19/100\n",
      "100/100 [==============================] - 9s 86ms/step - loss: 3.9524e-05 - val_loss: 5.5895e-05 - lr: 1.0000e-05\n",
      "Epoch 20/100\n",
      "100/100 [==============================] - 9s 86ms/step - loss: 3.9461e-05 - val_loss: 5.5914e-05 - lr: 1.0000e-05\n",
      "Epoch 21/100\n",
      "100/100 [==============================] - 9s 86ms/step - loss: 3.9398e-05 - val_loss: 5.5910e-05 - lr: 1.0000e-05\n",
      "Epoch 22/100\n",
      "100/100 [==============================] - 9s 86ms/step - loss: 3.9337e-05 - val_loss: 5.5893e-05 - lr: 1.0000e-05\n",
      "Epoch 23/100\n",
      "100/100 [==============================] - 9s 86ms/step - loss: 3.9273e-05 - val_loss: 5.5906e-05 - lr: 1.0000e-05\n",
      "Epoch 24/100\n",
      "100/100 [==============================] - 9s 86ms/step - loss: 3.9209e-05 - val_loss: 5.5908e-05 - lr: 1.0000e-05\n",
      "Epoch 25/100\n",
      "100/100 [==============================] - 9s 86ms/step - loss: 3.9148e-05 - val_loss: 5.5919e-05 - lr: 1.0000e-05\n",
      "Epoch 26/100\n",
      "100/100 [==============================] - 9s 86ms/step - loss: 3.9081e-05 - val_loss: 5.5922e-05 - lr: 1.0000e-05\n",
      "Epoch 27/100\n",
      "100/100 [==============================] - 9s 86ms/step - loss: 3.9017e-05 - val_loss: 5.5919e-05 - lr: 1.0000e-05\n",
      "New model saved\n"
     ]
    }
   ],
   "source": [
    "tf.keras.utils.set_random_seed(42)\n",
    "\n",
    "number_filters = 128\n",
    "number_conv_layers = 1\n",
    "dense_layer_units = 128\n",
    "batch_size = 8000\n",
    "stockfish_depth = 2\n",
    "model = build_model(number_filters, number_conv_layers, dense_layer_units) # initial 32, 4, 64\n",
    "x_train, y_train = load_dataset(batches=BATCHES, stockfish_depth=stockfish_depth)\n",
    "\n",
    "model.compile(optimizer=optimizers.Adam(5e-5), loss='mean_squared_error')\n",
    "model.summary()\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=100,\n",
    "          verbose=1,\n",
    "          validation_split=0.2,\n",
    "          callbacks=[callbacks.ReduceLROnPlateau(monitor='val_loss', patience=10, min_delta=1e-6, factor=0.2),\n",
    "                     callbacks.EarlyStopping(monitor='val_loss', patience=20, min_delta=1e-6)])\n",
    "\n",
    "model.save(f'models/model_{number_filters}_filters_{number_conv_layers}_conv_layers_{dense_layer_units}_dense_units_{batch_size}_batch_size_{stockfish_depth}_depth.h5')\n",
    "print('New model saved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_54\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_63 (InputLayer)       [(None, 12, 8, 8)]        0         \n",
      "                                                                 \n",
      " conv2d_90 (Conv2D)          (None, 128, 8, 8)         13952     \n",
      "                                                                 \n",
      " flatten_54 (Flatten)        (None, 8192)              0         \n",
      "                                                                 \n",
      " dense_107 (Dense)           (None, 128)               1048704   \n",
      "                                                                 \n",
      " dense_108 (Dense)           (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,062,785\n",
      "Trainable params: 1,062,785\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-19 15:15:14.623746: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150/150 [==============================] - ETA: 0s - loss: 0.0042"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-19 15:15:27.042520: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150/150 [==============================] - 13s 86ms/step - loss: 0.0042 - val_loss: 0.0039 - lr: 5.0000e-04\n",
      "Epoch 2/100\n",
      "150/150 [==============================] - 12s 83ms/step - loss: 0.0015 - val_loss: 7.8013e-04 - lr: 5.0000e-04\n",
      "Epoch 3/100\n",
      "150/150 [==============================] - 13s 84ms/step - loss: 9.0560e-04 - val_loss: 7.1260e-04 - lr: 5.0000e-04\n",
      "Epoch 4/100\n",
      "150/150 [==============================] - 13s 84ms/step - loss: 8.5545e-04 - val_loss: 6.6856e-04 - lr: 5.0000e-04\n",
      "Epoch 5/100\n",
      "150/150 [==============================] - 13s 84ms/step - loss: 8.2229e-04 - val_loss: 6.1553e-04 - lr: 5.0000e-04\n",
      "Epoch 6/100\n",
      "150/150 [==============================] - 13s 84ms/step - loss: 8.0149e-04 - val_loss: 6.1844e-04 - lr: 5.0000e-04\n",
      "Epoch 7/100\n",
      "150/150 [==============================] - 13s 84ms/step - loss: 7.8454e-04 - val_loss: 5.9312e-04 - lr: 5.0000e-04\n",
      "Epoch 8/100\n",
      "150/150 [==============================] - 13s 84ms/step - loss: 7.7255e-04 - val_loss: 5.8722e-04 - lr: 5.0000e-04\n",
      "Epoch 9/100\n",
      "150/150 [==============================] - 13s 84ms/step - loss: 7.6290e-04 - val_loss: 5.8852e-04 - lr: 5.0000e-04\n",
      "Epoch 10/100\n",
      "150/150 [==============================] - 13s 84ms/step - loss: 7.5659e-04 - val_loss: 5.6628e-04 - lr: 5.0000e-04\n",
      "Epoch 11/100\n",
      "150/150 [==============================] - 13s 84ms/step - loss: 7.4805e-04 - val_loss: 5.6343e-04 - lr: 5.0000e-04\n",
      "Epoch 12/100\n",
      "150/150 [==============================] - 13s 84ms/step - loss: 7.4164e-04 - val_loss: 5.6735e-04 - lr: 5.0000e-04\n",
      "Epoch 13/100\n",
      "150/150 [==============================] - 13s 84ms/step - loss: 7.3756e-04 - val_loss: 5.6185e-04 - lr: 5.0000e-04\n",
      "Epoch 14/100\n",
      "150/150 [==============================] - 13s 84ms/step - loss: 7.3337e-04 - val_loss: 5.4992e-04 - lr: 5.0000e-04\n",
      "Epoch 15/100\n",
      "150/150 [==============================] - 13s 84ms/step - loss: 7.2868e-04 - val_loss: 5.5728e-04 - lr: 5.0000e-04\n",
      "Epoch 16/100\n",
      "150/150 [==============================] - 13s 84ms/step - loss: 7.2491e-04 - val_loss: 5.6921e-04 - lr: 5.0000e-04\n",
      "Epoch 17/100\n",
      "150/150 [==============================] - 13s 84ms/step - loss: 7.2184e-04 - val_loss: 5.6017e-04 - lr: 5.0000e-04\n",
      "Epoch 18/100\n",
      "150/150 [==============================] - 13s 84ms/step - loss: 7.1847e-04 - val_loss: 5.6795e-04 - lr: 5.0000e-04\n",
      "Epoch 19/100\n",
      "150/150 [==============================] - 13s 84ms/step - loss: 7.1500e-04 - val_loss: 5.5331e-04 - lr: 5.0000e-04\n",
      "Epoch 20/100\n",
      "150/150 [==============================] - 13s 84ms/step - loss: 7.1142e-04 - val_loss: 5.6673e-04 - lr: 5.0000e-04\n",
      "Epoch 21/100\n",
      "150/150 [==============================] - 13s 84ms/step - loss: 7.0989e-04 - val_loss: 5.5190e-04 - lr: 5.0000e-04\n",
      "Epoch 22/100\n",
      "150/150 [==============================] - 13s 84ms/step - loss: 7.0685e-04 - val_loss: 5.5422e-04 - lr: 5.0000e-04\n",
      "Epoch 23/100\n",
      "150/150 [==============================] - 13s 84ms/step - loss: 7.0372e-04 - val_loss: 5.6315e-04 - lr: 5.0000e-04\n",
      "Epoch 24/100\n",
      "150/150 [==============================] - 13s 84ms/step - loss: 6.9485e-04 - val_loss: 5.6146e-04 - lr: 5.0000e-04\n",
      "Epoch 25/100\n",
      "150/150 [==============================] - 13s 84ms/step - loss: 6.6559e-04 - val_loss: 5.3563e-04 - lr: 1.0000e-04\n",
      "Epoch 26/100\n",
      "150/150 [==============================] - 13s 84ms/step - loss: 6.5427e-04 - val_loss: 5.4003e-04 - lr: 1.0000e-04\n",
      "Epoch 27/100\n",
      "150/150 [==============================] - 13s 84ms/step - loss: 6.4316e-04 - val_loss: 5.3170e-04 - lr: 1.0000e-04\n",
      "Epoch 28/100\n",
      "150/150 [==============================] - 13s 84ms/step - loss: 6.3194e-04 - val_loss: 5.2516e-04 - lr: 1.0000e-04\n",
      "Epoch 29/100\n",
      "150/150 [==============================] - 13s 84ms/step - loss: 6.2080e-04 - val_loss: 5.3141e-04 - lr: 1.0000e-04\n",
      "Epoch 30/100\n",
      "150/150 [==============================] - 13s 84ms/step - loss: 6.1007e-04 - val_loss: 5.2261e-04 - lr: 1.0000e-04\n",
      "Epoch 31/100\n",
      "150/150 [==============================] - 13s 84ms/step - loss: 6.0053e-04 - val_loss: 5.2365e-04 - lr: 1.0000e-04\n",
      "Epoch 32/100\n",
      "150/150 [==============================] - 13s 84ms/step - loss: 5.9102e-04 - val_loss: 5.2095e-04 - lr: 1.0000e-04\n",
      "Epoch 33/100\n",
      "150/150 [==============================] - 13s 84ms/step - loss: 5.8279e-04 - val_loss: 5.1885e-04 - lr: 1.0000e-04\n",
      "Epoch 34/100\n",
      "150/150 [==============================] - 13s 84ms/step - loss: 5.7469e-04 - val_loss: 5.1777e-04 - lr: 1.0000e-04\n",
      "Epoch 35/100\n",
      "150/150 [==============================] - 13s 84ms/step - loss: 5.6733e-04 - val_loss: 5.1345e-04 - lr: 1.0000e-04\n",
      "Epoch 36/100\n",
      "150/150 [==============================] - 13s 84ms/step - loss: 5.6103e-04 - val_loss: 5.1745e-04 - lr: 1.0000e-04\n",
      "Epoch 37/100\n",
      "150/150 [==============================] - 13s 84ms/step - loss: 5.5412e-04 - val_loss: 5.1377e-04 - lr: 1.0000e-04\n",
      "Epoch 38/100\n",
      "150/150 [==============================] - 13s 84ms/step - loss: 5.4781e-04 - val_loss: 5.0790e-04 - lr: 1.0000e-04\n",
      "Epoch 39/100\n",
      "150/150 [==============================] - 13s 84ms/step - loss: 5.4194e-04 - val_loss: 5.1126e-04 - lr: 1.0000e-04\n",
      "Epoch 40/100\n",
      "150/150 [==============================] - 13s 84ms/step - loss: 5.3659e-04 - val_loss: 5.0858e-04 - lr: 1.0000e-04\n",
      "Epoch 41/100\n",
      "150/150 [==============================] - 13s 84ms/step - loss: 5.3103e-04 - val_loss: 5.0676e-04 - lr: 1.0000e-04\n",
      "Epoch 42/100\n",
      "150/150 [==============================] - 13s 84ms/step - loss: 5.2590e-04 - val_loss: 5.0741e-04 - lr: 1.0000e-04\n",
      "Epoch 43/100\n",
      "150/150 [==============================] - 13s 84ms/step - loss: 5.2035e-04 - val_loss: 5.0165e-04 - lr: 1.0000e-04\n",
      "Epoch 44/100\n",
      "150/150 [==============================] - 13s 84ms/step - loss: 5.1456e-04 - val_loss: 5.0010e-04 - lr: 1.0000e-04\n",
      "Epoch 45/100\n",
      "150/150 [==============================] - 13s 84ms/step - loss: 5.0911e-04 - val_loss: 4.9761e-04 - lr: 1.0000e-04\n",
      "Epoch 46/100\n",
      "150/150 [==============================] - 13s 84ms/step - loss: 5.0500e-04 - val_loss: 5.1008e-04 - lr: 1.0000e-04\n",
      "Epoch 47/100\n",
      "150/150 [==============================] - 13s 84ms/step - loss: 5.0047e-04 - val_loss: 4.9969e-04 - lr: 1.0000e-04\n",
      "Epoch 48/100\n",
      "150/150 [==============================] - 13s 84ms/step - loss: 4.9664e-04 - val_loss: 4.9902e-04 - lr: 1.0000e-04\n",
      "Epoch 49/100\n",
      "150/150 [==============================] - 13s 84ms/step - loss: 4.9264e-04 - val_loss: 5.0255e-04 - lr: 1.0000e-04\n",
      "Epoch 50/100\n",
      "150/150 [==============================] - 13s 84ms/step - loss: 4.8950e-04 - val_loss: 5.0337e-04 - lr: 1.0000e-04\n",
      "Epoch 51/100\n",
      "150/150 [==============================] - 13s 84ms/step - loss: 4.8618e-04 - val_loss: 4.9883e-04 - lr: 1.0000e-04\n",
      "Epoch 52/100\n",
      "150/150 [==============================] - 13s 84ms/step - loss: 4.8276e-04 - val_loss: 4.9855e-04 - lr: 1.0000e-04\n",
      "Epoch 53/100\n",
      "150/150 [==============================] - 13s 84ms/step - loss: 4.7944e-04 - val_loss: 5.0993e-04 - lr: 1.0000e-04\n",
      "Epoch 54/100\n",
      "150/150 [==============================] - 13s 84ms/step - loss: 4.7552e-04 - val_loss: 4.9733e-04 - lr: 2.0000e-05\n",
      "Epoch 55/100\n",
      "150/150 [==============================] - 13s 84ms/step - loss: 4.7472e-04 - val_loss: 4.9811e-04 - lr: 2.0000e-05\n",
      "Epoch 56/100\n",
      "150/150 [==============================] - 13s 84ms/step - loss: 4.7406e-04 - val_loss: 4.9937e-04 - lr: 2.0000e-05\n",
      "Epoch 57/100\n",
      "150/150 [==============================] - 13s 84ms/step - loss: 4.7330e-04 - val_loss: 4.9760e-04 - lr: 2.0000e-05\n",
      "Epoch 58/100\n",
      "150/150 [==============================] - 13s 84ms/step - loss: 4.7268e-04 - val_loss: 4.9748e-04 - lr: 2.0000e-05\n",
      "Epoch 59/100\n",
      "150/150 [==============================] - 13s 84ms/step - loss: 4.7196e-04 - val_loss: 4.9791e-04 - lr: 2.0000e-05\n",
      "Epoch 60/100\n",
      "150/150 [==============================] - 13s 84ms/step - loss: 4.7120e-04 - val_loss: 4.9795e-04 - lr: 2.0000e-05\n",
      "Epoch 61/100\n",
      "150/150 [==============================] - 13s 84ms/step - loss: 4.7051e-04 - val_loss: 4.9690e-04 - lr: 2.0000e-05\n",
      "Epoch 62/100\n",
      "150/150 [==============================] - 13s 84ms/step - loss: 4.6975e-04 - val_loss: 4.9570e-04 - lr: 2.0000e-05\n",
      "Epoch 63/100\n",
      "150/150 [==============================] - 13s 84ms/step - loss: 4.6906e-04 - val_loss: 4.9657e-04 - lr: 2.0000e-05\n",
      "New model saved\n"
     ]
    }
   ],
   "source": [
    "tf.keras.utils.set_random_seed(42)\n",
    "\n",
    "number_filters = 128\n",
    "number_conv_layers = 1\n",
    "dense_layer_units = 128\n",
    "batch_size = 8000\n",
    "#stockfish_depth = 2\n",
    "model = build_model(number_filters, number_conv_layers, dense_layer_units) # initial 32, 4, 64\n",
    "data = np.load(f'data/dataset.npz')\n",
    "x_train, y_train = data['b'], data['v']\n",
    "x_train = np.array([x[:12] for x in x_train])\n",
    "y_train = normalise_scores(y_train)\n",
    "\n",
    "model.compile(optimizer=optimizers.Adam(5e-4), loss='mean_squared_error')\n",
    "model.summary()\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=100,\n",
    "          verbose=1,\n",
    "          validation_split=0.2,\n",
    "          callbacks=[callbacks.ReduceLROnPlateau(monitor='val_loss', patience=10, min_delta=1e-5, factor=0.2),\n",
    "                     callbacks.EarlyStopping(monitor='val_loss', patience=20, min_delta=1e-5)])\n",
    "\n",
    "model.save(f'models/model_{number_filters}_filters_{number_conv_layers}_conv_layers_{dense_layer_units}_dense_units_{batch_size}_batch_size_{stockfish_depth}_depth.h5')\n",
    "print('New model saved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_56\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_65 (InputLayer)       [(None, 14, 8, 8)]        0         \n",
      "                                                                 \n",
      " conv2d_92 (Conv2D)          (None, 128, 8, 8)         16256     \n",
      "                                                                 \n",
      " flatten_56 (Flatten)        (None, 8192)              0         \n",
      "                                                                 \n",
      " dense_111 (Dense)           (None, 128)               1048704   \n",
      "                                                                 \n",
      " dense_112 (Dense)           (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,065,089\n",
      "Trainable params: 1,065,089\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-19 15:32:57.583347: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150/150 [==============================] - ETA: 0s - loss: 0.0028"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-19 15:33:10.101232: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150/150 [==============================] - 13s 86ms/step - loss: 0.0028 - val_loss: 0.0011 - lr: 5.0000e-04\n",
      "Epoch 2/100\n",
      "150/150 [==============================] - 13s 84ms/step - loss: 9.5280e-04 - val_loss: 6.5518e-04 - lr: 5.0000e-04\n",
      "Epoch 3/100\n",
      "150/150 [==============================] - 13s 85ms/step - loss: 8.0060e-04 - val_loss: 6.1935e-04 - lr: 5.0000e-04\n",
      "Epoch 4/100\n",
      "150/150 [==============================] - 13s 85ms/step - loss: 7.5052e-04 - val_loss: 5.5699e-04 - lr: 5.0000e-04\n",
      "Epoch 5/100\n",
      "150/150 [==============================] - 13s 85ms/step - loss: 7.1617e-04 - val_loss: 5.3684e-04 - lr: 5.0000e-04\n",
      "Epoch 6/100\n",
      "150/150 [==============================] - 13s 85ms/step - loss: 6.8706e-04 - val_loss: 5.1189e-04 - lr: 5.0000e-04\n",
      "Epoch 7/100\n",
      "150/150 [==============================] - 13s 85ms/step - loss: 6.0420e-04 - val_loss: 4.8338e-04 - lr: 5.0000e-04\n",
      "Epoch 8/100\n",
      "150/150 [==============================] - 13s 85ms/step - loss: 4.6970e-04 - val_loss: 4.3410e-04 - lr: 5.0000e-04\n",
      "Epoch 9/100\n",
      "150/150 [==============================] - 13s 85ms/step - loss: 4.0809e-04 - val_loss: 4.2188e-04 - lr: 5.0000e-04\n",
      "Epoch 10/100\n",
      "150/150 [==============================] - 13s 84ms/step - loss: 3.7482e-04 - val_loss: 4.3239e-04 - lr: 5.0000e-04\n",
      "Epoch 11/100\n",
      "150/150 [==============================] - 13s 85ms/step - loss: 3.5707e-04 - val_loss: 4.0123e-04 - lr: 5.0000e-04\n",
      "Epoch 12/100\n",
      "150/150 [==============================] - 13s 85ms/step - loss: 3.4354e-04 - val_loss: 3.9019e-04 - lr: 5.0000e-04\n",
      "Epoch 13/100\n",
      "150/150 [==============================] - 13s 85ms/step - loss: 3.3506e-04 - val_loss: 3.6260e-04 - lr: 5.0000e-04\n",
      "Epoch 14/100\n",
      "150/150 [==============================] - 13s 85ms/step - loss: 3.2313e-04 - val_loss: 3.5790e-04 - lr: 5.0000e-04\n",
      "Epoch 15/100\n",
      "150/150 [==============================] - 13s 85ms/step - loss: 3.1737e-04 - val_loss: 3.9661e-04 - lr: 5.0000e-04\n",
      "Epoch 16/100\n",
      "150/150 [==============================] - 13s 85ms/step - loss: 3.0847e-04 - val_loss: 3.5711e-04 - lr: 5.0000e-04\n",
      "Epoch 17/100\n",
      "150/150 [==============================] - 13s 85ms/step - loss: 3.0175e-04 - val_loss: 3.5482e-04 - lr: 5.0000e-04\n",
      "Epoch 18/100\n",
      "150/150 [==============================] - 13s 85ms/step - loss: 2.9830e-04 - val_loss: 3.6944e-04 - lr: 5.0000e-04\n",
      "Epoch 19/100\n",
      "150/150 [==============================] - 13s 85ms/step - loss: 2.9423e-04 - val_loss: 3.4436e-04 - lr: 5.0000e-04\n",
      "Epoch 20/100\n",
      "150/150 [==============================] - 13s 84ms/step - loss: 2.8747e-04 - val_loss: 3.5121e-04 - lr: 5.0000e-04\n",
      "Epoch 21/100\n",
      "150/150 [==============================] - 13s 84ms/step - loss: 2.8509e-04 - val_loss: 3.6432e-04 - lr: 5.0000e-04\n",
      "Epoch 22/100\n",
      "150/150 [==============================] - 13s 84ms/step - loss: 2.8145e-04 - val_loss: 3.3858e-04 - lr: 5.0000e-04\n",
      "Epoch 23/100\n",
      "150/150 [==============================] - 13s 85ms/step - loss: 2.7516e-04 - val_loss: 3.5527e-04 - lr: 5.0000e-04\n",
      "Epoch 24/100\n",
      "150/150 [==============================] - 13s 85ms/step - loss: 2.6968e-04 - val_loss: 3.4331e-04 - lr: 5.0000e-04\n",
      "Epoch 25/100\n",
      "150/150 [==============================] - 13s 85ms/step - loss: 2.6876e-04 - val_loss: 3.5799e-04 - lr: 5.0000e-04\n",
      "Epoch 26/100\n",
      "150/150 [==============================] - 13s 85ms/step - loss: 2.6393e-04 - val_loss: 3.4990e-04 - lr: 5.0000e-04\n",
      "Epoch 27/100\n",
      "150/150 [==============================] - 13s 85ms/step - loss: 2.6291e-04 - val_loss: 3.1409e-04 - lr: 5.0000e-04\n",
      "Epoch 28/100\n",
      "150/150 [==============================] - 13s 85ms/step - loss: 2.5687e-04 - val_loss: 3.3894e-04 - lr: 5.0000e-04\n",
      "Epoch 29/100\n",
      "150/150 [==============================] - 13s 85ms/step - loss: 2.5293e-04 - val_loss: 3.3651e-04 - lr: 5.0000e-04\n",
      "Epoch 30/100\n",
      "150/150 [==============================] - 13s 85ms/step - loss: 2.5229e-04 - val_loss: 3.2933e-04 - lr: 5.0000e-04\n",
      "Epoch 31/100\n",
      "150/150 [==============================] - 13s 85ms/step - loss: 2.5029e-04 - val_loss: 3.5855e-04 - lr: 5.0000e-04\n",
      "Epoch 32/100\n",
      "150/150 [==============================] - 13s 85ms/step - loss: 2.4655e-04 - val_loss: 3.3076e-04 - lr: 5.0000e-04\n",
      "Epoch 33/100\n",
      "150/150 [==============================] - 13s 85ms/step - loss: 2.4668e-04 - val_loss: 3.0979e-04 - lr: 5.0000e-04\n",
      "Epoch 34/100\n",
      "150/150 [==============================] - 13s 85ms/step - loss: 2.4400e-04 - val_loss: 3.8166e-04 - lr: 5.0000e-04\n",
      "Epoch 35/100\n",
      "150/150 [==============================] - 13s 85ms/step - loss: 2.3860e-04 - val_loss: 3.5018e-04 - lr: 5.0000e-04\n",
      "Epoch 36/100\n",
      "150/150 [==============================] - 13s 85ms/step - loss: 2.4133e-04 - val_loss: 3.2218e-04 - lr: 5.0000e-04\n",
      "Epoch 37/100\n",
      "150/150 [==============================] - 13s 85ms/step - loss: 2.3718e-04 - val_loss: 3.1944e-04 - lr: 5.0000e-04\n",
      "Epoch 38/100\n",
      "150/150 [==============================] - 13s 85ms/step - loss: 2.2506e-04 - val_loss: 3.3117e-04 - lr: 1.0000e-04\n",
      "Epoch 39/100\n",
      "150/150 [==============================] - 13s 84ms/step - loss: 2.2412e-04 - val_loss: 3.2403e-04 - lr: 1.0000e-04\n",
      "Epoch 40/100\n",
      "150/150 [==============================] - 13s 85ms/step - loss: 2.2385e-04 - val_loss: 3.2955e-04 - lr: 1.0000e-04\n",
      "Epoch 41/100\n",
      "150/150 [==============================] - 13s 85ms/step - loss: 2.2319e-04 - val_loss: 3.3838e-04 - lr: 1.0000e-04\n",
      "Epoch 42/100\n",
      "150/150 [==============================] - 13s 85ms/step - loss: 2.2319e-04 - val_loss: 3.2146e-04 - lr: 1.0000e-04\n",
      "Epoch 43/100\n",
      "150/150 [==============================] - 13s 85ms/step - loss: 2.2249e-04 - val_loss: 3.3849e-04 - lr: 1.0000e-04\n",
      "Epoch 44/100\n",
      "150/150 [==============================] - 13s 85ms/step - loss: 2.2179e-04 - val_loss: 3.3296e-04 - lr: 1.0000e-04\n",
      "Epoch 45/100\n",
      "150/150 [==============================] - 13s 84ms/step - loss: 2.2192e-04 - val_loss: 3.4204e-04 - lr: 1.0000e-04\n",
      "Epoch 46/100\n",
      "150/150 [==============================] - 13s 85ms/step - loss: 2.2191e-04 - val_loss: 3.4668e-04 - lr: 1.0000e-04\n",
      "Epoch 47/100\n",
      "150/150 [==============================] - 13s 86ms/step - loss: 2.2084e-04 - val_loss: 3.2749e-04 - lr: 1.0000e-04\n",
      "New model saved\n"
     ]
    }
   ],
   "source": [
    "tf.keras.utils.set_random_seed(42)\n",
    "\n",
    "number_filters = 128\n",
    "number_conv_layers = 1\n",
    "dense_layer_units = 128\n",
    "batch_size = 8000\n",
    "#stockfish_depth = 2\n",
    "model = build_model(number_filters, number_conv_layers, dense_layer_units) # initial 32, 4, 64\n",
    "data = np.load(f'data/dataset.npz')\n",
    "x_train, y_train = data['b'], data['v']\n",
    "y_train = normalise_scores(y_train)\n",
    "\n",
    "model.compile(optimizer=optimizers.Adam(5e-4), loss='mean_squared_error')\n",
    "model.summary()\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=100,\n",
    "          verbose=1,\n",
    "          validation_split=0.2,\n",
    "          callbacks=[callbacks.ReduceLROnPlateau(monitor='val_loss', patience=10, min_delta=1e-5, factor=0.2),\n",
    "                     callbacks.EarlyStopping(monitor='val_loss', patience=20, min_delta=1e-5)])\n",
    "\n",
    "model.save(f'models/model_{number_filters}_filters_{number_conv_layers}_conv_layers_{dense_layer_units}_dense_units_{batch_size}_batch_size_downloaded_attacked.h5')\n",
    "print('New model saved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_59\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_68 (InputLayer)       [(None, 12, 8, 8)]        0         \n",
      "                                                                 \n",
      " conv2d_95 (Conv2D)          (None, 128, 8, 8)         13952     \n",
      "                                                                 \n",
      " flatten_59 (Flatten)        (None, 8192)              0         \n",
      "                                                                 \n",
      " dense_117 (Dense)           (None, 128)               1048704   \n",
      "                                                                 \n",
      " dense_118 (Dense)           (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,062,785\n",
      "Trainable params: 1,062,785\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-19 17:10:44.360762: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - ETA: 0s - loss: 5.7681e-05"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-19 17:11:00.855112: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 17s 168ms/step - loss: 5.7681e-05 - val_loss: 3.4945e-05 - lr: 5.0000e-05\n",
      "Epoch 2/100\n",
      "100/100 [==============================] - 17s 166ms/step - loss: 3.9095e-05 - val_loss: 2.8762e-05 - lr: 5.0000e-05\n",
      "Epoch 3/100\n",
      "100/100 [==============================] - 17s 166ms/step - loss: 3.5531e-05 - val_loss: 2.7053e-05 - lr: 5.0000e-05\n",
      "Epoch 4/100\n",
      "100/100 [==============================] - 17s 166ms/step - loss: 3.4558e-05 - val_loss: 2.6576e-05 - lr: 5.0000e-05\n",
      "Epoch 5/100\n",
      "100/100 [==============================] - 17s 166ms/step - loss: 3.4142e-05 - val_loss: 2.6326e-05 - lr: 5.0000e-05\n",
      "Epoch 6/100\n",
      "100/100 [==============================] - 17s 166ms/step - loss: 3.3850e-05 - val_loss: 2.6152e-05 - lr: 5.0000e-05\n",
      "Epoch 7/100\n",
      "100/100 [==============================] - 17s 166ms/step - loss: 3.3613e-05 - val_loss: 2.6008e-05 - lr: 5.0000e-05\n",
      "Epoch 8/100\n",
      "100/100 [==============================] - 17s 165ms/step - loss: 3.3410e-05 - val_loss: 2.5887e-05 - lr: 5.0000e-05\n",
      "Epoch 9/100\n",
      "100/100 [==============================] - 17s 165ms/step - loss: 3.3226e-05 - val_loss: 2.5789e-05 - lr: 5.0000e-05\n",
      "Epoch 10/100\n",
      "100/100 [==============================] - 17s 165ms/step - loss: 3.3057e-05 - val_loss: 2.5702e-05 - lr: 5.0000e-05\n",
      "Epoch 11/100\n",
      "100/100 [==============================] - 16s 165ms/step - loss: 3.2901e-05 - val_loss: 2.5622e-05 - lr: 5.0000e-05\n",
      "Epoch 12/100\n",
      "100/100 [==============================] - 17s 165ms/step - loss: 3.2754e-05 - val_loss: 2.5560e-05 - lr: 5.0000e-05\n",
      "Epoch 13/100\n",
      "100/100 [==============================] - 17s 167ms/step - loss: 3.2614e-05 - val_loss: 2.5495e-05 - lr: 5.0000e-05\n",
      "Epoch 14/100\n",
      "100/100 [==============================] - 17s 171ms/step - loss: 3.2479e-05 - val_loss: 2.5450e-05 - lr: 5.0000e-05\n",
      "Epoch 15/100\n",
      "100/100 [==============================] - 16s 165ms/step - loss: 3.2348e-05 - val_loss: 2.5401e-05 - lr: 5.0000e-05\n",
      "Epoch 16/100\n",
      "100/100 [==============================] - 17s 165ms/step - loss: 3.2221e-05 - val_loss: 2.5350e-05 - lr: 5.0000e-05\n",
      "Epoch 17/100\n",
      "100/100 [==============================] - 17s 168ms/step - loss: 3.2092e-05 - val_loss: 2.5328e-05 - lr: 5.0000e-05\n",
      "Epoch 18/100\n",
      "100/100 [==============================] - 17s 169ms/step - loss: 3.1999e-05 - val_loss: 2.5314e-05 - lr: 1.0000e-05\n",
      "Epoch 19/100\n",
      "100/100 [==============================] - 17s 167ms/step - loss: 3.1972e-05 - val_loss: 2.5304e-05 - lr: 1.0000e-05\n",
      "Epoch 20/100\n",
      "100/100 [==============================] - 17s 166ms/step - loss: 3.1944e-05 - val_loss: 2.5299e-05 - lr: 1.0000e-05\n",
      "Epoch 21/100\n",
      "100/100 [==============================] - 17s 166ms/step - loss: 3.1917e-05 - val_loss: 2.5289e-05 - lr: 1.0000e-05\n",
      "Epoch 22/100\n",
      "100/100 [==============================] - 17s 166ms/step - loss: 3.1889e-05 - val_loss: 2.5283e-05 - lr: 1.0000e-05\n",
      "Epoch 23/100\n",
      "100/100 [==============================] - 17s 166ms/step - loss: 3.1861e-05 - val_loss: 2.5276e-05 - lr: 1.0000e-05\n",
      "Epoch 24/100\n",
      "100/100 [==============================] - 17s 166ms/step - loss: 3.1832e-05 - val_loss: 2.5269e-05 - lr: 1.0000e-05\n",
      "Epoch 25/100\n",
      "100/100 [==============================] - 16s 165ms/step - loss: 3.1804e-05 - val_loss: 2.5262e-05 - lr: 1.0000e-05\n",
      "Epoch 26/100\n",
      "100/100 [==============================] - 17s 165ms/step - loss: 3.1774e-05 - val_loss: 2.5252e-05 - lr: 1.0000e-05\n",
      "Epoch 27/100\n",
      "100/100 [==============================] - 17s 165ms/step - loss: 3.1745e-05 - val_loss: 2.5246e-05 - lr: 1.0000e-05\n",
      "New model saved\n"
     ]
    }
   ],
   "source": [
    "tf.keras.utils.set_random_seed(42)\n",
    "\n",
    "number_filters = 128\n",
    "number_conv_layers = 1\n",
    "dense_layer_units = 128\n",
    "batches=100\n",
    "batch_size = 16000\n",
    "stockfish_depth = 1\n",
    "model = build_model(number_filters, number_conv_layers, dense_layer_units) # initial 32, 4, 64\n",
    "x_train, y_train = load_dataset(batches=batches, stockfish_depth=stockfish_depth)\n",
    "\n",
    "model.compile(optimizer=optimizers.Adam(5e-5), loss='mean_squared_error')\n",
    "model.summary()\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=100,\n",
    "          verbose=1,\n",
    "          validation_split=0.2,\n",
    "          callbacks=[callbacks.ReduceLROnPlateau(monitor='val_loss', patience=10, min_delta=1e-6, factor=0.2),\n",
    "                     callbacks.EarlyStopping(monitor='val_loss', patience=20, min_delta=1e-6)])\n",
    "\n",
    "model.save(f'models/model_{number_filters}_filters_{number_conv_layers}_conv_layers_{dense_layer_units}_dense_units_{batch_size}_batch_size_{stockfish_depth}_depth_{batches}_batches.h5')\n",
    "print('New model saved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_60\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_69 (InputLayer)       [(None, 12, 8, 8)]        0         \n",
      "                                                                 \n",
      " conv2d_96 (Conv2D)          (None, 128, 8, 8)         13952     \n",
      "                                                                 \n",
      " flatten_60 (Flatten)        (None, 8192)              0         \n",
      "                                                                 \n",
      " dense_119 (Dense)           (None, 128)               1048704   \n",
      "                                                                 \n",
      " dense_120 (Dense)           (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,062,785\n",
      "Trainable params: 1,062,785\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-19 19:21:12.099167: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - ETA: 0s - loss: 2.8310e-05"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-19 19:22:32.535819: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 84s 165ms/step - loss: 2.8310e-05 - val_loss: 4.4054e-05 - lr: 5.0000e-05\n",
      "Epoch 2/100\n",
      "500/500 [==============================] - 82s 164ms/step - loss: 2.6009e-05 - val_loss: 4.3414e-05 - lr: 5.0000e-05\n",
      "Epoch 3/100\n",
      "500/500 [==============================] - 82s 164ms/step - loss: 2.5821e-05 - val_loss: 4.3079e-05 - lr: 5.0000e-05\n",
      "Epoch 4/100\n",
      "500/500 [==============================] - 82s 165ms/step - loss: 2.5687e-05 - val_loss: 4.2850e-05 - lr: 5.0000e-05\n",
      "Epoch 5/100\n",
      "500/500 [==============================] - 82s 164ms/step - loss: 2.5581e-05 - val_loss: 4.2701e-05 - lr: 5.0000e-05\n",
      "Epoch 6/100\n",
      "500/500 [==============================] - 82s 164ms/step - loss: 2.5490e-05 - val_loss: 4.2549e-05 - lr: 5.0000e-05\n",
      "Epoch 7/100\n",
      "500/500 [==============================] - 82s 164ms/step - loss: 2.5407e-05 - val_loss: 4.2447e-05 - lr: 5.0000e-05\n",
      "Epoch 8/100\n",
      "500/500 [==============================] - 82s 164ms/step - loss: 2.5329e-05 - val_loss: 4.2349e-05 - lr: 5.0000e-05\n",
      "Epoch 9/100\n",
      "500/500 [==============================] - 82s 163ms/step - loss: 2.5252e-05 - val_loss: 4.2259e-05 - lr: 5.0000e-05\n",
      "Epoch 10/100\n",
      "500/500 [==============================] - 82s 164ms/step - loss: 2.5174e-05 - val_loss: 4.2158e-05 - lr: 5.0000e-05\n",
      "Epoch 11/100\n",
      "500/500 [==============================] - 82s 163ms/step - loss: 2.5095e-05 - val_loss: 4.2056e-05 - lr: 5.0000e-05\n",
      "Epoch 12/100\n",
      "500/500 [==============================] - 82s 163ms/step - loss: 2.5016e-05 - val_loss: 4.1945e-05 - lr: 5.0000e-05\n",
      "Epoch 13/100\n",
      "500/500 [==============================] - 82s 164ms/step - loss: 2.4936e-05 - val_loss: 4.1885e-05 - lr: 5.0000e-05\n",
      "Epoch 14/100\n",
      "500/500 [==============================] - 82s 164ms/step - loss: 2.4855e-05 - val_loss: 4.1762e-05 - lr: 5.0000e-05\n",
      "Epoch 15/100\n",
      "500/500 [==============================] - 82s 164ms/step - loss: 2.4775e-05 - val_loss: 4.1645e-05 - lr: 5.0000e-05\n",
      "Epoch 16/100\n",
      "500/500 [==============================] - 82s 163ms/step - loss: 2.4691e-05 - val_loss: 4.1542e-05 - lr: 5.0000e-05\n",
      "Epoch 17/100\n",
      "500/500 [==============================] - 82s 163ms/step - loss: 2.4610e-05 - val_loss: 4.1402e-05 - lr: 5.0000e-05\n",
      "Epoch 18/100\n",
      "500/500 [==============================] - 82s 163ms/step - loss: 2.4527e-05 - val_loss: 4.1280e-05 - lr: 5.0000e-05\n",
      "Epoch 19/100\n",
      "500/500 [==============================] - 82s 164ms/step - loss: 2.4446e-05 - val_loss: 4.1146e-05 - lr: 5.0000e-05\n",
      "Epoch 20/100\n",
      "500/500 [==============================] - 82s 163ms/step - loss: 2.4368e-05 - val_loss: 4.1032e-05 - lr: 5.0000e-05\n",
      "Epoch 21/100\n",
      "500/500 [==============================] - 82s 164ms/step - loss: 2.4294e-05 - val_loss: 4.0916e-05 - lr: 5.0000e-05\n",
      "Epoch 22/100\n",
      "500/500 [==============================] - 82s 164ms/step - loss: 2.4224e-05 - val_loss: 4.0826e-05 - lr: 5.0000e-05\n",
      "Epoch 23/100\n",
      "500/500 [==============================] - 82s 163ms/step - loss: 2.4158e-05 - val_loss: 4.0734e-05 - lr: 5.0000e-05\n",
      "Epoch 24/100\n",
      "500/500 [==============================] - 82s 163ms/step - loss: 2.4096e-05 - val_loss: 4.0646e-05 - lr: 5.0000e-05\n",
      "Epoch 25/100\n",
      "500/500 [==============================] - 82s 163ms/step - loss: 2.4040e-05 - val_loss: 4.0577e-05 - lr: 5.0000e-05\n",
      "Epoch 26/100\n",
      "500/500 [==============================] - 83s 166ms/step - loss: 2.3985e-05 - val_loss: 4.0524e-05 - lr: 5.0000e-05\n",
      "Epoch 27/100\n",
      "500/500 [==============================] - 83s 166ms/step - loss: 2.3934e-05 - val_loss: 4.0457e-05 - lr: 5.0000e-05\n",
      "Epoch 28/100\n",
      "500/500 [==============================] - 82s 163ms/step - loss: 2.3884e-05 - val_loss: 4.0413e-05 - lr: 5.0000e-05\n",
      "Epoch 29/100\n",
      "500/500 [==============================] - 82s 163ms/step - loss: 2.3837e-05 - val_loss: 4.0368e-05 - lr: 5.0000e-05\n",
      "Epoch 30/100\n",
      "500/500 [==============================] - 82s 164ms/step - loss: 2.3789e-05 - val_loss: 4.0469e-05 - lr: 5.0000e-05\n",
      "Epoch 31/100\n",
      "500/500 [==============================] - 82s 163ms/step - loss: 2.3746e-05 - val_loss: 4.0355e-05 - lr: 5.0000e-05\n",
      "Epoch 32/100\n",
      "500/500 [==============================] - 82s 163ms/step - loss: 2.3700e-05 - val_loss: 4.0307e-05 - lr: 5.0000e-05\n",
      "Epoch 33/100\n",
      "500/500 [==============================] - 82s 163ms/step - loss: 2.3658e-05 - val_loss: 4.0284e-05 - lr: 5.0000e-05\n",
      "Epoch 34/100\n",
      "500/500 [==============================] - 82s 163ms/step - loss: 2.3607e-05 - val_loss: 4.0258e-05 - lr: 1.0000e-05\n",
      "Epoch 35/100\n",
      "500/500 [==============================] - 81s 163ms/step - loss: 2.3597e-05 - val_loss: 4.0264e-05 - lr: 1.0000e-05\n",
      "Epoch 36/100\n",
      "500/500 [==============================] - 81s 162ms/step - loss: 2.3588e-05 - val_loss: 4.0260e-05 - lr: 1.0000e-05\n",
      "Epoch 37/100\n",
      "500/500 [==============================] - 81s 162ms/step - loss: 2.3579e-05 - val_loss: 4.0263e-05 - lr: 1.0000e-05\n",
      "Epoch 38/100\n",
      "500/500 [==============================] - 81s 162ms/step - loss: 2.3570e-05 - val_loss: 4.0258e-05 - lr: 1.0000e-05\n",
      "Epoch 39/100\n",
      "500/500 [==============================] - 81s 163ms/step - loss: 2.3561e-05 - val_loss: 4.0261e-05 - lr: 1.0000e-05\n",
      "Epoch 40/100\n",
      "500/500 [==============================] - 81s 162ms/step - loss: 2.3553e-05 - val_loss: 4.0266e-05 - lr: 1.0000e-05\n",
      "Epoch 41/100\n",
      "500/500 [==============================] - 82s 164ms/step - loss: 2.3544e-05 - val_loss: 4.0257e-05 - lr: 1.0000e-05\n",
      "Epoch 42/100\n",
      "500/500 [==============================] - 115s 230ms/step - loss: 2.3536e-05 - val_loss: 4.0243e-05 - lr: 1.0000e-05\n",
      "Epoch 43/100\n",
      "500/500 [==============================] - 82s 164ms/step - loss: 2.3527e-05 - val_loss: 4.0251e-05 - lr: 1.0000e-05\n",
      "New model saved\n"
     ]
    }
   ],
   "source": [
    "tf.keras.utils.set_random_seed(42)\n",
    "\n",
    "number_filters = 128\n",
    "number_conv_layers = 1\n",
    "dense_layer_units = 128\n",
    "batches=500\n",
    "batch_size = 16000\n",
    "stockfish_depth = 1\n",
    "model = build_model(number_filters, number_conv_layers, dense_layer_units) # initial 32, 4, 64\n",
    "x_train, y_train = load_dataset(batches=batches, stockfish_depth=stockfish_depth)\n",
    "\n",
    "model.compile(optimizer=optimizers.Adam(5e-5), loss='mean_squared_error')\n",
    "model.summary()\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=100,\n",
    "          verbose=1,\n",
    "          validation_split=0.2,\n",
    "          callbacks=[callbacks.ReduceLROnPlateau(monitor='val_loss', patience=10, min_delta=1e-6, factor=0.2),\n",
    "                     callbacks.EarlyStopping(monitor='val_loss', patience=20, min_delta=1e-6)])\n",
    "\n",
    "model.save(f'models/model_{number_filters}_filters_{number_conv_layers}_conv_layers_{dense_layer_units}_dense_units_{batch_size}_batch_size_{stockfish_depth}_depth_{batches}_batches.h5')\n",
    "print('New model saved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 12, 8, 8)]        0         \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 128, 8, 8)         13952     \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 128, 8, 8)         147584    \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 8192)              0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 128)               1048704   \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,210,369\n",
      "Trainable params: 1,210,369\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-22 00:37:38.834320: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2022-11-22 00:37:39.126297: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - ETA: 0s - loss: 2.7075e-05"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-22 00:41:07.777882: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 216s 431ms/step - loss: 2.7075e-05 - val_loss: 4.3870e-05 - lr: 5.0000e-05\n",
      "Epoch 2/100\n",
      "500/500 [==============================] - 216s 431ms/step - loss: 2.5956e-05 - val_loss: 4.3344e-05 - lr: 5.0000e-05\n",
      "Epoch 3/100\n",
      "500/500 [==============================] - 462s 924ms/step - loss: 2.5790e-05 - val_loss: 4.3026e-05 - lr: 5.0000e-05\n",
      "Epoch 4/100\n",
      "500/500 [==============================] - 217s 433ms/step - loss: 2.5658e-05 - val_loss: 4.2804e-05 - lr: 5.0000e-05\n",
      "Epoch 5/100\n",
      "500/500 [==============================] - 219s 438ms/step - loss: 2.5547e-05 - val_loss: 4.2598e-05 - lr: 5.0000e-05\n",
      "Epoch 6/100\n",
      "500/500 [==============================] - 215s 430ms/step - loss: 2.5450e-05 - val_loss: 4.2428e-05 - lr: 5.0000e-05\n",
      "Epoch 7/100\n",
      "500/500 [==============================] - 215s 430ms/step - loss: 2.5356e-05 - val_loss: 4.2285e-05 - lr: 5.0000e-05\n",
      "Epoch 8/100\n",
      "500/500 [==============================] - 216s 431ms/step - loss: 2.5262e-05 - val_loss: 4.2125e-05 - lr: 5.0000e-05\n",
      "Epoch 9/100\n",
      "500/500 [==============================] - 215s 431ms/step - loss: 2.5166e-05 - val_loss: 4.1937e-05 - lr: 5.0000e-05\n",
      "Epoch 10/100\n",
      "500/500 [==============================] - 216s 432ms/step - loss: 2.5094e-05 - val_loss: 4.1896e-05 - lr: 1.0000e-05\n",
      "Epoch 11/100\n",
      "500/500 [==============================] - 216s 432ms/step - loss: 2.5072e-05 - val_loss: 4.1856e-05 - lr: 1.0000e-05\n",
      "Epoch 12/100\n",
      "500/500 [==============================] - 215s 431ms/step - loss: 2.5052e-05 - val_loss: 4.1815e-05 - lr: 1.0000e-05\n",
      "Epoch 13/100\n",
      "500/500 [==============================] - 216s 431ms/step - loss: 2.5031e-05 - val_loss: 4.1788e-05 - lr: 1.0000e-05\n",
      "Epoch 14/100\n",
      "500/500 [==============================] - 216s 431ms/step - loss: 2.5010e-05 - val_loss: 4.1770e-05 - lr: 1.0000e-05\n",
      "Epoch 15/100\n",
      "500/500 [==============================] - 217s 433ms/step - loss: 2.4990e-05 - val_loss: 4.1709e-05 - lr: 1.0000e-05\n",
      "Epoch 16/100\n",
      "500/500 [==============================] - 216s 433ms/step - loss: 2.4968e-05 - val_loss: 4.1684e-05 - lr: 1.0000e-05\n",
      "Epoch 17/100\n",
      "500/500 [==============================] - 217s 434ms/step - loss: 2.4948e-05 - val_loss: 4.1645e-05 - lr: 1.0000e-05\n",
      "Epoch 18/100\n",
      "500/500 [==============================] - 217s 433ms/step - loss: 2.4927e-05 - val_loss: 4.1602e-05 - lr: 1.0000e-05\n",
      "Epoch 19/100\n",
      "500/500 [==============================] - 218s 435ms/step - loss: 2.4911e-05 - val_loss: 4.1591e-05 - lr: 2.0000e-06\n",
      "Epoch 20/100\n",
      "500/500 [==============================] - 217s 434ms/step - loss: 2.4906e-05 - val_loss: 4.1583e-05 - lr: 2.0000e-06\n",
      "Epoch 21/100\n",
      "500/500 [==============================] - 215s 430ms/step - loss: 2.4902e-05 - val_loss: 4.1578e-05 - lr: 2.0000e-06\n",
      "Epoch 22/100\n",
      "500/500 [==============================] - 215s 430ms/step - loss: 2.4898e-05 - val_loss: 4.1569e-05 - lr: 2.0000e-06\n",
      "Epoch 23/100\n",
      "500/500 [==============================] - 216s 432ms/step - loss: 2.4894e-05 - val_loss: 4.1565e-05 - lr: 2.0000e-06\n",
      "Epoch 24/100\n",
      "500/500 [==============================] - 216s 431ms/step - loss: 2.4890e-05 - val_loss: 4.1561e-05 - lr: 4.0000e-07\n",
      "Epoch 25/100\n",
      "500/500 [==============================] - 218s 435ms/step - loss: 2.4889e-05 - val_loss: 4.1561e-05 - lr: 4.0000e-07\n",
      "Epoch 26/100\n",
      "500/500 [==============================] - 216s 431ms/step - loss: 2.4889e-05 - val_loss: 4.1558e-05 - lr: 4.0000e-07\n",
      "Epoch 27/100\n",
      "500/500 [==============================] - 215s 430ms/step - loss: 2.4888e-05 - val_loss: 4.1556e-05 - lr: 4.0000e-07\n",
      "Epoch 28/100\n",
      "500/500 [==============================] - 215s 430ms/step - loss: 2.4887e-05 - val_loss: 4.1554e-05 - lr: 4.0000e-07\n",
      "Epoch 29/100\n",
      "500/500 [==============================] - 215s 429ms/step - loss: 2.4886e-05 - val_loss: 4.1554e-05 - lr: 8.0000e-08\n",
      "Epoch 30/100\n",
      "500/500 [==============================] - 215s 429ms/step - loss: 2.4886e-05 - val_loss: 4.1554e-05 - lr: 8.0000e-08\n",
      "Epoch 31/100\n",
      "500/500 [==============================] - 215s 430ms/step - loss: 2.4886e-05 - val_loss: 4.1554e-05 - lr: 8.0000e-08\n",
      "Epoch 32/100\n",
      "500/500 [==============================] - 215s 430ms/step - loss: 2.4886e-05 - val_loss: 4.1554e-05 - lr: 8.0000e-08\n",
      "Epoch 33/100\n",
      "500/500 [==============================] - 215s 430ms/step - loss: 2.4886e-05 - val_loss: 4.1554e-05 - lr: 8.0000e-08\n",
      "New model saved\n"
     ]
    }
   ],
   "source": [
    "tf.keras.utils.set_random_seed(42)\n",
    "\n",
    "number_filters = 128\n",
    "number_conv_layers = 2\n",
    "dense_layer_units = 128\n",
    "batches=500\n",
    "batch_size = 16000\n",
    "stockfish_depth = 1\n",
    "model = build_model(number_filters, number_conv_layers, dense_layer_units) # initial 32, 4, 64\n",
    "x_train, y_train = load_dataset(batches=batches, stockfish_depth=stockfish_depth)\n",
    "\n",
    "model.compile(optimizer=optimizers.Adam(5e-5), loss='mean_squared_error')\n",
    "model.summary()\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=100,\n",
    "          verbose=1,\n",
    "          validation_split=0.2,\n",
    "          callbacks=[callbacks.ReduceLROnPlateau(monitor='val_loss', patience=5, min_delta=1e-6, factor=0.2),\n",
    "                     callbacks.EarlyStopping(monitor='val_loss', patience=20, min_delta=1e-6)])\n",
    "\n",
    "model.save(f'models/model_{number_filters}_filters_{number_conv_layers}_conv_layers_{dense_layer_units}_dense_units_{batch_size}_batch_size_{stockfish_depth}_depth_{batches}_batches.h5')\n",
    "print('New model saved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW0AAAIECAIAAABdcOh6AAAABmJLR0QA/wD/AP+gvaeTAAAgAElEQVR4nOydeVwUx7r3a9gGHBjBRBHEgAExCCoSFRUUwaC4RiVABAXkw1FEclFUIi8qGiXiyWYOEk1wgaPDJiCgXgXM8XgII3qVLa4gEGXfgoAzMMxS7x9107czwNBMzwxo6vtXV3VV9dNPV/+6u6q6igEhBBgMBkMDtZE2AIPBvPFgHcFgMHTBOoLBYOiCdQSDwdBFQ75sd+7c+fbbbxVrCgaDGVkWLFgQFhYmR0Y530dqa2vT09Ply/uXpaioqKioaKStUAp1dXW4PrzpFBUV3blzR768cr6PIC5dukQn+18NDw8P8JY6LS0tzcvL6608tb8OqH7KB24fwWAwdME6gsFg6IJ1BIPB0AXrCAaDoQvWEQwGQxda/TVy09HR4eDg8Pnnn/v5+Y2IAQPS2Nj4888/19bWenp6mpubAwB6enoyMzOLi4stLCy8vb3Hjh2rYpNGp6Pk5sqVK6mpqWh71apVGzduJHZVVlZmZWUZGRmhoKurq6GhIbFXIBBkZmaKxWIAgJqampub27hx41Ro+P+Sl5cnFApXrVpFjnzx4gWHw2lpabG1tfXx8dHU1KRYGo/HS0xMrK6uHjt2rKen57Rp0+hkvHXr1pgxY+zt7Ylk9+/fP3HiBNq2s7OTb2AIVaBcoNogX14IYVdXl6OjY3p6utwlDElvb++w0v/4448LFy4sKiqSSCQopq2tbdGiRSdOnGhoaNi7d6+lpeVvv/1Gx6RPPvnkk08+GVaWUeioAaFYH2JiYiZOnNjW1tbW1sbj8Yj4jIyMkJAQkUjU3Ny8detWAMD8+fOlDOvo6PD19V24cGFtbS19g4dLfn7+smXLAACHDh0ixz969IjFYpmYmCD5sLOz6+7uplJgS0uLubn5hQsX+Hx+UVGRlZXV5cuXaWY8d+7csWPHiJQCgQC5es2aNWvXrh2yZDnqJ8HI6IgK2L17t1gsppJSIpF8/PHHLi4uPT095Hg/P78lS5agbbFYPHPmTCoXQwZ0rpPyoO4oGVDXEWNjY6nIsrIyR0dHcgx6wPr7+0ulvHjx4v79+2maKh89PT01NTX9dSQsLOzOnTsQwrq6Oi8vLwDAvn37qBS4e/duNzc3Ivjll19aWFjQz+jv75+bmyuVxd3dXdk68na2j/z666+nT5+mmPjrr78uKiricDja2tpEZGdn58WLF5cvX46CampqW7ZsycnJKSsrU7y5I8ewHKUMxGKxu7u7j48POZLFYi1YsCAhIYF4LUdoaWnp6uqq1sD/RVtbe9KkSVKRr169cnR0nD9/PgBg0qRJx48fZzAYd+/epVJgXV1dY2Mj/GP2HxaLRa5+cmc8cuRIUFAQj8ejUpQCGRkd6e3tvXDhQl5eHgo+f/58//79EomksrIyOjo6Pj5eKBSiXVVVVagy/fLLL5GRkYmJiRKJBACQmpqanJxMjMVOT09PTk7OysoCABQWFq5evZrH46WkpAw5wrK4uDgyMnL37t0TJ04kx1dUVIjFYh0dHSLGysoKAFBSUqIQD1BExY7i8XhffPHFs2fPVHaC2dnZ9fX13t7eUvGZmZkmJiZ79uy5efPmYHkFAkFeXl5kZGRcXFxVVRURL8NLAICurq74+PiwsLCTJ0++fv2auqnq6upSMfr6+uvXryeCpqam1tbWU6dOpVKai4tLWVnZwYMHAQAikYjD4ezcuZN+RhMTEz09PbRXpcj3GkPnu+bJkyfr1q0DABw/fhxCmJCQgFrUcnJyNmzYgBqxDhw4ACGMjY3V1dU1MjLicDgzZsxAd7W7uzuEsKury8HBgc1mozIbGhpmzJgxceJECGFBQQF6vl29erX/O54UmzZt0tDQuHTpkp+fn5OTU1hY2KtXryCET58+BQAEBwcTKW/fvg0AOHz4sHxnDYf/3qh6RyHBCg8PH+6pyf1d4+zsbGtrK5XMzs4OQnj//n0dHZ1x48Y9f/4cxaelpcXExKDtnp6eJUuWpKSkdHR0xMbG6unpZWRkyPYShLCiomLNmjW5ubmlpaU2Njbm5uYdHR0UzxHpsowKIBaLWSwWMmNI+vr6nJ2dAQB+fn7+/v4//fQTRTOGzBgUFGRqakqOUcF3zci0j9TX1xO3B4QwPDwcAJCdnY2Czs7OlpaWaNvLy4vFYl28eBFC2NDQsGDBAgAAqvQhISHE7QEhDAwMRLcHhPDw4cMAAKLFVAaWlpbGxsapqand3d05OTk6OjqzZs0SCoVCofC9997T19cn6hk65dOnT8t91nJcJxU7SiQSZWdnt7e3D/fU5NMRiUSira29cuVKqWRIRyCESUlJAABra+uuri74Zx3x9vbesmULkeWTTz7R0dFBTbAyvOTq6kq0Sl6/fp0sMUMypI5cvnzZ3t6eSq1D8Pl8pAh2dnbNzc0Ucw2ZMSoqCgBAvohvbfuI1Fcui8UCAKxcuRIFbWxs6urqiF1sNhs9No2MjI4dOwYAyM/PBwCoqf3JeKkgFV69elVZWeni4uLp6amrq7tmzZrg4OCysrLk5GQNDY34+HiRSDR9+vRvvvnm0KFD6JaztraW43zlRsWOUldXX7t2rcq6VBsbG3t7e42NjQdLsHHjxn379j169GjTpk2QNJEwn8+/dOnS7NmziZjt27f39PScP38eDO6lxsbG/Px8LpcbERERERFx7dq1OXPm8Pl8hZyLUCg8duxYYmIig8GgmOXevXvGxsZ79+4tLi62t7evra1VSMYJEyYAAEpLS4dlP01GZvyI7JrNYrFEIhERJF+YuXPnAgCoe1w26F3j3XffJWIcHR2/+eab0tLSzZs3L1u27Ndff71+/TqTydywYcOPP/44depUBwcHhRyaIqPEUUqiubkZAMBms2WkiY6OfvjwYU5OzsGDB2fOnIkiuVyuUCjU0Pi/2otaJSoqKsDgXqqsrAQAhIeHk6+4oti5c2dUVBT1MSBFRUV+fn7l5eVsNtvU1DQkJCQ4OPjKlSv0M6Kze/bsmYuLi3znIgdvWH+NlpYWk8l87733FFKamZmZnp5eQ0MDEYM+B9ADDSXYvn17QEDAv//97+bm5qNHj1J/2owsinWUkrCwsGAwGO3t7TLSqKmpcTgcKyuro0ePEq3maEAal8slkqGbx9LSUkZRWlpaAIDi4mJyZHd3t7zm/x/ff//93LlziTcgKsTFxc2bNw9p6I4dO8LDw3Nzc9va2uhnRJ015FF8KuAN0JHe3l5im8vlCgSCefPmAQDYbLZAICB2QQhR9SKQCvaHwWAsXryY3AWDHuCLFy8mJ+vs7Dx+/PgPP/zg6elJ4zyUjvIcpST09PTMzc1bWlpkJ2Oz2Tk5OQYGBoSOzJ49m8lkFhYWEmlaW1sBAIsWLZJRzrRp09TV1aOiovr6+ohcHA6HorXowwr2W6fl3LlzDAbD39+fSIYa6WXT3NxM7gDatm2bUCgc0hVUMqLn4pQpU4YsSoGMjI6g/jail/v3338HAPT09KCgSCQSCoVE1e/s7Hz58iXavnHjxpw5c9zd3QEApqamAoEgPz8fQpiamsrlcjs7Ozs7O8Vi8fjx4wEADx48KCgoIN9d/YmNjW1qaiIq07Vr11xdXT/66CMiQWtrq7Ozc2BgYFBQkOIcQBUVO6qpqcnT05N8fyqb2bNn97956uvrpZotLCws0tLSiPtnwoQJn332WU1Nza1bt1BMVlaWh4eHk5MTGNxLBgYGQUFBRUVFTk5OSUlJCQkJPj4+aGx+TEyMt7c3+c20P0h9pIZmnD59+syZM2w2OyEh4fz587GxsatXr0aiJrvMwMDAq1evEkaWlJTMmjXrgw8+oJMR0dDQoK+vT45RBfI1z9Lpr3n58uX27dsBANOnT79+/XpWVpaZmRkAIDQ0tLq6OiUlBUnp3r17m5ubAwICWCzW2rVr4+Litm7d6ujoWFNTg8rh8Xg2NjYAAENDw8TExK1btxoYGOzZs6etra26utrQ0NDAwODMmTND2nPlyhUrK6vjx4+Hhob6+PgQ47Xv3r17/Pjx1atXX7hwQb4zlWK47eGqdxQarBEVFTXcU5O73zcpKYnJZL5+/RoFi4uLAwMDAQAeHh5I+MicOHGC6K8Ri8VhYWHjx49HPx95enqi4ciyvcTj8Xx9fVHNZ7PZRN/N5MmTAQCRkZGDWc7lcoODgwEAFhYWcXFxQqEQQoiadaWYMmUK6rKRXaZIJIqIiJg1a9bJkycjIyM//fTT6upqKsbIyIhAc6ySY97afl/qBAQEGBsbCwSCkpISKX9BCCUSSXl5ObrzKyoq+Hw+sauvr48clI1AIHj06BFRm1HJBQUFtbW11LvxhkSp4+IV5Sg0AG+4R6czLn7FihU5OTkUD9Ta2koO8vn84uJiqR8aqBTy4MED8lk3NTUVFhaGhoYOqxzZUCmzt7f34cOHLS0tCskIIXz8+DGTyayqqiJHqkBHRqa/ZrhoaWnZ2tr2j2cwGDNmzEDbUuMINTU1qf95qaWlNX36dKmSHR0d5TJ2JKHvKIrDMRXIjz/+6O/vv2rVKio991JdLTo6OuTeX4q8++67UuUYGhqePXuWaONQCFTKZDKZ/UcSyJ0RABAfH//DDz+8//77wzaXHqO9nZXP56v+Z4E3kTfFURBCiUSC3vJQzOTJk0NCQmJiYkbQqlOnTrm5uQ0owaovU+6MKSkpOjo6AQEBRIyUq5XH6H0fEQqF8fHxt2/f7u7uPnDgwLZt20xMTIZbSG1t7ZYtWwbb6+fnt3nzZnpmjjwKcZRqMDc3//DDDz/++GMAwIYNG4hLs379eltb24yMDNQwrHq2bdsmxzhGJZUpX8aCggIDA4Po6Ggi5s6dO0ePHkXb5HlJlAFDPq1C6wyoQOdoAiEkOvn6o6Gh0f/nK+Xx1q87MfrrA0YGdOrn6H0fUQgMBoPJZI60FRjMW85obx/BYDCjH6wjGAyGLlhHMBgMXbCOYDAYutBqZ31Tfn4dVbzFTnuLT+0vwieffCJfRlo6QqxFgqHCd999BwDYtWvXSBuieO7cuXPixAlcH95oUP2UD1o6Msr/ox9toJ75t9VpJ06ceFtP7S8CnZFNuH0Eg8HQBesIBoOhC9YRDAZDF6wjGAyGLlhHMBgMXZT4n155eXl5eTkRNDIyWrp0qfIOBwC4d+8eWnkAoaGh8emnnyr1iJhhceXKFaJveNWqVWhuVERlZWVWVpaRkREKurq6kmc8FwgEmZmZaD5qNTU1Nzc3lS2yQyYvL08oFKI1+ghevHjB4XBaWlpsbW19fHyoz57F4/ESExOrq6vHjh3r6elJfc2KATPeunVrzJgx5PkB7t+/TyyQbGdnFxYWRrF8eZBvGjWK8+g9efJk7NixAIB//vOfIpFIvmMNSW9vL7H9n//8B13I7OxsYqbVUYJS51WEf/aDiguhPq/ixIkT29ra2trayFcnIyMjJCREJBI1Nzdv3boVADB//nwpSzo6Onx9fRcuXIgWzVMx+fn5y5YtAwAcOnSIHP/o0SMWi2ViYoJqnZ2dXXd3N5UCW1pazM3NL1y4wOfzi4qKrKysiMli5c547ty5Y8eOESkFAgFy9Zo1a974+Vk//PBDBoMhx5Sf1Nm9eze5fDMzs3feeUd5h5MbZeuIlB9UWQid+VnLysocHR3JMegB6+/vL5Xy4sWL+/fvH65tCqGnp6empqa/joSFhd25cwdCWFdX5+XlBQDYt28flQJ3797t5uZGBL/88ksLCwv6Gf39/fuvaf02rMupra2trq6u8MmmCH799dfTp0+TY7S0tNCKR38p+vthpAoZFmKx2N3dHS0nSsBisRYsWJCQkEC8liO0tLSkFipVGdra2pMmTZKKfPXqlaOj4/z58wEAkyZNOn78OIPBuHv3LpUC6+rqGhsb4R8zP7FYLG1tbfoZjxw5EhQUpPoZNlU9j9Hz588TEhK++OKLqqqqtLS0CRMm+Pv7o3fCqqqqK1eu7Ny585dffrl+/bqlpeXmzZvV1NRSU1MlEommpiYa/J+eni4UCnV0dNatW1dYWOjt7c3j8VJSUjQ1NdGETkNSWVn53//9369evZo3b96KFSsAANnZ2WjBFAaDgZpUHj16hBp3li1b9s4773R1daWmpj558uT999/39/dHtbmqqiohIeHQoUPXr19//Pjxrl27qH8by0YgENy+ffv27dvGxsZubm7m5uYAgGH5QSHO5PF433zzjZeXF/VP9+GSnZ1dX1/v7e0tFZ+ZmTl37tw9e/bY2NiQlxMa0ktAZh0DAAx4KanQf+o8fX399evXE0FTU1Nra2uKE2W7uLikpqYePHjwyJEjIpGIw+Hs3LmTfkYTExM9Pb2DBw9+8803VEpTGPK9xlD/rnFwcNDQ0EDbCQkJqPEsJydnw4YNqL0KLfgeGxurq6trZGTE4XBmzJiho6MDAHB3d4cQdnV1OTg4sNlsVEhDQ8OMGTMmTpwIISwoKECPsqtXrxKvc5aWlkZGRoPZ89lnny1atKitrS0vL4/BYKD1UJ48eYJa+CorK1EysVi8dOnSkydPSiSSioqKNWvW5ObmlpaW2tjYmJubd3R0JCYmTpw4EQCQkJCApiwvLCyU7QqK7409PT1LlixJSUnp6OiIjY3V09PLyMgYlh8U5cy8vDwAQHh4+JA2y/1d4+zsbGtrK5XMzs4OQnj//n0dHZ1x48Y9f/4cxaelpRHr1wzmJRl1DEI44KUc0myERCIBABw+fHiwBGKxmMViITOGpK+vz9nZGQDg5+fn7+//008/UTRjyIxBQUGmpqbkmLdh/RqyjkAIw8PDAQDZ2dko6OzsbGlpiba9vLxYLNbFixchhA0NDWipXVShQ0JCiKoPIQwMDERVH0J4+PBhAAB5lRnZOjJ27NijR4+i7enTp8+fPx9toyX1CDHq6+ubM2cOaht2dXUlmrKuX79O1MvIyEikIxDCp0+fDrnSDcXr5O3tvWXLFnIuHR0d1LhI3Q8KcaZIJMrOzm5vbx/SZvl0RCKRaGtrr1y5UioZ0hEIYVJSEgDA2tq6q6sL/llHZHhJRh0b7FJSYUgduXz5sr29PfUFj/h8PlIEOzu75uZmirmGzBgVFQUAIF+1t6F9RAq0BDexorKNjU1dXR2xi81mo0eikZHRsWPHAAD5+fmg3wrydFpbrl27hhapu3fvHoSQWN/Qy8vLwsLi66+/RsHLly+vW7dOXV29sbExPz+fy+VGRERERERcu3Ztzpw56CMIPedR5+W0adMU8tc8n8+/dOkSeU2W7du39/T0oKXbqPtBIc5UV1dfu3at8npYGxsbe3t7jY2NB0uwcePGffv2PXr0aNOmTZA0ibRsLw1Wx2RcSvoIhcJjx44lJiZSrwb37t0zNjbeu3dvcXGxvb09WluafsYJEyYAAEpLS4dlP01U3T4iVWtZLJZIJCKC5Gswd+5c8MfC3QrEwcHh8uXLmZmZy5cvNzMzq6+vR/Hq6uqff/753/72t3v37s2bN+/s2bOJiYkAgMrKSgBAeHi41MpJQDnTbXC5XKFQqKHxf9cFfW+Tx8VQRAXOpElzczMAgM1my0gTHR398OHDnJycgwcPzpw5E0XK9tJgdUzGpaTPzp07o6KiqDckFRUV+fn5lZeXs9lsU1PTkJCQ4ODgK1eu0M+Izu7Zs2cuLi7ynYscjN7xrFpaWkwm87333lNUgUQ1OnfuXHx8/KZNm6Smkvf19Z00aVJ0dPSzZ8/09fVR8wfq+ikuLian7O7uVpRVUqChVlwul4hB1cLS0pJOsQp3pkKwsLBgMBjt7e0y0qipqXE4HCsrq6NHjxI/tsvnJeVdyu+//37u3LnEGxAV4uLi5s2bhzR0x44d4eHhubm5bW1t9DOizhryKD4VMLp0pLe3l9jmcrkCgWDevHkAADabLRAIiF0QQlSTCKSCsN9CKhKJJD4+/sGDB1999dWOHTuIrjJySi0trT179qBujqCgIBQ5bdo0dXX1qKgoYh2c1tZW1JiiDGbPns1kMgsLC4kYtHj9okWLwDD9oChnKg89PT1zc/OWlhbZydhsdk5OjoGBAaEjsr00GDQvJaoq/avWuXPnGAwGsYwmhPDp06dDltbc3EzuANq2bZtQKBzSFVQyNjQ0AADQ6ugqQ+k60t3dLRKJXr9+jYK///47AIBolRCJREKhkKjWnZ2dL1++RNs3btyYM2cOWmDN1NRUIBCgBehTU1O5XG5nZ2dnZ6dYLB4/fjwA4MGDBwUFBejOaWxsbGtrI98qAoHgv/7rv8zMzMaMGQMAyMrKEolEN2/eLCsr6+joqKysREOMAAB/+9vf3nnnnZqaGtSOBQAwMDAICgoqKipycnJKSkpKSEjw8fFBbSJCoRAAIPtxOlwmTJjw2Wef1dTU3Lp1C8VkZWV5eHg4OTkN1w/0ndnU1OTp6Um+XRXO7Nmz+9889fX1Us0WFhYWaWlpxP0j20uD1TEZlzImJsbb2xvdgYOB1EdqaMbp06fPnDnDZrMTEhLOnz8fGxu7evVqJGqyywwMDLx69SphZElJyaxZsz744AM6GRENDQ36+vrkGFUgX/Mslfb5srKykJAQ9LHq4+OTl5eXlZVlZmYGAAgNDa2urk5JSUGquXfv3ubm5oCAABaLtXbt2ri4uK1btzo6OtbU1KCieDyejY0NAMDQ0DAxMXHr1q0GBgZ79uxpa2urrq42NDQ0MDA4c+ZMUVERMaLJxMRk7ty58+bNmzlzpp6eHoPBqKurgxCiYRSGhoanT58+evSompranj17yGaHh4d/++235Bgej+fr64uKZbPZqME/PT0dfQx7eHiUlZVRcRrF9nCxWBwWFjZ+/PjPP//cz8/P09Ozp6dnWH6AENJ3JoTw5s2bAICoqKghbZa73zcpKYnJZL5+/RoFi4uLAwMDkVeR0pE5ceIE0V8zmJdk17EBLyWEcPLkyQCAyMjIwSzncrnBwcEAAAsLi7i4OKFQCCFEzbpSTJkyBXXZyC5TJBJFRETMmjXr5MmTkZGRn376aXV1NRVjZGRELFiwICwsjBzzNvT7UicgIMDY2FggEJSUlEi5BkIokUjKy8vRTxkVFRV8Pp/Y1dfXRw4OSUtLS19fH9r+/fffpfauXLmyfySEsLW19cGDB8M6kBTDuk58Pr+4uJhQEAKKflCUMysqKqgMk6czLn7FihU5OTlD5kW0traSg4N5achCpC5lU1NTYWFhaGjosMqRDZUye3t7Hz582NLSopCMEMLHjx8zmcyqqipypAp0ZNSty6mlpTXgSusMBmPGjBloW2rIoKam5rAGkqK3d4SBgQF5F5fLnTx5slQk4t1331VGO/9g6OjokPs1CYblB/rOpDg6kw4//vijv7//qlWrqHTnS12Cwbw0ZCFS5RgaGp49e5Zo41AIVMpkMpnW1taKyggAiI+P/+GHH95///1hm0uPUaQjfD5f9f8FIO7duxcWFmZtbf348eOrV6+OiA2KZQSdKRv4x4AuBoOBeqYnT54cEhISExPz//7f/xspq06dOuXm5jag5qq+TLkzpqSk6OjoBAQEEDHI1VD567ePiv4aoVD4ww8/3L59u7u7+8CBA8TINFVSWVlZXV194sQJNNHBm8tocOZgmJubf/jhhx9//PHHH3+ckJBAxK9fv37jxo0ZGRkjZdi2bdvs7OxGSZnyZSwoKDAwMIiOjiZi7ty5s2bNmjVr1vT29n744YdyWEIdhnxalZaW5uXlpQKde5tAvxHSmd1/1ILrw1sAnfo5Kt5HMBjMGw3WEQwGQxesIxgMhi5YRzAYDF1o9fumpaUpyo6/Aqjr5I1zGo/HYzKZ5J9r+3Pnzh3wBp4ahkxdXZ2JiYmcmeUbvoZXlsdg3j7kHs8qZ78v5q8Dg8FITU319PQcaUMwoxfcPoLBYOiCdQSDwdAF6wgGg6EL1hEMBkMXrCMYDIYuWEcwGAxdsI5gMBi6YB3BYDB0wTqCwWDognUEg8HQBesIBoOhC9YRDAZDF6wjGAyGLlhHMBgMXbCOYDAYumAdwWAwdME6gsFg6IJ1BIPB0AXrCAaDoQvWEQwGQxesIxgMhi5YRzAYDF2wjmAwGLpgHcFgMHTBOoLBYOiCdQSDwdAF6wgGg6EL1hEMBkMXrCMYDIYuWEcwGAxdsI5gMBi6aIy0AZhRx6tXryCE5Bgej9fR0UEEdXV1NTU1VW4XZvTCkKoxGIyLi8utW7cG26uurl5fX29oaKhKkzCjHPxdg5Hm008/ZTAYA+5SU1NbvHgxFhGMFFhHMNJ4eHhoaAz8wctgMHx9fVVsD2b0g3UEI42BgYGrq6u6unr/XWpqauvWrVO9SZhRDtYRzABs2rRJIpFIRWpoaKxcuVJfX39ETMKMZrCOYAbg448/ZjKZUpESiWTTpk0jYg9mlIN1BDMAY8aMWb9+vVTnLpPJXLVq1UiZhBnNYB3BDIy3t7dQKCSCmpqaHh4eOjo6I2gSZtSCdQQzMMuXL2ez2URQKBR6e3uPoD2Y0QzWEczAaGpqbty4UUtLCwX19fWXLl06siZhRi1YRzCDsnHjxr6+PgCApqbmpk2bBhtUgsHgcfGYQZFIJMbGxs3NzQCAgoICR0fHkbYIM0rB7yOYQVFTU0MdvUZGRg4ODiNtDmb0gnUEI4uNGzcCAHx9fQf74waDAfi7BjMk1tbWycnJM2fOHGlDMKMYSCI1NXWkzcFgMG8An3zyCVk6BmiBx2oyevDy8tq5c+eCBQtG2hDF89133wEAdu3aNdKGYIYNunZkBtART09PlRiDGRovL68FCxa8lVfk0qVLAFe2NxN07cjgdlYMBkMXrCMYDIYuWEcwGAxdsI5gMBi6YB3BYDB0eav+vHrx4gWHw2lpabG1tfXx8RlwjZUXL1789NNPHA7nt99+G7LAnp6ezMzM4uJiCwsLb2/vsWPH9k/T2Nj4888/19bWenp6mpub0z8LmnR0dDg4OHz++ed+fv/ByxsAACAASURBVH4jbYuyqKyszMrKMjIyQkFXV1fyFPYCgSAzM1MsFgMA1NTU3Nzcxo0bp3oj8/LyhEKh1MxPVKrogPB4vMTExOrq6rFjx3p6ek6bNo1Oxlu3bo0ZM8be3n5YZySL/uPQ4JvJo0ePWCyWiYkJujZ2dnbd3d39k/3rX/9auHChurr6kAW2tbUtWrToxIkTDQ0Ne/futbS0/O2336TS/PjjjwsXLiwqKpJIJIo5jT8DAEhNTR1Wlq6uLkdHx/T0dGXYg+jt7aVfyCeffCI1lokiGRkZISEhIpGoubl569atAID58+dLmdTR0eHr67tw4cLa2lr6pg6X/Pz8ZcuWAQAOHTpEjqdYRfvT0tJibm5+4cIFPp9fVFRkZWV1+fJlmhnPnTt37Nix4Z4aov+1e3t0JCws7M6dOxDCuro6Ly8vAMC+ffsGTLl3714qOuLn57dkyRK0LRaLZ86cuXbtWmKvRCL5+OOPXVxcenp6FGH+wMihIypg9+7dYrGYZiHy6UhZWZmjoyM5Bj1g/f39pVJevHhx//79tEyUl56enpqamv46Qr2KSrF79243Nzci+OWXX1pYWNDP6O/vn5ubS6UcKfpfu7ekfeTVq1eOjo7z588HAEyaNOn48eMMBuPu3bsDJqbyMtnZ2Xnx4sXly5ejoJqa2pYtW3JycsrKylDM119/XVRUxOFwtLW1FXQSbwa//vrr6dOnR+TQYrHY3d3dx8eHHMlisRYsWJCQkHDixAlyvJaWlq6urmoN/F+0tbUnTZokFTmsKipFXV1dY2Mj/ONXOBaLRbHWyc545MiRoKAgHo9HpSjZqEJHent7L1y4sG/fvuzs7J6eHiJeIBDk5eVFRkbGxcVVVVUR8c+fP9+/f79EIqmsrIyOjo6Pj0cThV67di05OTk5OTklJUUgEAAAiouLUYyamtr69euJEkxNTa2tradOnUrECIXCtLS0iIiI3Nzc/isq9KeiokIsFpOnI7WysgIAlJSUoONGRkbu3r174sSJdDyjDJC38/LyUHAwZwIAqqqq0L33yy+/REZGJiYmIs+kpqYmJyenp6ejZOnp6cnJyVlZWQCAwsLC1atX83i8lJQUNKiRx+N98cUXz549U8GpZWdn19fX95/eMTMz08TEZM+ePTdv3hws73ArG6Krqys+Pj4sLOzkyZOvX7+mbmr/1X/09fVlV1EZuLi4lJWVHTx4EAAgEok4HM7OnTvpZzQxMdHT00N76UJ+OVHGd81vv/22aNGi+Pj42trapUuXvv/+++hDoKenZ8mSJSkpKR0dHbGxsXp6ehkZGRDChIQE1GaWk5OzYcMG1Ex14MABCGFjY+OHH34IAPjll19Q4RKJZOXKlcnJyVIHFYvFLBYLFQghfPXq1dKlSw8dOtTe3p6YmKilpTXkd83Tp08BAMHBwUTM7du3AQCHDx+GEKLJwS5duuTn5+fk5BQWFobW1lY4YJjfNU+ePEHrVB0/fhzKdGZsbKyurq6RkRGHw5kxYwZSTHd3dwhhV1eXg4MDm81GZTY0NMyYMWPixIkQwoKCAvQ6cPXqVfRKjAQrPDx8uKcmx3eNs7Ozra2tVKSdnR2E8P79+zo6OuPGjXv+/DmKT0tLi4mJQdtyVDYIYUVFxZo1a3Jzc0tLS21sbMzNzTs6OiiaihQZ1ZYBkaqisunr63N2dgYA+Pn5+fv7//TTTxTNGDJjUFCQqakpxdIIRqB9xNXVdevWrWj76tWrDAYjMzMTQujt7b1lyxayZTo6OqhVLDw8HACQnZ2Ndjk7O1taWqLt/Px8AACHw0FBgUCwYcOG/ge9fPmyvb090fYZHBy8bt06Yu/q1auH1BGhUPjee+/p6+sTVQc55/Tp0xBCS0tLY2Pj1NTU7u7unJwcHR2dWbNmCYXCYXmGCsPVEQhhfX09oSNQpjO9vLxYLNbFixchhA0NDehvQKQOISEhhI5ACAMDA5GOQAgPHz4MACB8KxKJsrOz29vbh3tqw9URiUSira29cuVKqXikIxDCpKQkAIC1tXVXVxf8s47IV9lcXV2JVsnr16+TJYaKtbJ1RKqKDgmfz0eKYGdn19zcTDHXkBmjoqIAAMO9fKpuH3n+/Hl+fj6xkuOqVauamprWr1/P5/MvXbo0e/ZsIuX27dt7enrOnz8PAGCxWACAlStXol02NjZ1dXVo+6OPPrKysiK+zzMzMz08PKQOKhQKjx07lpiYiKbeaWlpiY+PR+3nCCpTaWhoaMTHx4tEounTp3/zzTeHDh1C94+1tfWrV68qKytdXFw8PT11dXXXrFkTHBxcVlaWnJwsj48UjVSjgAxnslgsNpuN3i+MjIyOHTsGAEBKrab2p4ohFSSjrq6+du1aFXSsNjY29vb2GhsbD5Zg48aN+/bte/To0aZNmyBpVh35KltjY2N+fj6Xy42IiIiIiLh27dqcOXP4fL5CzkWqilLh3r17xsbGe/fuLS4utre3r62tVUjGCRMmAABKS0uHZX9/lDt+5MmTJ+DPNRvZzeVyhUIhed5g9KFYUVEB+tVaFoslEomIYEhIyI4dO8rLy2fOnHn58uULFy5IHXTnzp1RUVFEB3tZWZlQKCQ3ZFC8eMuWLfv111+vX7/OZDI3bNjw448/Tp061cHBAfX+vvvuu0RKR0fHb775prS0dPPmzVRKViqyJUDKmWRXzJ07FwBAvYKqGDRNLHkpjP5ER0c/fPgwJyfn4MGDxNNCvspWWVkJAAgPDydfaEUhVUWHpKioyM/Pr7y8nM1mm5qahoSEBAcHX7lyhX5GdHbPnj1zcXGR71wQyn0fQV/dubm55MjW1lY0RojL5RKR6HwsLS2HLNPX15fNZp88efLJkydTp04lFkZAfP/993PnziUeLwCA7u5uAEBjY6Mc9puZmW3fvj0gIODf//53c3Pz0aNHGQyGmZmZnp5eQ0MDkQx9EaAn25uLlpYWk8l87733RtqQgbGwsGAwGO3t7TLSqKmpcTgcKyuro0ePEv+2y1fZUL0qLi4mR6K6RJP+VXRI4uLi5s2bhzR0x44d4eHhubm5bW1t9DOizhryKD75UK6OTJ8+XU1N7cqVK+haAgCqqqru378/e/ZsJpNZWFhIpGxtbQUALFq0aMgydXV1/fz8OBzOV199hYYhEZw7d47BYPj7+6MghPDp06cffPABAAB93xJQ6bIh6OzsPH78+A8//IAmy2AwGIsXL0YdNwj0DF+8eDH1MkcJvb29xDaXyxUIBPPmzQMAsNls1COGgBASVxAhFVQBenp65ubmLS0tspOx2eycnBwDAwNCR+SrbNOmTVNXV4+KikIrb6BcHA6HorXowwr2m7R0wCo6ZGnNzc3kDqBt27YJhcIhXUElI3ocTpkyZciiZKNcHTE2Nvb19S0vL/fw8PjXv/4VFxd34MABNze3CRMmfPbZZzU1Nbdu3UIps7KyPDw8nJycAAC///47AIDoIRaJREKhkFytd+zY0dPT097eTn54nj59+syZM2w2OyEh4fz587GxsatXr25tbZ0+fbqbm9vVq1cTEhIAAH19faWlpRDC2tpa8hv+YLS2tjo7OwcGBgYFBRGRsbGxTU1NRK26du2aq6vrRx99RM9bigF1TxKDAmQ7s7Oz8+XLl2j7xo0bc+bMcXd3BwCYmpoKBIL8/HwIYWpqKpfL7ezs7OzsFIvF48ePBwA8ePCgoKCgt7e3qanJ09OTfJcqj9mzZ/e/eerr66WaLSwsLNLS0oj7R77KZmBgEBQUVFRU5OTklJSUlJCQ4OPjg2a9jomJ8fb2Jr+Q9gepj9TQjMGq6JBlBgYGXr16lTCypKRk1qxZ6AEpd0ZEQ0ODvr4+OUZOyI2uyuiv6ezsJLrNzczM/ud//gfFi8XisLCw8ePHoz9BPD09UX9wVlaWmZkZACA0NLS6ujolJQWJ5d69e8mtzcuWLbtx4wYRRG1mUkyZMgW1hzc1NaGHj6Wl5dq1azdt2qSrqxsSElJXVyfD8rt37x4/fnz16tUXLlzov/fKlStWVlbHjx8PDQ318fHh8XgKcZcUYJj9NS9fvty+fTsAYPr06devX5ftzICAABaLtXbt2ri4uK1btzo6OtbU1KByeDyejY0NAMDQ0DAxMXHr1q0GBgZ79uxpa2urrq42NDQ0MDA4c+YMhBAN2YiKihruqcnR75uUlMRkMl+/fo2CxcXFgYGBAAAPDw8keWROnDhB9NfIV9l4PJ6vry+qS2w2m+i7mTx5MgAgMjJyMDu5XG5wcDAAwMLCIi4uDnXkya6isssUiUQRERGzZs06efJkZGTkp59+Wl1dTcUYGRkRCxYsCAsLk+X0gRixcfH19fWlpaV9fX1S8Xw+v7i4WI6h5S9fvhzuLy3Pnz9/9uyZRCKprq7u7OyUnVgikRQUFNTW1so4ikAgePToEVGtlcFwdWRYBAQEGBsbCwSCkpISqeoFIZRIJOXl5UgfKyoq+Hw+sauvr48cRGP2hnt0+cbFr1ixIicnh2Li1tZWclC+ytba2vrgwQPy+TY1NRUWFoaGhg6rHNlQKbO3t/fhw4ctLS0KyQghfPz4MZPJrKqqGq61b/P/NW8lKtARJRU+JPLpyMuXL11cXOj/3UOT6OjokpKSUVKm3Bl37dp19uxZOTK+tf/XYOSAz+cr5N8KVTJ58uSQkJCYmJgRtOHUqVNubm62trajoUy5M6akpOjo6AQEBAw344C8VfOPDIva2totW7YMttfPz280DAZREkKhMD4+/vbt293d3QcOHNi2bZuJiclIG0WV9evX29raZmRkoCZh1bNt2zYZA/NUXKZ8GQsKCgwMDKKjo+U44oD8dXXExMTk2rVrg+0lD1t6+9DU1AwODkZtgW8iU6ZMod9VKTcKFxE6ZcqXkcoAi2HxNt8tsmEwGEwmc6StwGDeBnD7CAaDoQvWEQwGQxesIxgMhi4DtI+kpaWp3g7MYNy5c2ekTVAK6Pd8XNneROrq6qQ7+MiDSdA4NAwGg5GN1Di0Ad5HYL+fFN960GRI/VdRH3EYDEZqair6z/gtY9T6HDMk/ScPw+0jGAyGLlhHMBgMXbCOYDAYumAdwWAwdME6gsFg6IJ1BIPB0IXWf3r19fWXLl2qrKx85513lixZsmDBgpcvX4rF4unTpyvKPjIvXrzgcDgtLS22trY+Pj5omd7CwkK0JjNCQ0Nj7Nix48aNmzFjxpgxY5RhxpCgpaFOnTq1Zs2a0NDQEbHh7aOysjIrK8vIyAgFXV1dybOcCwSCzMxMNPu0mpqam5ubCpbU6U9eXp5QKETr8hEMWG8RPB4vMTGxurp67Nixnp6e1FeiUGzGW7dujRkzxt7enmIhA9B/HBrFOZG+/PJLExOTmJiY0tLStra2GzduODk5jR8/npjGUrE8evSIxWKZmJigy2BnZ9fd3Q0hlEgkN27cYDAY+vr6Bw8ePH/+fHR09Lp167S1tVesWPHkyRMqhcs3N9dg1NTU/OMf/wAAfPXVVzSLAsqcD623t3cECxmWzzMyMkJCQkQiUXNzM1okYP78+VKH7ujo8PX1XbhwIVooT8Xk5+ejtdYOHTpEjh+s3kIIW1pazM3NL1y4wOfzi4qKrKysKN47ysh47ty5Y8eOUTxZhc2r+N1332lqahLr7CJ6enrs7e3PnTtH0ZphERYWdufOHQhhXV2dl5cXAGDfvn3E3nHjxk2bNo2c/ubNmxMnTtTW1i4qKhqycMXqCIQQLREyynVk9+7d9CcolLsQ6j4vKytzdHQkx6CnqL+/v1TKixcv7t+/Xw5j6NPT04Pei6V0REa93b17t5ubG5Hyyy+/tLCwoHIsJWX09/dHq7IOiWLmVUxOTt61a9eRI0ccHBzI8dra2rGxsWgif8Xy6tUrR0fH+fPnAwAmTZp0/PhxBoNx9+5dIoHUalgAgKVLl549e7a3t9fd3Z28ZoVqGP3TIP3666/E8qYjW4hsxGKxu7s7WjyUgMViLViwICEh4cSJE+R4LS0tqWVJVYa2tvakSZOkImXX27q6usbGRvjH8HEWi6WtrU3lWErKeOTIkaCgIPmm2pRHR44ePQpIS6KSmTt3LjHVkkAgyMvLi4yMjIuLq6qqItI8f/58//79EomksrIyOjo6Pj5eKBQCAK5du5acnJycnJySkoLu/OLiYhSjpqZGLF4BADA1NbW2tkarK8pg5cqVS5cuRY04cpxmf6qqqg4cOCAWi69evfr3v/8dmd3V1RUfHx8WFnby5Em0dgz483qXqampycnJ6enpKJienp6cnJyVlaUQkxADulrGcQsLC1evXs3j8VJSUpBzqqqq0D35yy+/REZGJiYmoqXChlUIj8f74osvnj17psBTy87Orq+v9/b2lorPzMw0MTHZs2cPWviCulvA4DUQMeAFpQJ5xSmEvr6+jHrr4uJSVlZ28OBBAIBIJOJwODt37qRyICVlNDEx0dPTQ3uHDfnlhMp3DVr3VENDQyAQyEjW09OzZMmSlJSUjo6O2NhYPT29jIwMCGFCQgJqHsvJydmwYQNqkULLuDc2Nn744YcAAOJzSSKRrFy5Mjk5WapwsVjMYrFQgYiJEydKfdcg9u/fDwAICAiQfVJU3rETExPRIsEJCQlo0enCwsKKioo1a9bk5uaWlpba2NiYm5t3dHRACDs7O8Ef3zVdXV0ODg5sNhuV09DQMGPGjIkTJ8o+HAJQ+K4ZzNUyjltQUICe8FevXs3NzY2NjdXV1TUyMuJwODNmzECrqbq7uw+rEAhhXl4eACA8PJzKqVH8rnF2dra1tZWKtLOzgxDev39fR0dn3Lhxz58/R/FpaWnEmjVy1EAI4WAXlApIeQ8fPjxYAql629fX5+zsDADw8/Pz9/f/6aefKB5IeRmDgoJMTU2HLEcB7SNoPfoPPvhAdjJvb+8tW7aQD6yjo4MawMLDwwEA2dnZaJezs7OlpSW5cA6Hg4ICgWDDhg39C798+bK9vT15ZZnBdOSf//wnAMDV1VW2tRTrdGRkJNIRCOHTp08lEomrqyvRUoWW/kQ1kqwjEMKQkBDiVoQQBgYGKlBHZLhaxnEPHz4MACB86OXlxWKxLl68CCFsaGhAKxYjdaBeCOqoam9vp3JqVHwukUi0tbVXrlwpFY90BEKYlJQEALC2tu7q6oJ/1hH5auBgF5QKQ+pI/3rL5/PRjW1nZ0de5m1IlJQxKioKADDkFVRA+wiVL38+n3/p0iX00EZs3769p6cHLSmG1tMmPotsbGzQVBQAgI8++sjKyor45M7MzOz/Z6FQKDx27FhiYiL522Ew0MceWkqSPuhBjRZnnDZtWlNTU35+PpfLjYiIiIiIuHbt2pw5c6TWiERITcarwImCZbua+nFZLBabzUbvF0ZGRseOHQMAIFmnXoi6uvratWsV2OHa2NjY29trbGw8WIKNGzfu27fv0aNHmzZtgqT/1OWrgY2NjRQvqBwMWG/v3btnbGy8d+/e4uJie3t7tFA0FZSUccKECQCA0tJSiqURDLs5EH3dVVZW9vT0oPuqP1wuVygUkhUH5aqoqAD9KiKLxSKvsxsSErJjx47y8vKZM2devnz5woULUoXv3LkzKiqKYoc5+lZX1HgWKeVCn3jh4eFo/foRQbarhwX57ObOnQv+WP98BGlubgYAsNlsGWmio6MfPnyYk5Nz8ODBmTNnokj5aqBSL2j/eltUVOTn51deXs5ms01NTUNCQoKDg69cuTJkUcrLiE782bNnLi4uwzq7YT8YJ02aZG1tLRaLHz58OGAC+Mfa9FwuV8o+S0vLIcv39fVls9knT5588uTJ1KlTpTpivv/++7lz5w7YxNufvr6+q1evamhokNu6FAiyrbi4mBzZ3d2tjGMNBh1Xy0BLS4vJZJKXYR8RLCwsGAxGe3u7jDRqamocDsfKyuro0aNEg7p8blHeBR2w3sbFxc2bNw+p5I4dO8LDw3Nzc9GIAdkoLyN6fycP8KOIPC/Y6Ks4PDwcLapOprW19fz587Nnz2YymeQ16NGi6lRWzdDV1fXz8+NwOF999RUacURw7tw5BoPh7++PghDCp0+fyijqq6++ev78+c6dO5U0vnbatGnq6upRUVGEH1pbWzkcTv+UbDab3PdMSC19ZLt6yOOSg729vcQ2l8sVCATz5s0bbiGKRU9Pz9zcvKWlRXYyNpudk5NjYGBA6Ih8NZD6BR0Q9GEF+00DNli9bW5uJnfxbNu2TSgUDnmySs3Y0NAAAJBjbSB5dMTd3f3o0aO3b9/+29/+Ru5tfvnyZUxMzObNmydMmPDZZ5/V1NTcunUL7crKyvLw8HBycgIAoAEmPT09aJdIJBIKheSaumPHjp6envb2dvLz8PTp02fOnGGz2QkJCefPn4+NjV29ejWqHEKhEG0QCASCXbt2HT58OCIiAvVSKwTUO0g8Hg0MDIKCgoqKipycnJKSkhISEnx8fFDrCeovJJxjamoqEAjy8/MhhKmpqVwut7Ozs7Ozk/4dKNvVMo6L2owePHhQUFCAFKSzs/Ply5eokBs3bsyZMwctWEe9kKamJk9PT/LdS5/Zs2f3v0Pq6+ulmi0sLCzS0tKIm0S+GijjgsbExHh7e6PbbDCQ+kiNv5BRbwMDA69evUqYUVJSMmvWrA8++GDIwykjI6KhoUFfX58cQxVyo+uwxsWnp6fb2Njo6Og4OTnt2LHjb3/726FDh4jOYLFYHBYWNn78+M8//9zPz8/T0xOt856VlWVmZgYACA0Nra6uTklJQeK3d+9ecuvxsmXLbty4QQRR85gUU6ZMkUgk//nPf1B119DQmD179vr1693d3VevXh0UFPTgwQOK50Kl7yA9PR193Hp4eJSVlaFIHo/n6+uL7GGz2aipv6GhYfv27QCA6dOnZ2VloWQ2NjYAAENDw8TExK1btxoYGOzZs6etrU32QQGF/prBXC37uNXV1YaGhgYGBmfOnIEQBgQEsFistWvXxsXFbd261dHRsaamZriFoKEcUVFRsg1GUOwjS0pKYjKZr1+/RsHi4uLAwEB0FZC0kTlx4gTRXyNfDRzwgkIIJ0+eDACIjIwczE4ul4vWJ7SwsIiLixMKhVBmvYUQikSiiIiIWbNmnTx5MjIy8tNPP62urqZyOGVkRCxYsCAsLGywcyRQ2Lh4gtevX9+5c6e1tXXAvXw+v7i4mKjW1Hn58iW5e0zZ0BwX39ra+uDBAz6fLyONRCIpLy/n8XgQwoqKCtmJCajoCGIwV8s4bl9fHxEMCAgwNjYWCAQlJSVSdYt6IWgvxWHy1H2+YsWKnJwcKikhhFJVUb4a2P+CNjU1FRYWhoaGDqscKvT29j58+LClpYUcSeVwis0IIXz8+DGTyayqqhrSZsXryNuBwv+vURTUdYQmSEdUcCAC6j5/+fKli4sL/V+BaBIdHV1SUjL6Dyd3xl27dp09e5ZKSsX8X4N5++Dz+fL9WKECJk+eHBISEhMTM4I2nDp1ys3NzdbWdpQfTu6MKSkpOjo6AQEBw82IGO2/k2GUjVAojI+Pv337dnd394EDB7Zt2ya9xNEoYP369ba2thkZGagtTPVs27ZNgaMHlXc4+TIWFBQYGBhER0fLcUQE1pG/OpqamsHBwaiNcDQzZcoUOfojFYUqRYTO4eTLSGVAxhDHpZkfg8FgsI5gMBi6YB3BYDB0wTqCwWDoMkA7a/9f9d96ioqKwGg98e+++25kF9NGg1bRv/YKZDT7HCOboqIiNFkkAQOSfiu6c+fOt99+q3KrMKOa9PT0+fPnj8LOYMwIgkbQE8E/6QgG0x8Gg5Gamurp6TnShmBGL7h9BIPB0AXrCAaDoQvWEQwGQxesIxgMhi5YRzAYDF2wjmAwGLpgHcFgMHTBOoLBYOiCdQSDwdAF6wgGg6EL1hEMBkMXrCMYDIYuWEcwGAxdsI5gMBi6YB3BYDB0wTqCwWDognUEg8HQBesIBoOhC9YRDAZDF6wjGAyGLlhHMBgMXbCOYDAYumAdwWAwdME6gsFg6IJ1BIPB0AXrCAaDoQvWEQwGQxesIxgMhi5YRzAYDF2wjmAwGLpgHcFgMHTRGGkDMKOO5OTk7u5ucszNmzdfvXpFBNevXz9+/HiV24UZvTAghCNtA2Z04efn989//lNTUxMFxWKxmpoag8FA2ywWq7W1lclkjqiNmNEF/q7BSLNx40YAgPAPJBKJSCRC2+rq6p6enlhEMFLg9xGMNCKRyNDQ8Pfffx9w788//+zi4qJikzCjHPw+gpFGQ0Nj48aNxHcNmXfffdfJyUn1JmFGOVhHMAOwceNGoVAoFamlpbVp0yZ1dfURMQkzmsHfNZgBgBBOnjy5vr5eKv7u3bvz5s0bEZMwoxn8PoIZAAaDsXnzZqlPm8mTJ8+dO3ekTMKMZrCOYAZG6tNGU1PT398f9f5iMFLg7xrMoHzwwQfPnj0jgg8fPrS2th5BezCjFvw+ghkU8qfN9OnTsYhgBgPrCGZQNm7cKBKJAACampp+fn4jbQ5m9IK/azCymDNnTnFxMQCgpqbG1NR0pM3BjFLw+whGFr6+vhBCe3t7LCIYGWAdwcjC09NTXV198+bNI20IZlSjsHkD0tLSFFUUZlQxY8YMTU1NfH3fShYuXGhiYqKAgqCCUIApGAxGtaSmpirk9lfkPEapqamenp4KLPDtIC0tzcvL622VWgaDga/7G4oCRxXi9hEMBkMXrCMYDIYuWEcwGAxdsI5gMBi6YB3BYDB0wTqCwWDoMgLr17S0tCQkJNy9e5fH47333nvV1dVr1qwJDQ1VvSVD0tjY+PPPP9fW1np6epqbm6PIkpKSjIyM9957z9vbW1dXV0mH7ujocHBw+Pzzz9+mH+QqKyuzsrKMjIxQ0NXV1dDQkNgrEAgyMzPFYjEAQE1Nzc3Nbdy4cao3Mi8vTygUrlq1ihz54sULDofT0tJia2vr4+NDnuGJ0P82mgAAIABJREFUx+MlJiZWV1ePHTvW09Nz2rRpFA+k2Iy3bt0aM2aMvb09xUIUjEJGoaDBEVTGtPB4PAcHh/r6epFINGvWLGTDV199NWTG3t5eGUFl8OOPPy5cuLCoqEgikRCR586dW7FixW+//ZaYmPjhhx+2trYOWU5qaqocfu7q6nJ0dExPTx9uRuooxIcUrzuEMCMjIyQkRCQSNTc3b926FQAwf/58KRs6Ojp8fX0XLlxYW1tL37bhkp+fv2zZMgDAoUOHyPGPHj1isVgmJiZIPuzs7Lq7u9GulpYWc3PzCxcu8Pn8oqIiKyury5cvUzmWMjKeO3fu2LFj1M+X+rUbuiiFlAIp28ThcExMTNB2T09PTk4ORR3ZvXu3WCweLKhYJBLJxx9/7OLi0tPTQ45/9OiRnp5eQ0MDCi5btmz79u1DliafjqgAhfiQ4nUvKytzdHQkx6CnqL+/v1TKixcv7t+/n6ZV8tHT01NTU9NfR8LCwu7cuQMhrKur8/LyAgDs27cP7dq9e7ebmxuR8ssvv7SwsKByLCVl9Pf3z83NpVIOVKiOqLp9pKSkRFtbG21ra2svXryYSq5ff/319OnTgwUVztdff11UVMThcAhTEXv27Jk6dSrxWu7i4nL27Nna2lrlWaI8lO1DMmKx2N3d3cfHhxzJYrEWLFiQkJBw4sQJcryWlpbyvhZlo62tPWnSJKnIV69eOTo6zp8/HwAwadKk48ePMxiMu3fvor11dXWNjY3wj8HKLBZLqs4MhpIyHjlyJCgoiMfjUSlKgahORxobG5OTkwsLC3k8XnJycnJyMhhoZG5lZeX3339/+PDh69evo5jCwsLVq1fzeLyUlJRLly5JBVGarq6u+Pj4sLCwkydPvn79GkU+f/58//79EomksrIyOjo6Pj6+/1oK/SkuLo6MjNy9e/fEiRP777K0tCSCZmZmfX19+fn5cvljCHp7ey9cuJCXl4eCMs6lqqoK3Yq//PJLZGRkYmKiRCIBAKSmpiYnJ6enp6Nk6enpycnJWVlZoJ9LAQA8Hu+LL74gz6KoQLKzs+vr6729vaXiMzMzTUxM9uzZc/PmzcHyCgSCvLy8yMjIuLi4qqoqIl72xR2wPlCh/6oa+vr669evJ4KmpqbW1tZTp05FQRcXl7KysoMHDwIARCIRh8PZuXMnlQMpKaOJiYmenh7aq1IU8lYDKbwjtbS0ZGdnOzo6Tpo0KTs7Ozs7G0LY2dkJSN81n3322aJFi9ra2vLy8hgMRkxMDISwoKAAPcquXr2am5srFYQQVlRUrFmzJjc3t7S01MbGxtzcvKOjIyEhAbXh5eTkbNiwATWbHThwYMgT2bRpk4aGxqVLl/z8/JycnMLCwl69egUhbG1tBQDs2LGDSFlUVAQAGPIlXI7vmidPnqxbtw4AcPz4cQihjHOJjY3V1dU1MjLicDgzZszQ0dEBALi7u0MIu7q6HBwc2Gw2KrOhoWHGjBkTJ07s71IIIRKs8PDwYdkJqb0bOzs729raSkXa2dlBCO/fv6+jozNu3Ljnz5+j+LS0NHTdIYQ9PT1LlixJSUnp6OiIjY3V09PLyMiQ7RA4SH2geDpIgg8fPjxYArTCMTIDQtjX1+fs7AwA8PPz8/f3/+mnnygeSHkZg4KCTE1NqRRF5dpRRNXtI15eXtOmTSOCUjoyduzYo0ePou3p06fPnz8fbR8+fBgAQLR3SgVdXV2Jpib0FoOqVHh4OAAACRaE0NnZ2dLSckgLLS0tjY2NU1NTu7u7c3JydHR0Zs2aJRQK//WvfwEADh48SKREj0c/Pz/ZBcrXPoLWjkE6IvtcvLy8WCzWxYsXIYQNDQ0LFiwAACB1CAkJIXQEQhgYGIh0BPbzoUgkys7Obm9vH66dQ153iUSira29cuVKqXikIxDCpKQkAIC1tXVXVxf8s454e3tv2bKFyPLJJ5/o6OigJlgZDhmsPlBhSB25fPmyvb09uemdz+ejG9vOzq65uZnigZSXMSoqCgBA5VIqUEdG1/iRa9eubd++HQBw7949CGFPT8+QWRobG/Pz87lcbkRERERExLVr1+bMmcPn8wEALBYLALBy5UqU0sbGpq6uTnZpr169qqysdHFx8fT01NXVXbNmTXBwcFlZWXJyMvI7ucMPmdf/80chSLURyDgXFovFZrPR+4WRkdGxY8cAAOhrS03tT9dXKkhGXV197dq1yuhnbWxs7O3tNTY2HizBxo0b9+3b9+jRo02bNkHSX9F8Pv/SpUuzZ88mYrZv397T03P+/HkwuENk1Af6CIXCY8eOJSYmkr/H7927Z2xsvHfv3uLiYnt7e+rtZUrKOGHCBABAaWkpxdIUwgiMH5GBg4PD5cuXMzMzly9fbmZm1n89t/5UVlYCAMLDw999912pXVK3DYvFQrMWywC9AJOLcnR0/Oabb0pLS1HPfEdHB7ELtWbZ2NgMaaQcyJYAqXMhV2u0VNXoaf1tbm4GALDZbBlpoqOjHz58mJOTc/DgwZkzZ6JILpcrFAo1NP6viqJWiYqKCjC4Q2TUB/rs3LkzKiqKPNCjqKjIz8+vvLyczWabmpqGhIQEBwdfuXJlyKKUlxGd+LNnz1S5nPvoeh8JDw8/d+5cfHz8pk2bmEwmlSxaWloAADQXMUF3d7d8BpiZmaGeXSIGfSawWCwzM7Nx48Y1NjYSu168eAEAGG2rMWhpaTGZzPfee2+kDflfLCwsGAxGe3u7jDRqamocDsfKyuro0aNE2zkakMblcolk6A4hN3X3R7H1gcz3338/d+5c4g0IERcXN2/ePKSSO3bsCA8Pz83NbWtrG7I05WVEjzfyAD8VMIp05MGDB1999dWOHTuIfiz457l/UMWSCk6bNk1dXT0qKqqvrw/Ft7a2cjgc+WxgMBiLFy8uKSkhYtCDffHixVpaWt7e3gUFBcSu8vLy8ePHT58+Xb5jKZDe3l5im8vlCgQCtAovm80WCATELgjhgD5UKnp6eubm5i0tLbKTsdnsnJwcAwMDQkdmz57NZDILCwuJNKipe9GiRTLKoVkfUJWD/SadOnfuHIPB8Pf3J5I9ffoUANDc3Ezu4tm2bZtQKBzyZJWaET0Fp0yZMmRRCkTVOtLR0YHaVhGoTw4p6JgxYwAAWVlZIpHo5s2bZWVlHR0dlZWVNTU148ePBwA8ePCgoKCgt7eXHNTR0QkKCioqKnJyckpKSkpISPDx8dm4cSMA4Pfffwd/tGIAAEQikVAoJN9XAxIbG9vU1ETUvGvXrrm6un700UcAgM8//1wkEiEpef369U8//XT06FGK703DheyZIc+ls7Pz5cuXaPvGjRtz5sxxd3cHAJiamgoEgvz8fAhhamoql8vt7Ozs7OwUi8VSLm1qavL09CTftApk9uzZ/e+Q+vp6qWYLCwuLtLQ04iaZMGHCZ599VlNTc+vWLRSTlZXl4eHh5OQEBneIgYHBYPUhJibG29ub/LLZH6Q+UuMvTp8+febMGTabnZCQcP78+djY2NWrVyNRCwwMvHr1KmFGSUnJrFmzPvjggyEPp4yMiIaGBn19fXKMKlBIay2k0Pbb3t7+7bfforsuNDT03//+d0NDA2pVnT59elZWFoRw8+bNampqhoaGp0+fPnr0qJqa2p49eyCE1dXVhoaGBgYGZ86c6R/k8Xi+vr7odNhsNmqrz8rKMjMzQ8eqrq5OSUlBCr13794h28avXLliZWV1/Pjx0NBQHx8fHo9H7Lp79+7SpUv//ve/e3t7nzhxgopn5OivefnyJeGZ69evyz6XgIAAFou1du3auLi4rVu3Ojo61tTUoHJ4PB5qvjE0NExMTNy6dauBgcGePXva2tqkfIhGcERFRQ3LTkitzT8pKYnJZL5+/RoFi4uLAwMDAQAeHh5I48icOHGC6K8Ri8VhYWHjx49H/xl5enqiEcayHTJgfYAQTp48GQAQGRk5mJ1cLjc4OBgAYGFhERcXJxQKIYSoWVeKKVOmoC4bkUgUERExa9askydPRkZGfvrpp9XV1VQOp4yMiAULFoSFhQ12jmSoXDuKqLrfd0haWlr6+vrQ9u+//07E9/X18fn8wYIQwtbW1gcPHkhFyo1AIHj06BFR9aWorq6mPqJc2ePiAwICjI2NBQJBSUmJVJWCEEokkvLyciSFFRUVMnxYUVEhxzB5itd9xYoVOTk5FMuU+muJz+cXFxdL/aNApRCp+tDU1FRYWBgaGjqscqjQ29v78OHDlpYWciSVwyk2I4Tw8ePHTCazqqqKitlvs468fahGR5RXvmwoXveXL1+6uLgo75coikRHR5eUlIz+w8mdcdeuXWfPnqWYWIH37ChqZ8XIB5/PV/3/FMNl8uTJISEhMTExI2jDqVOn3NzcbG1tR/nh5M6YkpKio6MTEBAw3Iz0GV3jR1RAbW3tli1bBtvr5+f3Bq0dJxQK4+Pjb9++3d3dfeDAgW3btilmTSPlsH79eltb24yMDNQGrHq2bdsmYyTe6DmcfBkLCgoMDAyio6PlOCJ9/nI6YmJicu3atcH2kkc9jX40NTWDg4NR0+AbwZQpU1TcH0lGlSJC53DyZZTdHa5s3qTbRiEwGAwl9dRiMH9ZcPsIBoOhC9YRDAZDF6wjGAyGLopsH/nuu++InyMwBOh/dg8Pj5E2RFng647B7yMYDIYuinwf2bVrl6enpwILfDtIS0vz8vJ6W5/YDAYDX/c3lP6zI8sNfh/BYDB0wTqCwWDognUEg8HQBesIBoOhC9YRDAZDl9H1f01BQQGaPLk/M2fOnD59enZ29qlTp9asWRMaGqpi2zAqprKyMisri1gF1dXVlTx3sUAgyMzMRPPLqqmpubm5KWPRDBnweLzExMTq6uqxY8d6enqSJ5FH5OXlCYVCtEYXQU9PT2ZmZnFxsYWFhbe399ixY4ldL1684HA4LS0ttra2Pj4+aIWTW7dujRkzBq1VMJoZXe8jjo6OxsbGmzdv3r9/v66urq6urra2dnt7+5EjR5KSkurq6hoaGn7++Wcqy2tKzcM65LSsby4KObXR5p/MzMx//OMfYWFhy5YtKygo2Lx587p168hGMpnMFStW5Ofnnzp1avHixSoWkdbW1lmzZrHZ7CNHjixbtmz9+vVowVPEzZs3ly9fvnz58vv375Nztbe3L1++vK2tbc+ePTU1NfPmzSOemo8fP7a2tj516tQPP/ywZcuW+fPnowl6nZ2dHz9+PLLztlBCIbMhQYXOraSjozNz5kxyTENDw65duyCEaH59Yv09GezevZs8+5ZUUJUoez40hZya3IUo8LoTlJWVOTo6kmPQ097f318q5cWLF4dcF1UZ7N69283t/7d3rmFNJOker3ALMRAJDiCIogPiyEXBgxcGVgVHRWQ4IAIDglweHkXEIyIyclDBUUbdeTw6IsqKF9gx3FRExHUAd5VliOgR8IrLfZQ76CBoAiGQPh9qt09vICGkQxKd+n1KV1dXvV399j/dVdX1uuCb33//vZmZGb45MDDQ3NwMAEhMTCQeFRQUtHLlSvh7ZGRkwYIF7u7ucDM6Ovr+/fsYhrW2tvr6+gIA9u7dix8YHBwMAyTKFhleO+V6HoGMDrxuaGi4fft2IPH6IM+ePUtNTRW1+Skhk1NTqvYZGRnx8vKC4QFx6HS6vb19eno6jIiOo6GhIRR4UD60trZ2dHRg/wpPQafTiU6rqak5Y8YMoUP6+vouX768du1auKmiohISElJQUPDkyZN37945OjouW7YMADBjxoxjx45RKJQHDx7gxx46dCg8PFyZV71Trv6RMXn48KGdnZ2pqSkYawZefX39X/7yl3fv3i1ZsmTdunUAgPLycn9/fw6Hk52dra6ubmRkRNyE37n09/fn5OS8fPny888/Dw4Ohr7Y0NCQnp7+3XffNTY25ubm6uvrBwcHEwNxTjY8Hq+0tLS0tNTIyMjFxQWeck5OjkAgUFdX37hxIwDg6tWrfD6fRqN5eHgInam3t3djY+PNmzejoqJ++eWX27dvm5ubwyX4J1QIh8M5fvw4jMQst3PHuXHjRltbm7+/v1B6Xl7e4sWLY2JirKysYBiQ0YzZgGC8KzumM4jH2dk5JyfnwIEDhw4dGh4eZrFYUVFRxAzEEDMQuIw2DOQOmT9/PvhX4AhPT0883cTExNLSEgYPhBgbG2trax84cOD48ePj2qYYZPJUg8n0GYnJZOLvNXw+383NDV9BXiiu+I4dO/7whz+8efOmuLiYQqHAeAVlZWXw36ywsLCoqEhoExMRj158CHsySPheMzAwsHLlyuzs7N7e3uTkZG1tbRjUvr+/38HBAQ/33d7ebm1tDcN9C51acnKylpaWoaEhi8WytraGLuvl5TWhQjAMKy4uBgDExsZKcnYyvO4QJycnGxsboUQYVPzRo0c0Gk1XV7ehoQGmE4OKi2pA8Vd2TGcY18ihoSEYqTsoKCg4OPjcuXNCGUbHG4dxsyIiIvCU0tJSMFZM8pGRETqdDo3HCQ8PNzExGdewCSHDa6ekOkKn05cvX758+XIYilGUjkydOvXw4cPwt4WFxbJly+DvgwcPAgDwoPBCm6Li0YsJYU8GCXXE398/JCQE39y4cSONRmtpacEwLDIyEpcADMPCwsKgBIw+NV9fXzqdfvnyZQzD2tvbYVBRqA6SFzI8PHzjxg1JAtZjstYRgUCgqanp6uoqlA51BMOwzMxMAIClpWV/fz/27zoipgHFXFlRzjAuXC4XSsmiRYtGR0QarSN8Pn/WrFk6Ojq4TkHHSE1NFTr2+vXrS5cuxS8HJCEhAQAg4UWREBleO2XsHwEAmJqawgfUtrY2Md+A3bp1C8aLevjwIYZheJAxMYiJRy8qhL0c4HK5V65csbW1xVO2bds2MDAAgzCJjxlOhE6nMxgM+HxhaGh45MgRAEBJScmEClFVVXV3d5fzCAiko6NjcHDQyMhIVAY/P7+9e/e+ePEiICAAI0TPFN+Aoq6sGGcYl4cPHxoZGe3Zs6eqqmrp0qXjBmZXU1NLS0sbHh62sLA4fvx4YmIilG+h+NB8Pv/IkSMZGRlCr/D6+voAgMePH0tim/xR9v4RDQ2NiIgIUU7v4OBw/fr1vLy8tWvXzp49u62tbdwCxcSjFxXCXg6w2Ww+n0/sRYavx3V1dRMtiuh/ixcvBv8KUfxR0NXVBQCAQbBFkZSU9Pz584KCggMHDixYsAAmim9AUVdWjDOIp6KiIigo6OnTpwwGw8TEJDIyMiIi4ubNm+KPWrNmzbNnz27fvk2lUjds2PCnP/1p7ty5Dg4OxDxRUVEJCQmje6aghbW1tc7OzhMyVT4o6fMIkRUrVozutYLExsZevHgxLS0tICBAwtWbJy8ePRngfCo2m42nQL8xNzcnU6yGhgaVSp01axZJ8+SGmZkZhUJ5+/atmDwqKiosFmv+/PmHDx/GV2OQrgGldoaUlJQlS5ZAvdu+fXtsbGxRURGclCCe2bNnb9u2LTQ09N69e11dXYcPHybq/o8//rh48WL8uYkIHKwhzsRTKpRUR7BRAd9HU1lZ+cMPP2zfvh0fchM6CvqW0CbJePSThK2tLZVKJYbphmGoYTABBoNBnIKFYdiYpwYZHBzEf7PZbB6Pt2TJkokWoii0tbVNTU1HBxUXgsFgFBQUMJlMXEfEN6AopHaGrq4u4n/b1q1b+Xw+0WzoiqLcuK+v79ixY2fOnCG+s1+8eJFCoQQHB+MlwK5ZCAwbrsCoHeJROh0RCAQcDufdu3dj7oWT/KA2T5kyBQCQn58/PDx8586dJ0+e9Pb21tfXNzc36+npAQAqKyvLysoGBweJmzQaTVQ8elEh7OVw1vr6+jt27Ghubr579y5Myc/P9/b2XrFiBQDAxMSEx+PBkNo5OTlsNruvr6+vr29kZEToTAEAfX19r1+/hoX8/PPPdnZ2MO6U5IV0dnb6+PgQ70l5YmtrO1pH2trahLotzMzMcnNz8ZtZfAOKurJMJlOUMxw9etTf3x/evaMJCwsrLCzEC4Rjt1988QWeAQrTmDM+enp6nJycwsLCwsPD8cTU1NTz588zGIz09PRLly4lJye7ublBKYS0t7fr6OgQq1AuZNJbi8mo7/fevXtQoSkUyu7du2HvKU57ezvsVbWwsMjPz8cwDE6OMDAwSE1NPXz4sIqKSkxMDIZhTU1NBgYGTCbz/PnzozfHjEcvPoQ9mZOScLxmZGQkOjpaT0/v22+/DQoK8vHxwSNjczgcKysrAICBgUFGRsaWLVuYTGZMTMybN2+ETi00NJROp7u7u6ekpGzZssXR0bG5uXmihdy5cwcAkJCQIMnZyeS6E8nMzKRSqXiE9qqqqrCwMACAt7c3FEEiJ0+exMdrRDWg+Cs7pjNgGDZz5kwAQHx8/JhGDg8Px8XFLVy48PTp0/Hx8d988w0xQjubzYbByczMzFJSUvh8Pkx/8ODBsWPH3NzcfvrpJ2JpsDNYiDlz5hCHbOzt7aOjo6Vu1TGR4bVTLh2Rgu7ubnxU+LfffsPTh4aGiLHmhTaxseLRTxITmhfP5XKrqqpwBcERCARPnz7lcDgYhtXV1Yk6NRgznMfjVVdXEz17QoXAvRJOk5+M675u3bqCggIJM/f09BA3RTXguIUIOUNnZ2d5efnOnTvFHDU4OPj8+fPu7m5JqhAIBGVlZS0tLUIDupJQU1NDpVIbGxsneqB4kI58TEz29zVEoI7Ipy7IZFz3169fOzs7K+p7KJykpKTq6mrF2gDZtWvXhQsXZF6sDK+d0vWPIMjA5XKV+SsMCZk5c2ZkZKRiP3I9e/asi4uLjY2NAm2AZGdn02i00NBQRRsiDqQjnwh8Pv/MmTOlpaXv37/fv3+/3GbQTRKenp5+fn7Xrl1TlAFbt25dtGiRomrHKSsrYzKZSUlJijZkHJR9HhpCQtTV1SMiImD33qfBnDlzFDjMKWa+rzwRP26tPChFYyEQiI8apCMIBIIsSEcQCARZkI4gEAiyIB1BIBCkkcksFEyCz+oQCISyIat5aDIb94WzNhGfHr6+vlFRUXBpNcQnxpdffimTcijoUQIhHgqFkpOTI2ZVOgQC9Y8gEAiyIB1BIBBkQTqCQCDIgnQEgUCQBekIAoEgC9IRBAJBFqQjCASCLEhHEAgEWZCOIBAIsiAdQSAQZEE6gkAgyIJ0BIFAkAXpCAKBIAvSEQQCQRakIwgEgixIRxAIBFmQjiAQCLIgHUEgEGRBOoJAIMiCdASBQJAF6QgCgSAL0hEEAkEWpCMIBIIsSEcQCARZkI4gEAiyIB1BIBBkQTqCQCDIgnQEgUCQBekIAoEgC9IRBAJBFqQjCASCLBQMwxRtA0K52Lp1a21tLb5ZWlpqYWGhp6cHN1VVVTMyMoyNjRVkHUIZUVO0AQilQ19f/9y5c8SUmpoa/PecOXOQiCCEQO81CGE2bdokapeGhkZwcLAcbUF8HKD3GsQYWFpavnz5ckzfqK2tNTc3l79JCGUGPY8gxmDz5s2qqqpCiRQKZcGCBUhEEKNBOoIYA39//5GREaFENTW1oKAghdiDUHLQew1ibJYtW/a///u/AoEAT6FQKC0tLTNmzFCgVQjlBD2PIMZm8+bNFAoF31RRUXFwcEAighgTpCOIsfHx8SFuUiiUzZs3K8oYhJKDdAQxNp999tmqVauIva0bNmxQoD0IZQbpCEIkAQEBsPtMVVXVxcVl2rRpirYIoaQgHUGIxMPDQ11dHQCAYVhAQICizUEoL0hHECLR1tb++uuvAQAaGhrwBwIxJkhHEOKAc+Q9PDzodLqibUEoL0hHEOJYt26djo6Ov7+/og1BKDWyn4f2P//zP/fv35dtmQgF8vTpUysrKxUV9Jfz6XDlyhXZFih757h//35FRYXMi0VAWltbr169Ks8aLS0t5SYiV69ebW1tlU9dv08myX9k/zzi7e0NJkHwEJDc3FxfX99P9WsGCoWSk5MjNAUOIUMmyX/QwyoCgSAL0hEEAkEWpCMIBIIsSEcQCARZkI4gEAiyKPt68a9evTp37hyLxfr1118Vbcs/KS4u5vP569evl3DXwMBAXl5eVVWVmZmZv7//1KlT5WXp/9Pb2+vg4PDtt99+Sgua1dfX5+fnGxoaws3Vq1cbGBjge3k8Xl5eHlzVTUVFxcXFRVdXV57mcTicjIyMpqamqVOn+vj4zJs3TyjDRL3l1atXLBaru7vbxsZm06ZN8NOnu3fvTpkyZenSpXI4IzEo+/NIU1PTvXv3lGROwZ07d9auXbt27dpHjx5JuOvt27dr16598+ZNTExMc3PzkiVLXr16JUeT/4mamtq0adO0tLQmrwoejzd5hY8mLy/v1KlT0dHRa9asKSsrCwwM9PDwINpApVLXrVtXUlJy9uzZ5cuXy1lEenp6Fi5cyGAwDh06tGbNGk9Pz/z8fHyvFN5SU1NjaWl59uzZM2fOhISELFu27MOHDwAAJyenmpqao0ePyvPsxgCTNRs3bty4caMMC9yzZ4+qqqoMC5SagYGB5uZmAEBiYqKEu4KCglauXAl/j4yMLFiwwN3dnYwNOTk5k3HVyLN79+6RkRGShQAAcnJyxs325MkTR0dHYgr8tw8ODhbKefny5X379pG0Sgp2797t4uKCb37//fdmZmb4phTeEh0dff/+fQzDWltbfX19AQB79+7FDwwODi4qKpLEsEnyH2V/HgEAwOc3ZUBTU1PUwoJj7urr67t8+fLatWvhpoqKSkhISEFBwZMnTybXULnz7Nmz1NRU+dQ1MjLi5eUlFGSHTqfb29unp6efPHmSmK6hoTGpT2GiaG1t7ejowP413YtOp2tqauJ7J+ot7969c3R0XLZsGQBgxowZx44do1AoDx48wI89dOhQeHg4h8OZ3LMSjZLqCJ/Pz83NjYuLKyoqIi41DADo7+9PS0uLjo4+ffo0fLQDADQ0NOzbt08gENSL8H6gAAAgAElEQVTX1yclJaWlpfH5fPyQX375JT4+PjU1lRgmbsxyxmV0NAYxu+rq6kZGRmg0Gp4yf/58AEB1dbWE1cmKwcHBn376qbi4GG6Kaa7GxkZ4K8JGy8jIgO2fk5OTlZWFT6m+evVqVlYWfFYvLy93c3PjcDjZ2dlwHjOHw/nuu++IwT1lyI0bN9ra2kZ/OpiXl2dsbBwTE3Pnzh1Rx/J4vOLi4vj4+JSUlMbGRjxdvP9I4SrOzs5Pnjw5cOAAAGB4eJjFYkVFRREzTMhbdHR0PD098XQTExNLS8u5c+fiKcbGxtra2rA6xSDzJxzy7zXv3r1btWpVYmLi27dvMzIyNDQ08Peaurq6r7/+uqio6PHjx1ZWVqampr29venp6bCDraCgYMOGDbDjav/+/fCQ2NhYFovF4XCysrK0tLTElCOJbfCmOnjwoCS7/vGPfwAAIiIi8JTS0lJRh0uIFM+lL1++9PDwAAAcO3YMwzAxzZWcnKylpWVoaMhisaytraFPe3l5YRjW39/v4ODAYDBgme3t7dbW1tOnT8cwrKysDD4dFBYWwqdrKFixsbETPTsgwXuNk5OTjY2NUOKiRYswDHv06BGNRtPV1W1oaIDpubm5R48ehb8HBgZWrlyZnZ3d29ubnJysra197do18Q2CSesqQ0NDTk5OAICgoKDg4OBz584JZSDjLSMjI3Q6HRqPEx4ebmJiMq5hk/Reo4w6EhER4eHhgW+6ubnhOrJ69err16/D37dv38avd2xsLADgxo0bcJeTk5O5uTmGYUNDQ9OmTautrYXpO3fuFF/OuExIR/h8/qxZs3R0dHDPg1cxNTVVkrrGRDo/aGtrw3UEE91cGIb5+vrS6fTLly9jGNbe3m5vbw8AgOoQGRmJ6wiGYWFhYVBHMAw7ePAgAEAgEMDN4eHhGzduvH37dqJ2jqsjAoFAU1PT1dVVKB3qCIZhmZmZAABLS8v+/n7s33XE398/JCQEP2Tjxo00Gq2lpUV8g0jtKlwuF0rJokWLurq6Rp+I1N5y/fr1pUuX4q0NSUhIAACM2+a/l/6R7u7utLS0NWvW4CkLFiyAPzo6OkpKSthsdlxcXFxc3K1bt+zs7LhcLgAArrLj6uoKc1pZWcEhHnV1dW1t7a+++gp6QHx8vPhyZIuamlpaWtrw8LCFhcXx48cTExPh/WZpaSnzusQj1EcgqrngLgaDAZ8vDA0Njxw5AgAoKSkBAAh99SvmI2BVVVV3d/fJGCLp6OgYHBw0MjISlcHPz2/v3r0vXrzAF5eFcLncK1eu2Nra4inbtm0bGBi4dOkSEN0gZFzl4cOHRkZGe/bsqaqqWrp0aUtLi/j8EnoLn88/cuRIRkYGMSoIAEBfXx8A8PjxY0lskzlKN3/kyZMnfD5/+vTpeAreXvX19QCA2NjYzz77TOgoIZ+m0+nDw8Pw9+nTpwMDA11dXWE/nJ6enphyZM6aNWuePXt2+/ZtKpW6YcOGP/3pT3PnznVwcJjseoUQLwHE5gKEBgcALF68GAAw7j0gN7q6ugAADAZDTJ6kpKTnz58XFBQcOHAA/xNis9l8Pl9N7f8dHvYv1NXVAdENIrWrVFRUBAUFPX36lMFgmJiYREZGRkRE3Lx5U/xRknhLVFRUQkLC6Nko0MLa2lpnZ+cJmSoTlO555P379wCAjo6O0bs0NDQAAFVVVaPzi2H9+vUNDQ1RUVGVlZV2dnYvX76UrhypmT179rZt20JDQ+/du9fV1XX48GGhfxJlRkNDg0qlzpo1S9GG/BMzMzMKhfL27VsxeVRUVFgs1vz58w8fPoyvXwEnpLHZbDwbvPHEhyuW2lVSUlKWLFkC9W779u2xsbFFRUVv3rwZ90Dx3vLjjz8uXrwYf24iAgdriDPx5InS6cgXX3wBAICvITjwZXLevHmqqqoJCQlDQ0Mwvaenh8ViiSmNw+GkpaXp6uqeOHHi3r17Hz58yMrKkqIcHPiojI21fIOYXQCAvr6+Y8eOnTlzRvkX1xgcHMR/s9lsHo+3ZMkSAACDwSBO9MIwTCgG8OiQwDJHW1vb1NS0u7tbfDYGg1FQUMBkMnEdsbW1pVKp5eXleJ6enh4AwB/+8Acx5UjtKl1dXcQRma1bt/L5fKLZUnjLxYsXKRRKcHAwXgLsmoW0t7cDAObMmTOubZOB0umIhYWFi4tLYWFheno6AGBoaOjx48cYhrW0tGhra4eHh1dUVKxYsSIzMzM9PX3Tpk1+fn4AgN9++w0AMDAwAAsZHh7m8/k8Hk8gECQkJMAbw97efu7cuXp6ekwmU1Q54wL9acyBejG7enp6nJycwsLCwsPDpWoVssDRStw2Uc0FN/v6+l6/fg1///zzz3Z2dl5eXgAAExMTHo9XUlICu+vYbHZfX19fX9/IyIienh4AoLKysqysbHBwsLOz08fHh3jTyhBbW9vROtLW1ibUbWFmZpabm4vfzPr6+jt27Ghubr579y5Myc/P9/b2XrFiBRDdIGJc5ejRo/7+/vDuHU1YWFhhYSFeYHV19cKFC+F/JGSi3pKamnr+/HkGg5Genn7p0qXk5GQ3NzcohZD29nYdHR1iFXJF5j235MdrOjs74b+Eubm5u7t7QECAlpZWZGRka2srh8PBo0MyGAzYkZ6fnz979mwAwM6dO5uamrKzs6Eq79mzp7GxkUajWVtbnzp1KjExMSQkZGhoCMOwMcsZFzabHRERAQAwMzNLSUnh8/nj7nrw4MGxY8fc3Nx++uknMm2CI0V/++vXr7dt2wYAsLCwuH37tpjm6urqCg0NpdPp7u7uKSkpW7ZscXR0bG5uhuVwOBwrKysAgIGBQUZGxpYtW5hMZkxMzJs3b5qamgwMDJhM5vnz5zEMgzM4EhISJnp2QIJx38zMTCqV+uHDB7hZVVUVFhYGAPD29oYaR+TkyZP4eM3IyEh0dLSenh78zsjHx2dgYAAT6z9dXV2iXGXmzJkAgPj4+DGNHB4ejouLW7hw4enTp+Pj47/55pumpiZ870S9BXYGCzFnzhzikI29vX10dLT4psN+V+O+kIaGhtraWoFA0NTU1NfXR9zV09NTWVnJ5XLHLUQgEHA4nP7+/srKyvfv3wvtlbwc6RAIBGVlZS0tLUJDdGSY7HnxoaGhRkZGPB6vurqa6PoQgUDw9OlTDoeDYVhdXR2x6YaGhoibcFbVRGuXREcwDFu3bl1BQYGEZfb09BA3uVxuVVUVVBDJGe0qnZ2d5eXl+EyCMRkcHHz+/Hl3d7ckVZDxlpqaGiqV2tjYOG7O352OIMZEPjoyeeWLR0Idef36tbOzM/nPeUiSlJRUXV2tWBsgu3btunDhgiQ5fy/zRxCKhcvlKvAzDQmZOXNmZGSkYj9yPXv2rIuLi42NjQJtgGRnZ9NotNDQUAXaoHTzRxRFS0tLSEiIqL1BQUGBgYHytEf+8Pn8tLS00tLS9+/f79+/f+vWrcbGxoo2SiSenp42NjbXrl2DfcDyZ+vWrcoQ06esrIzJZCYlJSnWDKQj/8TY2PjWrVui9hLnL32qqKurR0REwP6/j4I5c+YoapgTiJ3OK0/Ej1vLjU//9pAQCoVCpVIVbQUC8VGiFJqKQCA+apCOIBAIsiAdQSAQZEE6gkAgSCPzGSkbN25U9DkhEAhxyPyun5TxmmXLlu3atWsySpYnvr6+UVFRcEEw5eH+/fsnT56EsxI/PZSzzT8loP/IvFgKJuLLZanx9vYGAODfa3+8UCiUnJwcZfvMPzc319fXV+ZXTUlQzjb/lJgk/0H9IwgEgixIRxAIBFmQjiAQCLIgHUEgEGRBOoJAIMiimO/0ysvLYZzkfxqhpjZ16lRdXV1ra+spU6YoxKRJBcaFOnv27Ndff71z505Fm/MJUl9fn5+fb2hoCDdXr15NXDmdx+Pl5eXBZahVVFRcXFwmI7bOuBQXF/P5fBivD+fVq1csFqu7u9vGxmbTpk3EaNYcDicjI6OpqWnq1Kk+Pj4w1sTdu3enTJmydOlSeVsvFsU8j3z55Zd6enqbN2/esWNHfX394OBgdXX10aNHp02b5urqSlwF+9OgtbW1vb39r3/9KzFqrHJCXBFesYVITl5e3qlTp6Kjo9esWVNWVhYYGOjh4UG0gUqlrlu3rqSk5OzZs8uXL5e/iNy5c2ft2rVr16599OgRMb2mpsbS0vLs2bNnzpwJCQlZtmwZHj+4p6dn4cKFDAbj0KFDa9as8fT0hNGUnZycampqFLuG0xjIfGab5Osq6urqzps3j5hy586d6dOna2pqVlRUyNywiQIkW+NPQmDskh9++IFkOZO9ruLu3bvJr1codSFStPmTJ08cHR2JKfB/Ozg4WCjn5cuX9+3bJ4VV5BkYGIAP4ImJicT06Ojo+/fvYxjW2trq6+sLANi7dy/ctXv3bhcXFzzn999/b2Zmhm8GBwfDYKkT5RNcVxEGGSKyatWqCxcuDA4Oenl5yfk/bbL5KFZCevbsWWpqqjIUIiEjIyNeXl4wiigOnU6HsROFJm5qaGgIxSeVG5qamjNmzBBKfPfunaOj47JlywAAM2bMOHbsGIVCefDgAdzb2tra0dGB/WvCGJ1O19TUxI89dOhQeHi48qyAqXTO7erqumrVqr/+9a9XrlwJCAgAAPT39+fk5Lx8+fLzzz8PDg6GrtDQ0JCenv7dd981Njbm5ubq6+sHBwfj75a//PLL7du3Z86cqaKismXLFpg4ZjkkaWxsTE9PT0xMvH37dk1Nza5du9TV1cesiBgVLScnRyAQqKurw2+Rrl69yufzaTSah4cHeZNweDxeaWlpaWmpkZGRi4uLqamp+KrLy8v9/f05HE52dra6urq3t3djY+PNmzejoqJge5qbmwcGBqqoqEyoEA6Hc/z4cV9f39GhJMlz48aNtrY2f39/ofS8vLzFixfHxMRYWVl99dVXkrcPGM+1pPYiYlgsiI6OjqenJ75pYmJiaWkJo4UCAJydnXNycg4cOHDo0KHh4WEWixUVFYVnNjY21tbWPnDgwPHjxyU0YHKR+ROO5O8106dPF3qvgezbtw8AEBoaimFYXV3d119/XVRU9PjxYysrK1NT097e3vT0dNiLVlBQsGHDBthxhUeBj42NZbFYHA4nKytLS0sLJo5ZjnjzwHjP2BkZGTAOcXp6OgxAXV5eLqqivr4+8K/3mv7+fgcHBwaDActpb2+3traePn26JI0m4XPpwMDAypUrs7Oze3t7k5OTtbW1r127Jr7qsrIy+MdeWFhYVFSUnJyspaVlaGjIYrGsra1pNBoAwMvLa0KFYBhWXFwMAIiNjZXk7MZtcyGcnJxsbGyEEhctWoRh2KNHj2g0mq6ubkNDA0zPzc3FY9mIah/xriWFF+HAmJAHDx4UlWFkZIROp0MzMAwbGhpycnICAAQFBQUHB587d04of3h4uImJiYS143yCcSdE6cif//xnAMDq1asxDFu9ejUeeQgG64QXNTY2FgBw48YNuMvJycnc3BzDsKGhoWnTptXW1sJ0PLyIqHLEIIlPx8fHQx3BMOwf//iHQCAQVRFRRzAMi4yMxO9DDMPCwsJkqyP+/v4hISH45saNG2k0WktLi/iqYYB7PH6Kr68vnU6/fPkyhmHt7e3w8zmoDpIXAseq3r59K8nZTUhHBAKBpqamq6urUDrUEQzDMjMzAQCWlpb9/f3Yv+uImPYR5VqYVF5EtFa8jly/fn3p0qXE4DVcLhdKyaJFi7q6uoTyJyQkAAAkbFicT7B/RBTwrU9PT6+jo6OkpITNZsfFxcXFxd26dcvOzg6GX6TT6QAAPGCylZVVa2srAEBdXV1bW/urr76Clxne52LKIQn8l4aBGufNm9fZ2SlhRUKrBMt20WAul3vlyhX4iATZtm3bwMAADMsmedV0Op3BYMDnC0NDwyNHjgAASkpKJlSIqqqqu7v7ZAyRdHR0DA4OGhkZicrg5+e3d+/eFy9eBAQEYIQv08S3jyjXmjwvAgDw+fwjR45kZGQQ338fPnxoZGS0Z8+eqqqqpUuXtrS0EA/R19cHADx+/FgmBpBE6fpHAAC1tbUAAAsLi/r6egBAbGwsDA1PRMhx6XT68PAw/H369OnAwEBXV1fY2aanpyemHJIQrzoAYPIqmhBsNpvP5xN7duFbd11d3USLIp7g4sWLAQBC3qxAurq6AAAMBkNMnqSkpOfPnxcUFBw4cGDBggUwUXz7iHKtSb24UVFRCQkJxC6kioqKoKCgp0+fMhgMExOTyMjIiIiImzdv4hmgGbW1tc7OzjK3Z6Io3fPI0NBQYWGhmpqap6cnHNCpqqoiZnj//r34EtavX9/Q0BAVFVVZWWlnZ/fy5UvpypECuVUkHjjhis1m4ynQ58zNzckUq6GhQaVSZ82aRdI8WWFmZkahUN6+fSsmj4qKCovFmj9//uHDh/G1LKRrn8m7uD/++OPixYvxJyBISkrKkiVLoEpu3749Nja2qKgIzh6AwMd24nQ7BaJ0OvLDDz9AFbCwsJg3b56qqmpCQgIMzg4A6OnpYbFYYg7ncDhpaWm6uronTpy4d+/ehw8fsrKypChHOiSviMFgEAe2MQyDzi0TbG1tqVRqeXk5ngID08NYJ+NWTdwcHBzEf7PZbB6Pt2TJkokWMkloa2ubmpp2d3eLz8ZgMAoKCphMJq4j4ttHFCS9CL5YYaMW/rh48SKFQgkODsazwXmYXV1dxCGerVu38vl84sm2t7cDABQYwYeIwnSEz+fDi4fD4/F27dp18ODBuLi4w4cPAwCYTGZ4eHhFRcWKFSsyMzPT09M3bdoEOyN+++03AMDAwAA8dnh4mM/n83g8gUCQkJAAvd/e3n7u3Ll6enpiyiF/FgAA/C9RTEVwniI+4G9iYsLj8UpKSmDXF5vN7uvr6+vrk8ntp6+vv2PHjubm5rt378KU/Px8b2/vFStWiK9aT08PAFBZWVlWVgbbsK+v7/Xr17CQn3/+2c7ODsavk7yQzs5OHx8f4k0rQ2xtbUfrSFtbm1C3hZmZWW5uLn5bim8fUa4l5uIePXrU398f3tiigOojNOMjNTX1/PnzDAYjPT390qVLycnJbm5u8L4ICwsrLCzEzaiurl64cOEXX3yBH9ve3q6jo0NMUSQy77mVZLzm73//O3RHNTU1W1tbT09PLy8vNze38PDwyspKYk4Oh7N582ZoKoPBgL3l+fn5s2fPBgDs3LmzqakpOzsbqvKePXsaGxtpNJq1tfWpU6cSExNDQkKGhoZElSMeMN7YwdWrV+ELrbe395MnT8QY3N7evm3bNgCAhYVFfn4+zGZlZQUAMDAwyMjI2LJlC5PJjImJefPmjXirJOxvHxkZiY6O1tPT+/bbb4OCgnx8fAYGBnALRVXd1NRkYGDAZDLPnz+PYVhoaCidTnd3d09JSdmyZYujo2Nzc/NEC7lz5w4AICEhYVybsYmP+2ZmZlKp1A8fPsDNqqqqsLAweEWgxhE5efIkPl4jqn3EuFZXV5coL5o5cyYAID4+XpSdbDYbBio0MzNLSUnh8/kYhsFuXSHmzJkDh2yGh4fj4uIWLlx4+vTp+Pj4b775pqmpiVimvb19dHS05G0F+QTHfSWnp6ensrKSy+WOm1MgEHA4nP7+/srKyvfv30tdDkZuXrwkFQkEgqdPn3I4HAzD6urqJLRqQn7A5XKrqqpwBZGk6qGhIXwzNDTUyMiIx+NVV1cLObHkhcC9Ek6Tl6LN161bV1BQIGHmnp4e4qao9hm3EKGL29nZWV5ejk8ykCGDg4PPnz/v7u4WSq+pqaFSqY2NjRMt8HetIwqBjI5MHpP9fQ0RqCPyqQsiRZu/fv3a2dmZ/DdBJElKSqqurpZbdbt27bpw4YIUB/6O5o8glAQul6s8X3CIYubMmZGRkYr9/vXs2bMuLi42NjbyqS47O5tGo4WGhsqnOklAOoIYAz6ff+bMmdLS0vfv3+/fvx9OxFJaPD09/fz8rl27pigDtm7dumjRIvnUVVZWxmQyk5KS5FOdhCjjPDSEwlFXV4+IiIBdgx8Fc+bMUeAIqGynI4tH/OC0okDPIwgEgixIRxAIBFmQjiAQCLIgHUEgEGSZlH7W1tbW3NzcyShZzty/f1/RJggDTZJn83I4HCqVKrd1IZWwzT8lJqt5ZT4jBa61h0AglBaZ3/UU7BONXI+QFRQKJScnx8fHR9GGIJQX1D+CQCDIgnQEgUCQBekIAoEgC9IRBAJBFqQjCASCLEhHEAgEWZCOIBAIsiAdQSAQZEE6gkAgyIJ0BIFAkAXpCAKBIAvSEQQCQRakIwgEgixIRxAIBFmQjiAQCLIgHUEgEGRBOoJAIMiCdASBQJAF6QgCgSAL0hEEAkEWpCMIBIIsSEcQCARZkI4gEAiyIB1BIBBkQTqCQCDIgnQEgUCQBekIAoEgC9IRBAJBFqQjCASCLEhHEAgEWZCOIBAIsqgp2gCE0vHu3TsMw4gpHA6nt7cX39TS0lJXV5e7XQjlhSLkMQiEs7Pz3bt3Re1VVVVta2szMDCQp0kIJQe91yCE+eabbygUypi7VFRUli9fjkQEIQTSEYQw3t7eampjv/BSKJTNmzfL2R6E8oN0BCEMk8lcvXq1qqrq6F0qKioeHh7yNwmh5CAdQYxBQECAQCAQSlRTU3N1ddXR0VGISQhlBukIYgz+8z//k0qlCiUKBIKAgACF2INQcpCOIMZgypQpnp6eQoO7VCp1/fr1ijIJocwgHUGMjb+/P5/PxzfV1dW9vb1pNJoCTUIoLUhHEGOzdu1aBoOBb/L5fH9/fwXag1BmkI4gxkZdXd3Pz09DQwNu6ujorFq1SrEmIZQWpCMIkfj5+Q0NDQEA1NXVAwICRE0qQSDQvHiESAQCgZGRUVdXFwCgrKzM0dFR0RYhlBT0PIIQiYqKChzoNTQ0dHBwULQ5COUF6QhCHH5+fgCAzZs3i/riBoEA6L0GMS6WlpZZWVkLFixQtCEIJQabIIq2F4FATDo5OTkTkgVpeuCjoqLs7e1lbjpisvH19f1Ur92JEycAALt27VK0IZ8Cvr6+Ez1EGh2xt7f38fGR4kCEYvH19f1Ur92VK1cAAJ/kqckfKXQE9bMiEAiyIB1BIBBkQTqCQCDIgnQEgUCQBekIAoEgy8f05dWrV6/OnTvHYrF+/fVXRdvyT4qLi/l8vtDqPq9evWKxWN3d3TY2Nps2bRJaDai6uvratWuzZs3y9/fX0tKSr70Tpre318HB4dtvvw0KClK0LbKkvr4+Pz/f0NAQbq5evZq4CD6Px8vLyxsZGQEAqKiouLi46Orqyt/IiXoXh8PJyMhoamqaOnWqj4/PvHnzAAB3796dMmXK0qVLJ9dWKeahTXSOiqz429/+9uWXX6qqqiqkdiFKSkrWrFkDAEhMTCSmv3jxgk6nGxsbwwu8aNGi9+/f43svXry4bt26X3/9NSMj4z/+4z96enrkabMU166/v9/R0fHq1auTZBKGYYODg+QL2bhx48aNGyXMfO3atcjIyOHh4a6uri1btgAAli1bJmRGb2/v5s2bv/zyy5aWFvLmTRQpvKu7u9vU1PSnn37icrkVFRXz58+/fv063HXx4sUjR45IXrsUfvIx6QiGYXv27FESHRkYGGhubh59paOjo+/fv49hWGtrKxyH37t3L9z14sULbW3t9vZ2uLlmzZpt27bJ02bFXjtR7N69e2RkhGQhkuvIkydPHB0diSnwfzs4OFgo5+XLl/ft20fSMOmQwrt2797t4uKC5/z+++/NzMzwzeDg4KKiIglrl8JPPrL+EeUJB6mpqTljxgyhxHfv3jk6Oi5btgwAMGPGjGPHjlEolAcPHsC9MTExc+fOxZ+lnZ2dL1y40NLSIk+zlY1nz56lpqbKrbqRkREvL69NmzYRE+l0ur29fXp6+smTJ4npGhoainrxlMK7WltbOzo6sH99uUKn0zU1NfFjDx06FB4ezuFwJsngj0BH+Hx+bm5uXFxcUVGRUDCE/v7+tLS06Ojo06dPf/jwASY2NDTs27dPIBDU19cnJSWlpaUR1xn95Zdf4uPjU1NTz507J76ccRkd4UVHR8fT0xPfNDExsbS0nDt3LtysqqoyNzfH986ePXtoaKikpETC6hTC4ODgTz/9VFxcDDfFtG1jYyO8D2ELZ2RkwIuVk5OTlZV19epVmO3q1atZWVn5+fkAgPLycjc3Nw6Hk52dDSekcjic7777rra2dpJO58aNG21tbaMXiMzLyzM2No6Jiblz546oY3k8XnFxcXx8fEpKSmNjI54u3t+kcy0wce9ydnZ+8uTJgQMHAADDw8MsFisqKgrPbGxsrK2tDfdOChN6epHumYcM7969W7VqVWJi4tu3bzMyMjQ0NPD3mrq6uq+//rqoqOjx48dWVlampqa9vb3p6emww6ygoGDDhg2wj2r//v3wkNjYWBaLxeFwsrKytLS0xJQjiW3wPjl48KCoDCMjI3Q6/dq1axiG9fT0AAC2b9+O762oqAAAyPPJeaLX7uXLlzDq1bFjxzAME9O2ycnJWlpahoaGLBbL2toaLgft5eWFYVh/f7+DgwODwYBltre3W1tbT58+HcOwsrIy+GhQWFgIn7qhYMXGxk701CR8r3FycrKxsRFKXLRoEYZhjx49otFourq6DQ0NMD03N/fo0aPw98DAwMqVK7Ozs3t7e5OTk7W1teFlFe9vUrsWNkHvwjBsaGjIyckJABAUFBQcHHzu3Dmh/OHh4SYmJpJULcU9ruw6EhER4eHhgW+6ubnhOrJ69Wq8J+n27dv49YuNjQUA3LhxA+5ycnIyNzfHMGxoaGjatGm1tbUwfefOneLLGZdxr/T169eXLl0qEAgwDPvb3/4GADhw4AC+F/6nBQUFSVKXTJDi2rW1teE6goluWwzDfH196XT65cuXMQxrb2+HXwNCdYiMjMR1BMOwsKP1S3kAABYpSURBVLAwqCMYhh08eBAAAJsIw7Dh4eEbN268fft2oqcmiY4IBAJNTU1XV1ehdKgjGIZlZmYCACwtLfv7+7F/1xF/f/+QkBBidTQaDXbBimkTqV0Lm6B3QbhcLpSSRYsWdXV1CeVPSEgAAEjStlL4iVK/13R3d6elpcGOawi+CkZHR0dJSQmbzY6Li4uLi7t165adnR2XywUA0Ol0AICrqyvMaWVl1draCgBQV1fX1tb+6quv4BWNj48XXw5J+Hz+kSNHMjIy4ApA8PIQ+3cGBgYAANOnTydf1+Qh1EEgqm3hLgaDAZ8vDA0Njxw5AgCAb20qKv/mZkKbRFRVVd3d3SdpkLWjo2NwcNDIyEhUBj8/v71797548SIgIAAjLJHB5XKvXLlia2uLp2zbtm1gYODSpUtAdJtMnmuBUd4FefjwoZGR0Z49e6qqqpYuXSrU9aavrw8AePz4sUwMEEKp5488efKEz+cT7zS81err6wEAsbGxn332mdBRQm5Kp9OHh4fh79OnTwcGBrq6usJ+NT09PTHlkCQqKiohIQGOBQAAjI2NAQC9vb14BtjpZWVlJdt6ZYt4CSC2LSBcHQDA4sWLAQBK1YsMF5olBtMYTVJS0vPnzwsKCg4cOID/abHZbD6fT1zmGvZK1NXVAdFtMnmuBUZ5FwCgoqIiKCjo6dOnDAbDxMQkMjIyIiLi5s2beAZoRm1trbOzs8ztUernkffv3wMAOjo6Ru+C8RCqqqpG5xfD+vXrGxoaoqKiKisr7ezsXr58KV054/Ljjz8uXrwY/48CAMyePVtXV5d4Lq9evQIAWFpakqxLOdHQ0KBSqbNmzVK0If+PmZkZhUJ5+/atmDwqKiosFmv+/PmHDx+GXb8AADghjc1m49ngPUnsNR/NJLkWGMu7AAApKSlLliyBKrl9+/bY2NiioqI3b97gGeD/FnG6nQxRah354osvAADwNQQHvjfOmzdPVVU1ISEBBkYAAPT09LBYLDGlcTictLQ0XV3dEydO3Lt378OHD1lZWVKUgwMffbFRa8RdvHiRQqEEBwfj2f7xj39oaGj4+/uXlZXh2Z4+faqnp2dhYSFJXR8Fg4OD+G82m83j8ZYsWQIAYDAYPB4P34VhGLwzcYQ2JwltbW1TU9Pu7m7x2RgMRkFBAZPJxHXE1taWSqWWl5fjeWCv+R/+8Acx5ZBxLTBB7wIAdHV1EYd4tm7dyufziSfb3t4OAJgzZ46EBkwIpdYRCwsLFxeXwsLC9PR0AMDQ0NDjx48xDGtpadHW1g4PD6+oqFixYkVmZmZ6evqmTZvgosS//fYb+FfvAwBgeHiYz+fzeDyBQJCQkAB93d7efu7cuXp6ekwmU1Q54wL9Q2hMPjU19fz58wwGIz09/dKlS8nJyW5ubtDtvv322+HhYSglHz58OHfu3OHDh0eH41Yq4FAlfo6i2hZu9vX1vX79Gv7++eef7ezsvLy8AAAmJiY8Hq+kpATDsJycHDab3dfX19fXNzIyoqenBwCorKwsKysbHBzs7Oz08fEh3rGyxdbWdrSOtLW1CXVbmJmZ5ebm4relvr7+jh07mpub7969C1Py8/O9vb1XrFgBRLeJGNc6evSov78/vLFFMVHvCgsLKywsxM2orq5euHAh/CeGtLe36+joEFNkyYR6ZaXryyVDZ2cnVH1zc3N3d/eAgAAtLa3IyMjW1lYOh7N582Z4FgwGA3aM5+fnz549GwCwc+fOpqam7OxsKMB79uxpbGyk0WjW1tanTp1KTEwMCQkZGhrCMGzMcsaFzWZHREQAAMzMzFJSUvh8PoZhsONNiDlz5uCd6g8ePFi1atUf//hHf3//kydPTlqzjc1Er93r16+3bdsGALCwsLh9+7aYtu3q6goNDaXT6e7u7ikpKVu2bHF0dGxuboblcDgc2A1kYGCQkZGxZcsWJpMZExPz5s2bpqYmAwMDJpN5/vx5DMPg9I2EhISJnpqE476ZmZlUKvXDhw9ws6qqKiwsDADg7e0NZY7IyZMn8fGakZGR6OhoPT09+KmRj4/PwMAAJtbfurq6RLnWzJkzAQDx8fGi7JTCu4aHh+Pi4hYuXHj69On4+PhvvvmmqamJWKa9vX10dLQkjSnFPa7sOgJpaGiora0VCARNTU19fX3EXT09PZWVlVwud9xCBAIBh8Pp7++vrKwkfvMy0XLI09TURH4muBRM6rULDQ01MjLi8XjV1dVCHoxhmEAgePr0KYfDwTCsrq6O2M5DQ0PEzbq6OikaR/J58evWrSsoKJCwWKEPoLhcblVVFVQQyRntWp2dneXl5fjMAxkyODj4/Pnz7u5uofSamhoqldrY2ChJIVL4iVKP1+CYmprCH6Pf7j777DMJ+8MpFMqUKVMAAIsWLRq9V/JyyDNJ76jKgIaGho2Nzeh0CoVibW0Nf+NTMCHq6urE4XChvTLnT3/6U3Bw8Pr168UMP+MIuQSNRiOO/krIaNcyMDC4cOEC3schQ6hU6pg992lpaWfOnPn8889lXiNEqftHEB8RXC538j7fkCEzZ86MjIw8evSoAm04e/asi4vLmII7GWRnZ9NotNDQ0Mmr4uN4HpEzLS0tISEhovYGBQUFBgbK0x4lh8/np6WllZaWvn//fv/+/Vu3boWTZZQWT09PGxuba9euwW5g+bN161ZJnoZkQllZGZPJTEpKmtRakI6MgbGx8a1bt0TtJc5HQgAA1NXVIyIiYL/gx8KcOXMU+HYpNxEB4w1Oywp0S4wBhUJR8uFYBEKpQP0jCASCLEhHEAgEWZCOIBAIskjTP3L//n2Z24GQD5/qtYOf6ufm5irakN8rE5q1ho36agiBQHx6yGM+a05Ozsce2D03N9fX1/f3JosUCuUTuHZj4u3tDQDAv9BFkIG4joyEoP4RBAJBFqQjCASCLEhHEAgEWZCOIBAIsiAdQSAQZEE6gkAgyCL77/TKy8thiON/VqCmNnXqVF1dXWtra7iM0MdOb2+vg4MDXF9P4TW+evXq3LlzLBbr119/lY8xnzz19fX5+fl4GObVq1cT11jn8Xh5eXlwYWoVFRUXF5dJirYjnuLiYj6fD8P3AQDu3r07ZcqUpUuXyt8SiOyfR7788ks9Pb3Nmzfv2LGjvr5+cHCwurr66NGj06ZNc3V1hWtbf9SoqalNmzZNnhGkxdTY1NR07949PBiVAiGuCK/YQsiQl5d36tSp6OjoNWvWlJWVBQYGenh4EK2iUqnr1q0rKSk5e/bs8uXL5S8id+7cWbt27dq1ax89eoQnOjk51dTUKHJxJinms0oy101XV3fevHnElDt37kyfPl1TU7OiomKilcqcnJwcKc5dOdmzZw8eq1Q8El476di9ezf5RWelLkTy9VnF8OTJE0dHR2IKDDQVHBwslPPy5cvyDMxMZGBgAD7vJyYmCu0KDg6GgVBJIoWfTFb/CAwCRGTVqlUXLlwYHBz08vJS+N/OpwRxcVNF8ezZs9TUVGUoRGpGRka8vLxgXFEcOp0OQy+ePHmSmK6hoSHPB1IimpqaM2bMGHPXoUOHwsPDFbK6pVzXMXJ1dV21atVf//rXK1euBAQEAAD6+/tzcnJevnz5+eefBwcHw2vT0NCQnp7+3XffNTY25ubm6uvrBwcH43fLL7/8cvv27ZkzZ6qoqGzZsgUmjlmOTBhd3eDg4JUrVwwMDPDAw1wu96effuru7p4/f/6qVasYDIaKigqFQvn1118vXbq0d+/erq4uGJjez89PR0ensbHxypUrGhoaISEhTCYTr4vH45WWlpaWlhoZGbm4uOCrW4+ukc/nX79+vbq6euXKlTAwmAwZ04ycnByBQKCurr5x40YAwNWrV/l8Po1G8/DwKC8v9/f353A42dnZ6urq3t7ejY2NN2/ejIqKgq1nbm4eGBiooqIyoUI4HM7x48d9fX2J0Scnjxs3brS1tfn7+wul5+XlLV68OCYmxsrK6quvvhrzWFEXTrwnS+20xHhXRIyNjbW1tQ8cOHD8+HEJi5IZk/TMM336dKH3Gsi+ffsAAKGhoRiG1dXVff3110VFRY8fP7aysjI1Ne3t7YX3GwCgoKBgw4YNsCcJj9IeGxvLYrE4HE5WVpaWlhZMHLMc8eZJ+F4zurqXL196eHgAAI4dOwbz9PT0mJqaZmRkDA0NwdDzs2fPdnR0zMrKgsuUXrlyJTAwcNOmTaqqqhs2bCgtLf3mm282bdqkpqbm6uqK1zUwMLBy5crs7Oze3t7k5GRtbe1r166NWeO7d+9WrVqVmJj49u3bjIwMDQ0NGb7XiDKjv7/fwcGBwWDAbO3t7dbW1tOnT8cwrKysDP6NFxYWFhUVJScna2lpGRoaslgsa2trGo0GAPDy8ppQIRiGFRcXAwBiY2MlOTXy7zVOTk42NjZCiYsWLcIw7NGjRzQaTVdXt6GhAabn5ubioW1EtZh4T5bCaXHgP8fBgwdH7woPDzcxMZnwyf87Et7j/3bIJNUhSkf+/Oc/AwBWr16NYdjq1avxyEAw+CZsZXg33rhxA+5ycnIyNzfHMGxoaGjatGm1tbUwHQ//IaocMUiiI6Kqa2trI97VUVFRDAYDRiqCYbH/+7//G+46ePAg8UTgCqZ//vOf4SaUVDwcj7+/f0hICF77xo0baTRaS0vL6BojIiI8PDzwnG5ubjLUETFmREZG4hKAYVhYWBiUAPxM8XBfvr6+dDr98uXLGIa1t7fb29sDAKA6SF7I8PDwjRs33r59K8mpkdQRgUCgqalJlHUI1BEMwzIzMwEAlpaW/f392L/riJgWE+XJmFROS7RWlI4kJCQAACRsNFFIoSPynj8CX9709PQ6OjpKSkrYbHZcXFxcXNytW7fs7OxgeEQ6nQ4AwMMgW1lZwfEIdXV1bW3tr776CrZ7fHw8AEBMOSQZszoAgNDzZ319PXyLAQAYGxubmZn98ssvxJzLly+HmwsXLgQAODo6wk0YIRFqBJfLvXLlCjE2yrZt2wYGBmAINWKN3d3daWlp+AsOAGDBggXkTxYi3gyh1YnFLFZMp9MZDAZ8vjA0NDxy5AgAoKSkZEKFqKqquru7y2dApKOjY3Bw0MjISFQGPz+/vXv3vnjxIiAgACN8Ji6+xUR58uQ5rb6+PgDg8ePH5IuaEPJe57m2thYAYGFhUV9fDwCIjY0dHX1KyLfodPrw8DD8ffr06cDAQFdXV9j7paenJ6Yc8oyubrR5jo6Ot27devjwob29PY/Ha29vd3NzI54I/hW20NrRsCuaz+cDANhsNp/PJ65ED8NB1dXVCdX45MkTPp8/ffp0PEWKr7xFId6MCUG0avHixQAA+LCmnHR1dQEAGAyGmDxJSUnPnz8vKCg4cOAArt2SXzhA8OTJc1pYYG1trbOzs2xLFo9cn0eGhoYKCwvV1NQ8PT3hXVRVVUXM8P79e/ElrF+/vqGhISoqqrKy0s7O7uXLl9KVIyGjqxudZ9euXRs3boyNjb1z505MTMyXX3753XffTbQiOK+JzWbjKdAhzM3NhXLCU+vo6JhoFbI1Y0JoaGhQqdRZs2aRNG/yMDMzo1Aob9++FZNHRUWFxWLNnz//8OHD+EIn0rXY5DktfN4nTpyTD3LVkR9++AHelhYWFvPmzVNVVU1ISIBx1QEAPT09LBZLzOEcDictLU1XV/fEiRP37t378OFDVlaWFOVIyJjVjc5GoVCMjIxOnDghEAi2b99eUlKira090bpsbW2pVGp5eTmeAoPIjw4+At+G4KsWjqyGbMSbwWAwiAP2GIbBuwiHuDk4OIj/ZrPZPB5vyZIlEy1Ebmhra5uamnZ3d4vPxmAwCgoKmEwmriOSXzgiJJ0WvlhhY63C1d7eDhQR+HVSdITP58PWxOHxeLt27Tp48GBcXNzhw4cBAEwmMzw8vKKiYsWKFZmZmenp6Zs2bfLz8wMA/PbbbwCAgYEBeOzw8DCfz+fxeAKBICEhATqovb393Llz9fT0xJRDkjGrAwB8+PAB/Ev4AQB//OMfS0tLW1pa1NXV+/r6ampq8LcwoZzwFYZ4XvhefX39HTt2NDc33717F+7Nz8/39vZesWKFUDkWFhYuLi6FhYXp6ekAgKGhocePH2MY1tLSgtcrNeLNMDEx4fF4JSUlGIbl5OSw2ey+vr6+vr6RkRHYMpWVlWVlZbDF+vr6Xr9+DQv5+eef7ezsYPA6yQvp7Oz08fEh3qKTiq2t7WgdaWtrE+q2MDMzy83NxUdexbeYKE8W47RHjx719/eHciAKqD5jzhNpb2/X0dGBfzZyReZ9uX//+9+hx6ipqdna2np6enp5ebm5uYWHh1dWVhJzcjiczZs3QzMYDAbsvs7Pz589ezYAYOfOnU1NTdnZ2VBc9+zZ09jYSKPRrK2tT506lZiYGBISMjQ0JKoc8UgyXtPf3z+6utevX2/btg0AYGFhcfv2bQzDbt68qampSWzSWbNmFRcXFxcXW1lZAQDCw8Nra2v/8pe/wG6CgICAp0+f/u1vf4Mdrhs3bqypqcEwbGRkJDo6Wk9PD35H4+PjA+Paj66xs7MT/t2Zm5u7u7sHBARoaWlFRka2traSvHZizIDtDM/IwMAgIyNjy5YtTCYzJibmzZs3TU1NBgYGTCbz/PnzGIaFhobS6XR3d/eUlJQtW7Y4Ojo2NzdPtJA7d+4AABISEsQbDCE/7puZmUmlUj98+AA3q6qqwsLCAADe3t5Q9YicPHkSH68R1WJiPLmrq0uU086cORMAEB8fL8pONpsNB/7MzMxSUlLgQCGOvb19dHQ0mXbAlGrcV3J6enoqKyu5XO64OQUCAYfD6e/vr6ysfP/+vdTlYJLpiPjqcK5cuZKVlfXmzZva2tqqqqq7d+8mJyevXLlSEjNGw+Vyq6qq8FtXDA0NDbW1tQKBoKmpCR88Fo/k106UGQKB4OnTpxwOB8Owuro6YmsPDQ3hm6GhoUZGRjwer7q6uqmpSbpC4F4Jp8nLZF78unXrCgoKJMzc09ND3JT8wgkVIuS0nZ2d5eXl+CSDCVFTU0OlUhsbG6U4lshHqSMKQVbf19TX1+vr6wv9J3R1dQUGBpIvXObI7dpBHZFDRTgy0ZHXr187OzuT/0qIJElJSdXV1VIcuGvXrgsXLpA3QAo/QeuPkKKlpaW7uzswMPDvf/97S0tLS0vLnTt3/uu//gtOB/rdwuVyFfKVB0lmzpwZGRmpyK9mATh79qyLi4uNjc1ED8zOzqbRaKGhoZNh1bggHSGFk5NTUVGRnp5eeHi4ubn5+vXri4qKzp07h39h8XuDz+efOXOmtLT0/fv3+/fvV4YFDSaEp6enn5/ftWvXFGXA1q1bFy1aNNGjysrKmExmUlLSZJgkCfKeh/bpsWbNGji7FMMwGU4J+0hRV1ePiIiAHYEfKXPmzJH/uCmOmAm+YhA/zCwH0POIzEAigvjdgnQEgUCQBekIAoEgC9IRBAJBFmn6WU+cOPGxB2SG4wgwuPTvik/g2o1JRUUF+F1eUCWBgo31tY8Y0KVCID55oqOj4epTEjJhHUEgEAghUP8IAoEgC9IRBAJBFqQjCASCLEhHEAgEWf4PaPCxdyMfIGoAAAAASUVORK5CYII=",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = models.load_model('models/model_128_filters_1_conv_layers_128_dense_units_16000_batch_size_1_depth_500_batches.h5')\n",
    "tf.keras.utils.plot_model(\n",
    "    model,\n",
    "    to_file='models/model_128_filters_1_conv_layers_128_dense_units_16000_batch_size_1_depth_500_batches.png',\n",
    "    show_shapes=True,\n",
    "    show_layer_activations=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "batches=1\n",
    "stockfish_depth = 1\n",
    "x_train, y_train = load_dataset(batches=batches, stockfish_depth=stockfish_depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.50649351, 0.51331169, 0.47954545, ..., 0.50974026, 0.51785714,\n",
       "       0.51006494])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('fishsticks')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "45496efc21114d43428a2aa822b83c32e4d2d7c05a02a7b3daddbc538fd9c465"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
